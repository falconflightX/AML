{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1d0708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.38.0 to work with aml_ws\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bbb5508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sekuritdatastore - Default = True\n",
      "azureml_globaldatasets - Default = False\n",
      "workspacefilestore - Default = False\n",
      "workspaceartifactstore - Default = False\n",
      "workspaceblobstore - Default = False\n"
     ]
    }
   ],
   "source": [
    "# Get the default datastore\n",
    "from azureml.core import Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49da1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name='sekuritdataset')\n",
    "data = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f111fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Length</th>\n",
       "      <th>Type</th>\n",
       "      <th>Style</th>\n",
       "      <th>OEM</th>\n",
       "      <th>Engine Disp</th>\n",
       "      <th>Age of OEM</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Oil Price</th>\n",
       "      <th>Petrol</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Column17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Jan-14</td>\n",
       "      <td>16</td>\n",
       "      <td>102.10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1,207</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Feb-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.83</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>882</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mar-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.04</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>839</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Apr-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.87</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>547</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>May-14</td>\n",
       "      <td>16</td>\n",
       "      <td>105.71</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>571</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Length             Type      Style   OEM  Engine Disp  \\\n",
       "0  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "1  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "2  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "3  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "4  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "\n",
       "   Age of OEM    Year  Mileage  Oil Price  Petrol  Automatic  Price  Sales  \\\n",
       "0           8  Jan-14       16     102.10    True      False    5.0  1,207   \n",
       "1           8  Feb-14       16     104.83    True      False    5.0    882   \n",
       "2           8  Mar-14       16     104.04    True      False    5.0    839   \n",
       "3           8  Apr-14       16     104.87    True      False    5.0    547   \n",
       "4           8  May-14       16     105.71    True      False    5.0    571   \n",
       "\n",
       "  Column17  \n",
       "0     None  \n",
       "1     None  \n",
       "2     None  \n",
       "3     None  \n",
       "4     None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a5d6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sekurit_hyper\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'sekurit_hyper'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7afac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric processed_rows:\n",
      "1151\n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Successfully obtained datastore reference and path.\n",
      "Uploading file to managed-dataset/42bda498-9964-4205-b826-82e92eeb2ea7/\n",
      "Successfully uploaded file to datastore.\n",
      "Creating and registering a new dataset.\n",
      "Successfully created and registered a new dataset.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from azureml.core import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Drop unnecessary columns and other cleaning steps\n",
    "data=data.drop(['Year','Column17'],axis=1)\n",
    "\n",
    "data['Sales']=pd.to_numeric(data['Sales'],errors='coerce')\n",
    "data= data[data['Sales'].notna()]\n",
    "\n",
    "\n",
    "# Label Encoding\n",
    "list_of_columns = ['Model','Type','Style','OEM']\n",
    "data[list_of_columns] = data[list_of_columns].apply(lambda col:pd.Categorical(col).codes)\n",
    "\n",
    "# Boolean Encoding\n",
    "data[[\"Petrol\", \"Automatic\"]] *= 1\n",
    "\n",
    "# Normalize the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['Length','Engine Disp','Age of OEM','Mileage','Oil Price','Price']\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "\n",
    "# Log processed rows\n",
    "row_count = (len(data))\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "# Save the train data to a csv to be uploaded to the datastore\n",
    "pd.DataFrame(data).to_csv(\"data/training_data.csv\", index=False)\n",
    "\n",
    "target_path = default_ds\n",
    "\n",
    "Dataset.Tabular.register_pandas_dataframe(dataframe=data, target=target_path, name=\"prepped_data\")\n",
    "# End the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fbeb95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sekurit_hyper/sekurit_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/sekurit_training.py\n",
    "\n",
    "# Import libraries\n",
    "from azureml.core import Run, Model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import math\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from azureml.core import Dataset\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\n",
    "parser.add_argument('--n_estimators', type=int, default=100, help=\"The number of boosting stages to perform\")\n",
    "parser.add_argument('--learning_rate', type=float, default=0.1, help=\"Learning rate shrinks the contribution of each tree by learning_rate\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Log Hyperparameter values\n",
    "run.log('learning_rate',  np.float(args.learning_rate))\n",
    "run.log('n_estimators',  np.int(args.n_estimators))\n",
    "\n",
    "\n",
    "# load the prepared data file in the training folder-\n",
    "print(\"Loading Data...\")\n",
    "data = run.input_datasets['prepped_data'].to_pandas_dataframe() # Get the training data from the estimator input\n",
    "\n",
    "sales_mean = data['Sales'].mean()\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = data[['Model','Length','Type','Style','OEM','Engine Disp','Age of OEM','Mileage','Oil Price','Petrol','Automatic','Price']].values, data['Sales'].values\n",
    "\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=args.n_estimators, learning_rate=args.learning_rate,\n",
    "                                    max_depth=1, random_state=0, loss='huber').fit(X_train, y_train)\n",
    " \n",
    "    \n",
    "    \n",
    "# calculate accuracy\n",
    "# MSE \n",
    "mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "\n",
    "# normalized_root_mean_squared_error => to be comparabe with Azure results\n",
    "metric = math.sqrt(mse)/sales_mean\n",
    "\n",
    "run.log(\"normalized_root_mean_squared_error\", np.float(metric))\n",
    "# Metric reported is 'r2_score' => metric to optimize\n",
    "run.log(\"r2_score\", np.float(model.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/sekurit_hyper_model.pkl')\n",
    "\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c05f4348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"computecluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f92a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sekurit_hyper/experiment_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/experiment_env.yml\n",
    "\n",
    "name: hyperdrive_environment\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- pandas\n",
    "- numpy\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cd88205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
    "\n",
    "# Register the environment \n",
    "experiment_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'experiment_env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "hyper_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "hyper_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "hyper_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d706660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform # supported by RandomParameterSampling\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice # supported by RandomParameterSampling\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core import Environment\n",
    "\n",
    "\n",
    "prepped_ds = Dataset.get_by_name(ws, name='prepped_data')\n",
    "\n",
    "# Parameter sampler for the HyperDrive\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--learning_rate': choice(0.01, 0.1, 0.3),# Contribution of each tree \n",
    "        '--n_estimators': choice(10, 100, 150), # Number of learners\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# This policy compares the value (Y + Y * 0.2) to \"best current score\", and if smaller, cancels the run.\n",
    "policy = BanditPolicy(slack_factor=0.01, delay_evaluation = 50)\n",
    "\n",
    "\n",
    "\n",
    "#ScriptRunConfig\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='sekurit_training.py',\n",
    "                                arguments = ['--training-data', prepped_ds.as_named_input('prepped_data')],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                environment=experiment_env)\n",
    "\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(hyperparameter_sampling=ps,\n",
    "                                     policy=policy,\n",
    "                                     run_config=script_config,\n",
    "                                     #The name of the primary metric reported by the experiment runs.\n",
    "                                     primary_metric_name='r2_score',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs = 10,\n",
    "                                     max_duration_minutes=15,\n",
    "                                     max_concurrent_runs=2) # Number of nodes to change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893be1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1068f71714949599eec93885d3e2aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_b172eab7-107d-4e9c-87fd-fa7f67fec910?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\", \"run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910\", \"run_properties\": {\"run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910\", \"created_utc\": \"2022-03-03T17:14:45.359539Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"r2_score\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"707a65cd-4227-4d6a-86ef-3a32f070361e\", \"user_agent\": \"python/3.6.9 (Linux-5.4.0-1064-azure-x86_64-with-debian-buster-sid) msrest/0.6.21 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.38.0\", \"space_size\": \"9\", \"score\": \"0.015308570482805206\", \"best_child_run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5\", \"best_metric_status\": \"Succeeded\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"2\", \"_aml_system_max_total_jobs\": \"10\", \"_aml_system_max_duration_minutes\": \"15\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 50, \\\"slack_factor\\\": 0.01}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--learning_rate\\\": [\\\"choice\\\", [[0.01, 0.1, 0.3]]], \\\"--n_estimators\\\": [\\\"choice\\\", [[10, 100, 150]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"r2_score\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southeastasia.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/experiments/sekurit-hyperdrive\\\", \\\"SubscriptionId\\\": \\\"8f35cf98-68ff-457e-b1b3-e05921a0fd46\\\", \\\"ResourceGroupName\\\": \\\"rg-lr-dp100\\\", \\\"WorkspaceName\\\": \\\"aml_ws\\\", \\\"ExperimentName\\\": \\\"sekurit-hyperdrive\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"sekurit_training.py\\\", \\\"arguments\\\": [\\\"--training-data\\\", \\\"DatasetConsumptionConfig:prepped_data\\\"], \\\"target\\\": \\\"computecluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": \\\"experiment_env\\\", \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"hyperdrive_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", \\\"scikit-learn\\\", \\\"pandas\\\", \\\"numpy\\\", \\\"pip\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"docker\\\": {\\\"useDocker\\\": false, \\\"sharedVolumes\\\": true, \\\"arguments\\\": [], \\\"shmSize\\\": \\\"2g\\\"}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {\\\"prepped_data\\\": {\\\"dataLocation\\\": {\\\"dataset\\\": {\\\"id\\\": \\\"47ba822f-99a2-40c6-a69e-6b12ffddd6b6\\\", \\\"name\\\": \\\"prepped_data\\\", \\\"version\\\": 2}, \\\"dataPath\\\": null, \\\"uri\\\": null}, \\\"createOutputDirectories\\\": false, \\\"mechanism\\\": \\\"direct\\\", \\\"environmentVariableName\\\": \\\"prepped_data\\\", \\\"pathOnCompute\\\": null, \\\"overwrite\\\": false, \\\"options\\\": null}}, \\\"datacaches\\\": [], \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"kubernetescompute\\\": {\\\"instanceType\\\": null}, \\\"credentialPassthrough\\\": false, \\\"command\\\": \\\"\\\", \\\"environmentVariables\\\": {}, \\\"applicationEndpoints\\\": {}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"707a65cd-4227-4d6a-86ef-3a32f070361e\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"e339bd4b-2e3b-4035-a452-2112d502f2ff\\\", \\\"amlClientRequestId\\\": \\\"c531275b-d120-4d18-832a-dd2ab26fb69d\\\", \\\"amlClientSessionId\\\": \\\"74846ea3-6efb-4220-9b8e-76154eba894c\\\", \\\"subscriptionId\\\": \\\"8f35cf98-68ff-457e-b1b3-e05921a0fd46\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 10, \\\"maxConcurrentRuns\\\": 2, \\\"maxDurationMinutes\\\": 15, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2022-03-03T17:14:46.832368\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"2df59f9111f0d00a2154bad9b4bf89934307394eedc298e83f1d64760c28b3ef\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2022-03-03T17:14:46.832368\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_0\": \"{\\\"--learning_rate\\\": 0.1, \\\"--n_estimators\\\": 150}\", \"_aml_system_HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_1\": \"{\\\"--learning_rate\\\": 0.01, \\\"--n_estimators\\\": 10}\", \"_aml_system_HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_2\": \"{\\\"--learning_rate\\\": 0.1, \\\"--n_estimators\\\": 100}\", \"_aml_system_HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_3\": \"{\\\"--learning_rate\\\": 0.3, \\\"--n_estimators\\\": 100}\", \"_aml_system_HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_4\": \"{\\\"--learning_rate\\\": 0.01, \\\"--n_estimators\\\": 150}\", \"_aml_system_HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5\": \"{\\\"--learning_rate\\\": 0.3, \\\"--n_estimators\\\": 150}\", \"_aml_system_HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_6\": \"{\\\"--learning_rate\\\": 0.3, \\\"--n_estimators\\\": 10}\", \"_aml_system_HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_7\": \"{\\\"--learning_rate\\\": 0.1, \\\"--n_estimators\\\": 10}\", \"_aml_system_HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_8\": \"{\\\"--learning_rate\\\": 0.01, \\\"--n_estimators\\\": 100}\", \"_aml_system_final_best_metric_update_retry_count\": \"1\"}, \"end_time_utc\": \"2022-03-03T17:25:24.665116Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b172eab7-107d-4e9c-87fd-fa7f67fec910/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=T%2BalB3H%2FgPKcdkEmJ1z3yuk8K936tjZpjAf5PzzEjKI%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-03-03T14%3A21%3A21Z&ske=2022-03-04T22%3A31%3A21Z&sks=b&skv=2019-07-07&st=2022-03-03T17%3A42%3A02Z&se=2022-03-04T01%3A52%3A02Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:10:39\", \"run_number\": \"1646327685\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"--learning_rate\": [\"choice\", [[0.01, 0.1, 0.3]]], \"--n_estimators\": [\"choice\", [[10, 100, 150]]]}}, \"child_runs\": [{\"run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_0\", \"run_number\": 1646327746, \"metric\": 0.00416439, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-03-03T17:16:24.037201Z\", \"end_time\": \"2022-03-03T17:16:27.628989Z\", \"created_time\": \"2022-03-03T17:15:46.733642Z\", \"created_time_dt\": \"2022-03-03T17:15:46.733642Z\", \"duration\": \"0:00:40\", \"hyperdrive_id\": \"b172eab7-107d-4e9c-87fd-fa7f67fec910\", \"arguments\": null, \"param_--learning_rate\": 0.1, \"param_--n_estimators\": 150, \"best_metric\": 0.00416439}, {\"run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_3\", \"run_number\": 1646327868, \"metric\": 0.00959239, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-03-03T17:18:17.990592Z\", \"end_time\": \"2022-03-03T17:18:21.564059Z\", \"created_time\": \"2022-03-03T17:17:48.143281Z\", \"created_time_dt\": \"2022-03-03T17:17:48.143281Z\", \"duration\": \"0:00:33\", \"hyperdrive_id\": \"b172eab7-107d-4e9c-87fd-fa7f67fec910\", \"arguments\": null, \"param_--learning_rate\": 0.3, \"param_--n_estimators\": 100, \"best_metric\": 0.00959239}, {\"run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_4\", \"run_number\": 1646327959, \"metric\": -0.0090816, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-03-03T17:20:17.002028Z\", \"end_time\": \"2022-03-03T17:20:20.519633Z\", \"created_time\": \"2022-03-03T17:19:19.119748Z\", \"created_time_dt\": \"2022-03-03T17:19:19.119748Z\", \"duration\": \"0:01:01\", \"hyperdrive_id\": \"b172eab7-107d-4e9c-87fd-fa7f67fec910\", \"arguments\": null, \"param_--learning_rate\": 0.01, \"param_--n_estimators\": 150, \"best_metric\": 0.00959239}, {\"run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5\", \"run_number\": 1646327989, \"metric\": 0.01530857, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-03-03T17:20:22.054195Z\", \"end_time\": \"2022-03-03T17:20:25.672136Z\", \"created_time\": \"2022-03-03T17:19:49.688805Z\", \"created_time_dt\": \"2022-03-03T17:19:49.688805Z\", \"duration\": \"0:00:35\", \"hyperdrive_id\": \"b172eab7-107d-4e9c-87fd-fa7f67fec910\", \"arguments\": null, \"param_--learning_rate\": 0.3, \"param_--n_estimators\": 150, \"best_metric\": 0.01530857}, {\"run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_7\", \"run_number\": 1646328080, \"metric\": -0.01095279, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-03-03T17:22:24.439407Z\", \"end_time\": \"2022-03-03T17:22:27.984745Z\", \"created_time\": \"2022-03-03T17:21:20.968976Z\", \"created_time_dt\": \"2022-03-03T17:21:20.968976Z\", \"duration\": \"0:01:07\", \"hyperdrive_id\": \"b172eab7-107d-4e9c-87fd-fa7f67fec910\", \"arguments\": null, \"param_--learning_rate\": 0.1, \"param_--n_estimators\": 10, \"best_metric\": 0.01530857}, {\"run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_6\", \"run_number\": 1646328081, \"metric\": -0.00257678, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-03-03T17:22:24.578544Z\", \"end_time\": \"2022-03-03T17:22:28.197859Z\", \"created_time\": \"2022-03-03T17:21:21.071044Z\", \"created_time_dt\": \"2022-03-03T17:21:21.071044Z\", \"duration\": \"0:01:07\", \"hyperdrive_id\": \"b172eab7-107d-4e9c-87fd-fa7f67fec910\", \"arguments\": null, \"param_--learning_rate\": 0.3, \"param_--n_estimators\": 10, \"best_metric\": 0.01530857}, {\"run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_8\", \"run_number\": 1646328202, \"metric\": -0.01121309, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2022-03-03T17:24:22.910464Z\", \"end_time\": \"2022-03-03T17:24:26.485845Z\", \"created_time\": \"2022-03-03T17:23:22.158634Z\", \"created_time_dt\": \"2022-03-03T17:23:22.158634Z\", \"duration\": \"0:01:04\", \"hyperdrive_id\": \"b172eab7-107d-4e9c-87fd-fa7f67fec910\", \"arguments\": null, \"param_--learning_rate\": 0.01, \"param_--n_estimators\": 100, \"best_metric\": 0.01530857}], \"children_metrics\": {\"categories\": [0], \"series\": {\"learning_rate\": [{\"categories\": [1646327746, 1646327868, 1646327959, 1646327989, 1646328080, 1646328081, 1646328202], \"mode\": \"markers\", \"name\": \"learning_rate\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.1, 0.3, 0.01, 0.3, 0.1, 0.3, 0.01]}, {\"categories\": [1646327746, 1646327868, 1646327959, 1646327989, 1646328080, 1646328081, 1646328202], \"mode\": \"lines\", \"name\": \"learning_rate_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.1, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3]}], \"n_estimators\": [{\"categories\": [1646327746, 1646327868, 1646327959, 1646327989, 1646328080, 1646328081, 1646328202], \"mode\": \"markers\", \"name\": \"n_estimators\", \"stepped\": false, \"type\": \"scatter\", \"data\": [150, 100, 150, 150, 10, 10, 100]}, {\"categories\": [1646327746, 1646327868, 1646327959, 1646327989, 1646328080, 1646328081, 1646328202], \"mode\": \"lines\", \"name\": \"n_estimators_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [150, 150, 150, 150, 150, 150, 150]}], \"normalized_root_mean_squared_error\": [{\"categories\": [1646327746, 1646327868, 1646327959, 1646327989, 1646328080, 1646328081, 1646328202], \"mode\": \"markers\", \"name\": \"normalized_root_mean_squared_error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [6.0610795793580525, 6.044538453589376, 6.101256808654807, 6.027070064255022, 6.106911103996661, 6.081559799208934, 6.10769727606766]}, {\"categories\": [1646327746, 1646327868, 1646327959, 1646327989, 1646328080, 1646328081, 1646328202], \"mode\": \"lines\", \"name\": \"normalized_root_mean_squared_error_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [6.0610795793580525, 6.0610795793580525, 6.101256808654807, 6.101256808654807, 6.106911103996661, 6.106911103996661, 6.10769727606766]}], \"r2_score\": [{\"categories\": [1646327746, 1646327868, 1646327959, 1646327989, 1646328080, 1646328081, 1646328202], \"mode\": \"markers\", \"name\": \"r2_score\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.004164394919271119, 0.009592393282152889, -0.00908160269008329, 0.015308570482805206, -0.010952787404098219, -0.002576776786199053, -0.011213093798323248]}, {\"categories\": [1646327746, 1646327868, 1646327959, 1646327989, 1646328080, 1646328081, 1646328202], \"mode\": \"lines\", \"name\": \"r2_score_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.004164394919271119, 0.009592393282152889, 0.009592393282152889, 0.015308570482805206, 0.015308570482805206, 0.015308570482805206, 0.015308570482805206]}]}, \"metricName\": null, \"primaryMetricName\": \"r2_score\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910\", \"categories\": [0], \"series\": [{\"data\": [{\"time_elapse\": [183, 274, 397, 397], \"metric_value\": [0.004164394919271119, 0.009592393282152889, 0.015308570482805206, 0.015308570482805206], \"metric_name\": [\"r2_score\", \"r2_score\", \"r2_score\", \"r2_score\"], \"run_id\": [\"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_0\", \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_3\", \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5\", \"HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5\"], \"final\": [false, false, false, true]}]}]}], \"run_logs\": \"[2022-03-03T17:14:45.822455][API][INFO]Experiment created\\r\\n[2022-03-03T17:14:46.639631][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2022-03-03T17:14:47.256224][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2022-03-03T17:15:16.488656][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2022-03-03T17:15:16.779030][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2022-03-03T17:15:46.1788749Z][SCHEDULER][INFO]Scheduling job, id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_0'\\r\\n[2022-03-03T17:15:46.1803110Z][SCHEDULER][INFO]Scheduling job, id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_1'\\r\\n[2022-03-03T17:15:46.6075501Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_1'\\r\\n[2022-03-03T17:15:46.8258907Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_0'\\r\\n[2022-03-03T17:17:19.570059][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2022-03-03T17:17:19.742434][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2022-03-03T17:17:47.5209302Z][SCHEDULER][INFO]Scheduling job, id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_2'\\r\\n[2022-03-03T17:17:47.7542634Z][SCHEDULER][INFO]Scheduling job, id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_3'\\r\\n[2022-03-03T17:17:48.1943968Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_2'\\r\\n[2022-03-03T17:17:48.2163019Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_3'\\r\\n[2022-03-03T17:18:49.445071][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2022-03-03T17:18:49.624799][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2022-03-03T17:19:18.6706372Z][SCHEDULER][INFO]Scheduling job, id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_4'\\r\\n[2022-03-03T17:19:19.2051698Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_4'\\r\\n[2022-03-03T17:19:19.481341][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2022-03-03T17:19:19.629989][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2022-03-03T17:19:49.3595240Z][SCHEDULER][INFO]Scheduling job, id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5'\\r\\n[2022-03-03T17:19:49.7903030Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5'\\r\\n[2022-03-03T17:20:49.438006][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2022-03-03T17:20:49.611810][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2022-03-03T17:21:20.3056669Z][SCHEDULER][INFO]Scheduling job, id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_6'\\r\\n[2022-03-03T17:21:20.3552846Z][SCHEDULER][INFO]Scheduling job, id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_7'\\r\\n[2022-03-03T17:21:21.0565160Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_7'\\r\\n[2022-03-03T17:21:21.1635501Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_6'\\r\\n[2022-03-03T17:22:49.545271][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2022-03-03T17:22:49.699854][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2022-03-03T17:23:19.388178][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2022-03-03T17:23:19.416484][GENERATOR][WARNING]Could not sample any more jobs from the space.\\r\\n[2022-03-03T17:23:21.7926355Z][SCHEDULER][INFO]Scheduling job, id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_8'\\r\\n[2022-03-03T17:23:22.2465895Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_8'\\r\\n[2022-03-03T17:25:24.865764][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.38.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "\n",
    "experiment = Experiment(workspace=ws, name='sekurit-hyperdrive')\n",
    "run = experiment.submit(config=hyperdrive_config)\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af7e576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5',\n",
       " 'target': 'computecluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2022-03-03T17:20:22.054195Z',\n",
       " 'endTimeUtc': '2022-03-03T17:20:25.672136Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '707a65cd-4227-4d6a-86ef-3a32f070361e',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '47ba822f-99a2-40c6-a69e-6b12ffddd6b6'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'prepped_data', 'mechanism': 'Direct'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'sekurit_training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--training-data',\n",
       "   'DatasetConsumptionConfig:prepped_data',\n",
       "   '--learning_rate',\n",
       "   '0.3',\n",
       "   '--n_estimators',\n",
       "   '150'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'computecluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {'prepped_data': {'dataLocation': {'dataset': {'id': '47ba822f-99a2-40c6-a69e-6b12ffddd6b6',\n",
       "      'name': 'prepped_data',\n",
       "      'version': '2'},\n",
       "     'dataPath': None,\n",
       "     'uri': None,\n",
       "     'type': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'prepped_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'experiment_env',\n",
       "   'version': '11',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'pandas',\n",
       "      'numpy',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults']}],\n",
       "     'name': 'azureml_cca64c8c3667dbc9fa4b9eb1c2f6cd0a'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'logs/azureml/dataprep/backgroundProcess.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=IvW7Tj8nUc83On3w%2Br4q6h5t1Go5gGxMWpjF5b8O8Hw%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-03-03T14%3A21%3A21Z&ske=2022-03-04T22%3A31%3A21Z&sks=b&skv=2019-07-07&st=2022-03-03T17%3A17%3A45Z&se=2022-03-04T01%3A27%3A45Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=%2Fn57wG5LyHN9JqkFwZaq9IgRdo0ZmWTOI1gin1zHlfk%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-03-03T14%3A21%3A21Z&ske=2022-03-04T22%3A31%3A21Z&sks=b&skv=2019-07-07&st=2022-03-03T17%3A17%3A45Z&se=2022-03-04T01%3A27%3A45Z&sp=r',\n",
       "  'logs/azureml/dataprep/rslex.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b172eab7-107d-4e9c-87fd-fa7f67fec910_5/logs/azureml/dataprep/rslex.log?sv=2019-07-07&sr=b&sig=2qGsFs9NSEqoyqTOGpjoad3eC3NDVf%2FnceAjUSbyZYc%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-03-03T14%3A21%3A21Z&ske=2022-03-04T22%3A31%3A21Z&sks=b&skv=2019-07-07&st=2022-03-03T17%3A17%3A45Z&se=2022-03-04T01%3A27%3A45Z&sp=r'},\n",
       " 'submittedBy': 'Lalitha Raghavan'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best run\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "\n",
    "best_run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecbb4264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='aml_ws', subscription_id='8f35cf98-68ff-457e-b1b3-e05921a0fd46', resource_group='rg-lr-dp100'), name=sekurit_hyper_model, id=sekurit_hyper_model:1, version=1, tags={'Training context': 'Hyperdrive'}, properties={'r2': '0.015308570482805206'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best run, and its metrics and arguments\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
    "\n",
    "# Register model\n",
    "best_run.register_model(model_path='outputs/sekurit_hyper_model.pkl', model_name='sekurit_hyper_model', ## Note, use the model path given earlier in training script\n",
    "                        tags={'Training context':'Hyperdrive'},\n",
    "                        properties={'r2': best_run_metrics['r2_score']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c5aa4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sekurit_hyper_model version: 1\n",
      "\t Training context : Hyperdrive\n",
      "\t r2 : 0.015308570482805206\n",
      "\n",
      "\n",
      "sekurit_automl_model version: 4\n",
      "\n",
      "\n",
      "sekurit_automl_model version: 3\n",
      "\n",
      "\n",
      "sekurit_automl_model version: 2\n",
      "\n",
      "\n",
      "sekurit_automl_model version: 1\n",
      "\n",
      "\n",
      "sekurit_model version: 7\n",
      "\t Training context : Pipeline\n",
      "\t Accuracy : 0.5057803468208093\n",
      "\n",
      "\n",
      "sekurit_model_initial version: 2\n",
      "\n",
      "\n",
      "AutoML0b24ea5a20 version: 1\n",
      "\n",
      "\n",
      "amlstudio-test-deploy-v2 version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "amlstudio-test-endpoint-lr version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "diabetes_model version: 11\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8832778417290374\n",
      "\t Accuracy : 0.8991111111111111\n",
      "\n",
      "\n",
      "diabetes_mitigated_19 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_18 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_17 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_16 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_15 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_14 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_13 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_12 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_11 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_10 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_9 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_8 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_7 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_6 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_4 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_3 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_2 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_1 version: 1\n",
      "\n",
      "\n",
      "diabetes_unmitigated version: 1\n",
      "\n",
      "\n",
      "diabetes_classifier version: 1\n",
      "\n",
      "\n",
      "diabetes_model version: 10\n",
      "\t Training context : Auto ML\n",
      "\t AUC : 0.9904812577250306\n",
      "\t Accuracy : 0.9520809898762654\n",
      "\n",
      "\n",
      "diabetes_model version: 9\n",
      "\t Training context : Hyperdrive\n",
      "\t AUC : 0.9885804604667666\n",
      "\t Accuracy : 0.9457777777777778\n",
      "\n",
      "\n",
      "diabetes_model version: 8\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8755584854967908\n",
      "\t Accuracy : 0.8863333333333333\n",
      "\n",
      "\n",
      "diabetes_model version: 7\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.879600975172894\n",
      "\t Accuracy : 0.8926666666666667\n",
      "\n",
      "\n",
      "diabetes_model version: 6\n",
      "\t Training context : Pipeline\n",
      "\t AUC : 0.8837616052365906\n",
      "\t Accuracy : 0.8988888888888888\n",
      "\n",
      "\n",
      "diabetes_model version: 5\n",
      "\t Training context : File dataset\n",
      "\t AUC : 0.8568743524381947\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 4\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8483964376337131\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8483999203940495\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC : 0.8484929598487486\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87e9ac42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>azml-sekurit-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/4378c267-0738-4788-a7a3-79e6886e88d1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws\" target=\"_blank\" rel=\"noopener\">4378c267-0738-4788-a7a3-79e6886e88d1</a></td><td>Active</td><td><a href=\"https://southeastasia.api.azureml.ms/pipelines/v1.0/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/PipelineRuns/PipelineSubmit/4378c267-0738-4788-a7a3-79e6886e88d1\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: azml-sekurit-pipeline,\n",
       "Id: 4378c267-0738-4788-a7a3-79e6886e88d1,\n",
       "Status: Active,\n",
       "Endpoint: https://southeastasia.api.azureml.ms/pipelines/v1.0/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/PipelineRuns/PipelineSubmit/4378c267-0738-4788-a7a3-79e6886e88d1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Publish the pipeline from the run\n",
    "\n",
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"azml-sekurit-pipeline\", description=\"Trains and registers a logistic regression on sekurit data\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01774225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://southeastasia.api.azureml.ms/pipelines/v1.0/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/PipelineRuns/PipelineSubmit/4378c267-0738-4788-a7a3-79e6886e88d1\n"
     ]
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rerun pipeline from published endpoint - Triggers a fresh pipeline but it will be faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5893aa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication header ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print(\"Authentication header ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "experiment_name = 'azml-sekurit-pipeline'\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f450e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "published_pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4710d60",
   "metadata": {},
   "source": [
    "## Lets deploy for real time inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a3c2908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sekurit_hyper_model version 1\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['sekurit_hyper_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec34c636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment_hyper\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the inference config files\n",
    "deployment_folder = 'deployment_hyper'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "\n",
    "print(deployment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51f7b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deployment_hyper/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $deployment_folder/score.py\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "\n",
    "\n",
    "input_sample = [{\n",
    "    \"Model\": \"Grand Punto\",\n",
    "    \"Length\": 4000,\n",
    "    \"Type\":\"Compact-Regular\",\n",
    "    \"Style\":\"Hatchback\",\n",
    "    \"OEM\":\"Fiat\",\n",
    "    \"Engine Disp\":1.4,\n",
    "    \"Age of OEM\":8,\n",
    "    \"Mileage\":16,\n",
    "    \"Oil Price\":102.1,\n",
    "    \"Petrol\":\"Y\", \n",
    "    \"Automatic\":\"N\",\n",
    "    \"Price\":5\n",
    "  }]\n",
    "\n",
    "output_sample = [[1207]]\n",
    "\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path(\"sekurit_hyper_model\")\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "\n",
    "# Inference_schema generates a schema for your web service\n",
    "# It then creates an OpenAPI (Swagger) specification for the web service\n",
    "# at http://<scoring_base_url>/swagger.json\n",
    "\n",
    "@input_schema('data', StandardPythonParameterType(input_sample))\n",
    "@output_schema(StandardPythonParameterType(output_sample))\n",
    "\n",
    "def run(data):\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        pred = model.predict(df)\n",
    "        result = {\"predict\":pred.tolist()}\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbafab01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_hyperml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the inference config files\n",
    "config_folder = 'config_hyperml'\n",
    "os.makedirs(config_folder, exist_ok=True)\n",
    "\n",
    "print(config_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ede91305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config_hyperml/inference_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $config_folder/inference_env.yml\n",
    "\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - azureml-sdk[automl]\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de711a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define deployment setup\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "    \n",
    "# Conda enviroment (if we want to use additional Python packages)\n",
    "env = Environment.from_conda_specification(\"inference-env\", config_folder + \"/inference_env.yml\")\n",
    "\n",
    "inference_config = InferenceConfig(entry_script= deployment_folder +'/score.py', environment=env)\n",
    "\n",
    "# Define how our webservice should look like (resources, security, etc.)\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c51f9669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-03-03 17:51:47+00:00 Creating Container Registry if not exists.\n",
      "2022-03-03 17:51:47+00:00 Registering the environment.\n",
      "2022-03-03 17:51:48+00:00 Use the existing image.\n",
      "2022-03-03 17:51:48+00:00 Generating deployment configuration.\n",
      "2022-03-03 17:51:49+00:00 Submitting deployment to compute.\n",
      "2022-03-03 17:51:55+00:00 Checking the status of deployment sekurit-hyper-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, \"sekurit-hyper-service\", [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb9bf113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: {\"predict\": [-537.4727213239458]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = service.scoring_uri\n",
    "\n",
    "# test_data = {\n",
    "#   'data': [{\n",
    "#     \"Model\": \"Grand Punto\",\n",
    "#     \"Length\": 4000,\n",
    "#     \"Type\":\"Compact-Regular\",\n",
    "#     \"Style\":\"Hatchback\",\n",
    "#     \"OEM\":\"Fiat\",\n",
    "    \n",
    "#     \"Engine Disp\":1.4,\n",
    "#     \"Age of OEM\":8,  \n",
    "#     \"Mileage\":16,\n",
    "#     \"Oil Price\":102.1,\n",
    "#     \"Petrol\":\"Y\", \n",
    "#     \"Automatic\":\"N\",\n",
    "#     \"Price\":5\n",
    "#   }]\n",
    "# }\n",
    "\n",
    "\n",
    "test_data = {\n",
    "  'data': [{\n",
    "    \"Model\": 0,\n",
    "    \"Length\": 4000,\n",
    "    \"Type\":0,\n",
    "    \"Style\":0,\n",
    "    \"OEM\":0,\n",
    "    \"Engine Disp\":1.4,\n",
    "    \"Age of OEM\":8,  \n",
    "    \"Mileage\":16,\n",
    "    \"Oil Price\":102.1,\n",
    "    \"Petrol\":0, \n",
    "    \"Automatic\":0,\n",
    "    \"Price\":5\n",
    "  }]\n",
    "}\n",
    "\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "resp = requests.post(url, json=test_data, headers=headers)\n",
    "\n",
    "print(\"Prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248ce97",
   "metadata": {},
   "source": [
    "## Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110579f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.38.0 to work with aml_ws\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a213a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sekuritdatastore - Default = True\n",
      "azureml_globaldatasets - Default = False\n",
      "workspaceworkingdirectory - Default = False\n",
      "workspacefilestore - Default = False\n",
      "workspaceartifactstore - Default = False\n",
      "workspaceblobstore - Default = False\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a73af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created!\n",
      "Saving files...\n",
      "files saved!\n",
      "Uploading files to datastore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 100 files\n",
      "Uploading batch-data/1.csv\n",
      "Uploaded batch-data/1.csv, 1 files out of an estimated total of 100\n",
      "Uploading batch-data/10.csv\n",
      "Uploaded batch-data/10.csv, 2 files out of an estimated total of 100\n",
      "Uploading batch-data/100.csv\n",
      "Uploaded batch-data/100.csv, 3 files out of an estimated total of 100\n",
      "Uploading batch-data/11.csv\n",
      "Uploaded batch-data/11.csv, 4 files out of an estimated total of 100\n",
      "Uploading batch-data/12.csv\n",
      "Uploaded batch-data/12.csv, 5 files out of an estimated total of 100\n",
      "Uploading batch-data/13.csv\n",
      "Uploaded batch-data/13.csv, 6 files out of an estimated total of 100\n",
      "Uploading batch-data/14.csv\n",
      "Uploaded batch-data/14.csv, 7 files out of an estimated total of 100\n",
      "Uploading batch-data/15.csv\n",
      "Uploaded batch-data/15.csv, 8 files out of an estimated total of 100\n",
      "Uploading batch-data/16.csv\n",
      "Uploaded batch-data/16.csv, 9 files out of an estimated total of 100\n",
      "Uploading batch-data/17.csv\n",
      "Uploaded batch-data/17.csv, 10 files out of an estimated total of 100\n",
      "Uploading batch-data/18.csv\n",
      "Uploaded batch-data/18.csv, 11 files out of an estimated total of 100\n",
      "Uploading batch-data/19.csv\n",
      "Uploaded batch-data/19.csv, 12 files out of an estimated total of 100\n",
      "Uploading batch-data/2.csv\n",
      "Uploaded batch-data/2.csv, 13 files out of an estimated total of 100\n",
      "Uploading batch-data/20.csv\n",
      "Uploaded batch-data/20.csv, 14 files out of an estimated total of 100\n",
      "Uploading batch-data/21.csv\n",
      "Uploaded batch-data/21.csv, 15 files out of an estimated total of 100\n",
      "Uploading batch-data/22.csv\n",
      "Uploaded batch-data/22.csv, 16 files out of an estimated total of 100\n",
      "Uploading batch-data/23.csv\n",
      "Uploaded batch-data/23.csv, 17 files out of an estimated total of 100\n",
      "Uploading batch-data/24.csv\n",
      "Uploaded batch-data/24.csv, 18 files out of an estimated total of 100\n",
      "Uploading batch-data/25.csv\n",
      "Uploaded batch-data/25.csv, 19 files out of an estimated total of 100\n",
      "Uploading batch-data/26.csv\n",
      "Uploaded batch-data/26.csv, 20 files out of an estimated total of 100\n",
      "Uploading batch-data/27.csv\n",
      "Uploaded batch-data/27.csv, 21 files out of an estimated total of 100\n",
      "Uploading batch-data/28.csv\n",
      "Uploaded batch-data/28.csv, 22 files out of an estimated total of 100\n",
      "Uploading batch-data/29.csv\n",
      "Uploaded batch-data/29.csv, 23 files out of an estimated total of 100\n",
      "Uploading batch-data/3.csv\n",
      "Uploaded batch-data/3.csv, 24 files out of an estimated total of 100\n",
      "Uploading batch-data/30.csv\n",
      "Uploaded batch-data/30.csv, 25 files out of an estimated total of 100\n",
      "Uploading batch-data/31.csv\n",
      "Uploaded batch-data/31.csv, 26 files out of an estimated total of 100\n",
      "Uploading batch-data/32.csv\n",
      "Uploaded batch-data/32.csv, 27 files out of an estimated total of 100\n",
      "Uploading batch-data/33.csv\n",
      "Uploaded batch-data/33.csv, 28 files out of an estimated total of 100\n",
      "Uploading batch-data/34.csv\n",
      "Uploaded batch-data/34.csv, 29 files out of an estimated total of 100\n",
      "Uploading batch-data/35.csv\n",
      "Uploaded batch-data/35.csv, 30 files out of an estimated total of 100\n",
      "Uploading batch-data/36.csv\n",
      "Uploaded batch-data/36.csv, 31 files out of an estimated total of 100\n",
      "Uploading batch-data/37.csv\n",
      "Uploaded batch-data/37.csv, 32 files out of an estimated total of 100\n",
      "Uploading batch-data/38.csv\n",
      "Uploaded batch-data/38.csv, 33 files out of an estimated total of 100\n",
      "Uploading batch-data/39.csv\n",
      "Uploaded batch-data/39.csv, 34 files out of an estimated total of 100\n",
      "Uploading batch-data/4.csv\n",
      "Uploaded batch-data/4.csv, 35 files out of an estimated total of 100\n",
      "Uploading batch-data/40.csv\n",
      "Uploaded batch-data/40.csv, 36 files out of an estimated total of 100\n",
      "Uploading batch-data/41.csv\n",
      "Uploaded batch-data/41.csv, 37 files out of an estimated total of 100\n",
      "Uploading batch-data/42.csv\n",
      "Uploaded batch-data/42.csv, 38 files out of an estimated total of 100\n",
      "Uploading batch-data/43.csv\n",
      "Uploaded batch-data/43.csv, 39 files out of an estimated total of 100\n",
      "Uploading batch-data/44.csv\n",
      "Uploaded batch-data/44.csv, 40 files out of an estimated total of 100\n",
      "Uploading batch-data/45.csv\n",
      "Uploaded batch-data/45.csv, 41 files out of an estimated total of 100\n",
      "Uploading batch-data/46.csv\n",
      "Uploaded batch-data/46.csv, 42 files out of an estimated total of 100\n",
      "Uploading batch-data/47.csv\n",
      "Uploaded batch-data/47.csv, 43 files out of an estimated total of 100\n",
      "Uploading batch-data/48.csv\n",
      "Uploaded batch-data/48.csv, 44 files out of an estimated total of 100\n",
      "Uploading batch-data/49.csv\n",
      "Uploaded batch-data/49.csv, 45 files out of an estimated total of 100\n",
      "Uploading batch-data/5.csv\n",
      "Uploaded batch-data/5.csv, 46 files out of an estimated total of 100\n",
      "Uploading batch-data/50.csv\n",
      "Uploaded batch-data/50.csv, 47 files out of an estimated total of 100\n",
      "Uploading batch-data/51.csv\n",
      "Uploaded batch-data/51.csv, 48 files out of an estimated total of 100\n",
      "Uploading batch-data/52.csv\n",
      "Uploaded batch-data/52.csv, 49 files out of an estimated total of 100\n",
      "Uploading batch-data/53.csv\n",
      "Uploaded batch-data/53.csv, 50 files out of an estimated total of 100\n",
      "Uploading batch-data/54.csv\n",
      "Uploaded batch-data/54.csv, 51 files out of an estimated total of 100\n",
      "Uploading batch-data/55.csv\n",
      "Uploaded batch-data/55.csv, 52 files out of an estimated total of 100\n",
      "Uploading batch-data/56.csv\n",
      "Uploaded batch-data/56.csv, 53 files out of an estimated total of 100\n",
      "Uploading batch-data/57.csv\n",
      "Uploaded batch-data/57.csv, 54 files out of an estimated total of 100\n",
      "Uploading batch-data/58.csv\n",
      "Uploaded batch-data/58.csv, 55 files out of an estimated total of 100\n",
      "Uploading batch-data/59.csv\n",
      "Uploaded batch-data/59.csv, 56 files out of an estimated total of 100\n",
      "Uploading batch-data/6.csv\n",
      "Uploaded batch-data/6.csv, 57 files out of an estimated total of 100\n",
      "Uploading batch-data/60.csv\n",
      "Uploaded batch-data/60.csv, 58 files out of an estimated total of 100\n",
      "Uploading batch-data/61.csv\n",
      "Uploaded batch-data/61.csv, 59 files out of an estimated total of 100\n",
      "Uploading batch-data/62.csv\n",
      "Uploaded batch-data/62.csv, 60 files out of an estimated total of 100\n",
      "Uploading batch-data/63.csv\n",
      "Uploaded batch-data/63.csv, 61 files out of an estimated total of 100\n",
      "Uploading batch-data/64.csv\n",
      "Uploaded batch-data/64.csv, 62 files out of an estimated total of 100\n",
      "Uploading batch-data/65.csv\n",
      "Uploaded batch-data/65.csv, 63 files out of an estimated total of 100\n",
      "Uploading batch-data/66.csv\n",
      "Uploaded batch-data/66.csv, 64 files out of an estimated total of 100\n",
      "Uploading batch-data/67.csv\n",
      "Uploaded batch-data/67.csv, 65 files out of an estimated total of 100\n",
      "Uploading batch-data/68.csv\n",
      "Uploaded batch-data/68.csv, 66 files out of an estimated total of 100\n",
      "Uploading batch-data/69.csv\n",
      "Uploaded batch-data/69.csv, 67 files out of an estimated total of 100\n",
      "Uploading batch-data/7.csv\n",
      "Uploaded batch-data/7.csv, 68 files out of an estimated total of 100\n",
      "Uploading batch-data/70.csv\n",
      "Uploaded batch-data/70.csv, 69 files out of an estimated total of 100\n",
      "Uploading batch-data/71.csv\n",
      "Uploaded batch-data/71.csv, 70 files out of an estimated total of 100\n",
      "Uploading batch-data/72.csv\n",
      "Uploaded batch-data/72.csv, 71 files out of an estimated total of 100\n",
      "Uploading batch-data/73.csv\n",
      "Uploaded batch-data/73.csv, 72 files out of an estimated total of 100\n",
      "Uploading batch-data/74.csv\n",
      "Uploaded batch-data/74.csv, 73 files out of an estimated total of 100\n",
      "Uploading batch-data/75.csv\n",
      "Uploaded batch-data/75.csv, 74 files out of an estimated total of 100\n",
      "Uploading batch-data/76.csv\n",
      "Uploaded batch-data/76.csv, 75 files out of an estimated total of 100\n",
      "Uploading batch-data/77.csv\n",
      "Uploaded batch-data/77.csv, 76 files out of an estimated total of 100\n",
      "Uploading batch-data/78.csv\n",
      "Uploaded batch-data/78.csv, 77 files out of an estimated total of 100\n",
      "Uploading batch-data/79.csv\n",
      "Uploaded batch-data/79.csv, 78 files out of an estimated total of 100\n",
      "Uploading batch-data/8.csv\n",
      "Uploaded batch-data/8.csv, 79 files out of an estimated total of 100\n",
      "Uploading batch-data/80.csv\n",
      "Uploaded batch-data/80.csv, 80 files out of an estimated total of 100\n",
      "Uploading batch-data/81.csv\n",
      "Uploaded batch-data/81.csv, 81 files out of an estimated total of 100\n",
      "Uploading batch-data/82.csv\n",
      "Uploaded batch-data/82.csv, 82 files out of an estimated total of 100\n",
      "Uploading batch-data/83.csv\n",
      "Uploaded batch-data/83.csv, 83 files out of an estimated total of 100\n",
      "Uploading batch-data/84.csv\n",
      "Uploaded batch-data/84.csv, 84 files out of an estimated total of 100\n",
      "Uploading batch-data/85.csv\n",
      "Uploaded batch-data/85.csv, 85 files out of an estimated total of 100\n",
      "Uploading batch-data/86.csv\n",
      "Uploaded batch-data/86.csv, 86 files out of an estimated total of 100\n",
      "Uploading batch-data/87.csv\n",
      "Uploaded batch-data/87.csv, 87 files out of an estimated total of 100\n",
      "Uploading batch-data/88.csv\n",
      "Uploaded batch-data/88.csv, 88 files out of an estimated total of 100\n",
      "Uploading batch-data/89.csv\n",
      "Uploaded batch-data/89.csv, 89 files out of an estimated total of 100\n",
      "Uploading batch-data/9.csv\n",
      "Uploaded batch-data/9.csv, 90 files out of an estimated total of 100\n",
      "Uploading batch-data/90.csv\n",
      "Uploaded batch-data/90.csv, 91 files out of an estimated total of 100\n",
      "Uploading batch-data/91.csv\n",
      "Uploaded batch-data/91.csv, 92 files out of an estimated total of 100\n",
      "Uploading batch-data/92.csv\n",
      "Uploaded batch-data/92.csv, 93 files out of an estimated total of 100\n",
      "Uploading batch-data/93.csv\n",
      "Uploaded batch-data/93.csv, 94 files out of an estimated total of 100\n",
      "Uploading batch-data/94.csv\n",
      "Uploaded batch-data/94.csv, 95 files out of an estimated total of 100\n",
      "Uploading batch-data/95.csv\n",
      "Uploaded batch-data/95.csv, 96 files out of an estimated total of 100\n",
      "Uploading batch-data/96.csv\n",
      "Uploaded batch-data/96.csv, 97 files out of an estimated total of 100\n",
      "Uploading batch-data/97.csv\n",
      "Uploaded batch-data/97.csv, 98 files out of an estimated total of 100\n",
      "Uploading batch-data/98.csv\n",
      "Uploaded batch-data/98.csv, 99 files out of an estimated total of 100\n",
      "Uploading batch-data/99.csv\n",
      "Uploaded batch-data/99.csv, 100 files out of an estimated total of 100\n",
      "Uploaded 100 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "sekurit = Dataset.get_by_name(ws, name='sekuritdataset')\n",
    "data = sekurit.to_pandas_dataframe()\n",
    "# Get a 100-item sample of the feature columns \n",
    "sample = data[['Model','Length','Type','Style','OEM','Engine Disp','Age of OEM','Year','Mileage','Oil Price','Petrol','Automatic','Price']].sample(n=100).values\n",
    "\n",
    "# Create a folder\n",
    "batch_folder = './batch-data'\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "print(\"Folder created!\")\n",
    "\n",
    "# Save each sample as a separate file\n",
    "print(\"Saving files...\")\n",
    "for i in range(100):\n",
    "    fname = str(i+1) + '.csv'\n",
    "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\n",
    "print(\"files saved!\")\n",
    "\n",
    "# Upload the files to the default datastore\n",
    "print(\"Uploading files to datastore...\")\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\n",
    "\n",
    "# Register a dataset for the input data\n",
    "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\n",
    "try:\n",
    "    batch_data_set = batch_data_set.register(workspace=ws, \n",
    "                                             name='batch-data',\n",
    "                                             description='batch data',\n",
    "                                             create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5aabff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"computeclusterlr\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8968f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'batch_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "326966b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_pipeline/batch_sekurit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_sekurit.py\n",
    "import os\n",
    "import numpy as np\n",
    "from azureml.core import Model\n",
    "import joblib\n",
    "\n",
    "\n",
    "def init():\n",
    "    # Runs when the pipeline step is initialized\n",
    "    global model\n",
    "\n",
    "    # load the model\n",
    "    model_path = Model.get_model_path('sekurit_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "def run(mini_batch):\n",
    "    # This runs for each batch\n",
    "    resultList = []\n",
    "\n",
    "    # process each file in the batch\n",
    "    for f in mini_batch:\n",
    "        # Read the comma-delimited data into an array\n",
    "        data = np.genfromtxt(f, delimiter=',')\n",
    "        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\n",
    "        prediction = model.predict(data.reshape(1, -1))\n",
    "        # Append prediction to results\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb0e92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_pipeline/batch_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_env.yml\n",
    "\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05e5b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Create an Environment for the experiment\n",
    "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_env.yml\")\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "print('Configuration ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34de0f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "\n",
    "output_dir = OutputFileDatasetConfig(name='inferences')\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=experiment_folder,\n",
    "    entry_script=\"batch_sekurit.py\",\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    compute_target=pipeline_cluster,\n",
    "    node_count=2)\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name='batch-score-sekurit',\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[batch_data_set.as_named_input('sekurit_batch')],\n",
    "    output=output_dir,\n",
    "    arguments=[],\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print('Steps defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "095c6ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batch-score-sekurit [a68d958d][169b673a-52c7-4dbe-b358-e72e5ea0d9a3], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 8601ef27-fb7d-4aa7-8249-1d3e4e271614\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/8601ef27-fb7d-4aa7-8249-1d3e4e271614?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "PipelineRunId: 8601ef27-fb7d-4aa7-8249-1d3e4e271614\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/8601ef27-fb7d-4aa7-8249-1d3e4e271614?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "StepRun( batch-score-sekurit ) Status: NotStarted\n",
      "StepRun( batch-score-sekurit ) Status: Queued\n",
      "StepRun( batch-score-sekurit ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_70e4add24c65bf530f9c4ed9ed5a8cf9b15facfc5b2124ce2243c82c68897141_d.txt\n",
      "========================================================================================================================\n",
      "2022-02-28T19:40:21Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24747 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2022-02-28T19:40:21Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/mounts/workspaceblobstore -- stdout/stderr: \n",
      "2022-02-28T19:40:22Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2022-02-28T19:40:22Z Starting output-watcher...\n",
      "2022-02-28T19:40:22Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2022-02-28T19:40:22Z Executing 'Copy ACR Details file' on 10.0.0.6\n",
      "2022-02-28T19:40:22Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2022-02-28T19:40:22Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "2022-02-28T19:40:23Z Copy ACR Details file succeeded on 10.0.0.6. Output: \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_f7dca5f5f0dac270c156fcb7f532f287\n",
      "92473f7ef455: Pulling fs layer\n",
      "fb52bde70123: Pulling fs layer\n",
      "64788f86be3f: Pulling fs layer\n",
      "33f6d5f2e001: Pulling fs layer\n",
      "eeb715f1b6ae: Pulling fs layer\n",
      "fe519cf36537: Pulling fs layer\n",
      "58ff99196c15: Pulling fs layer\n",
      "9b13f06a8eff: Pulling fs layer\n",
      "2d4e93adbf58: Pulling fs layer\n",
      "6ee7c3767844: Pulling fs layer\n",
      "62cfc3ccb8ab: Pulling fs layer\n",
      "4a7af9d757ee: Pulling fs layer\n",
      "9e003623bee8: Pulling fs layer\n",
      "3bc226f3e817: Pulling fs layer\n",
      "0f1427a1ad9a: Pulling fs layer\n",
      "d3e37e76c9a7: Pulling fs layer\n",
      "97329cd6cca4: Pulling fs layer\n",
      "9fc8fd4f5d56: Pulling fs layer\n",
      "b7455bac32aa: Pulling fs layer\n",
      "63561bab5267: Pulling fs layer\n",
      "33f6d5f2e001: Waiting\n",
      "eeb715f1b6ae: Waiting\n",
      "fe519cf36537: Waiting\n",
      "58ff99196c15: Waiting\n",
      "9b13f06a8eff: Waiting\n",
      "2d4e93adbf58: Waiting\n",
      "6ee7c3767844: Waiting\n",
      "62cfc3ccb8ab: Waiting\n",
      "4a7af9d757ee: Waiting\n",
      "9e003623bee8: Waiting\n",
      "3bc226f3e817: Waiting\n",
      "0f1427a1ad9a: Waiting\n",
      "d3e37e76c9a7: Waiting\n",
      "97329cd6cca4: Waiting\n",
      "9fc8fd4f5d56: Waiting\n",
      "b7455bac32aa: Waiting\n",
      "63561bab5267: Waiting\n",
      "fb52bde70123: Verifying Checksum\n",
      "fb52bde70123: Download complete\n",
      "64788f86be3f: Verifying Checksum\n",
      "64788f86be3f: Download complete\n",
      "33f6d5f2e001: Verifying Checksum\n",
      "33f6d5f2e001: Download complete\n",
      "92473f7ef455: Verifying Checksum\n",
      "92473f7ef455: Download complete\n",
      "58ff99196c15: Verifying Checksum\n",
      "58ff99196c15: Download complete\n",
      "fe519cf36537: Verifying Checksum\n",
      "fe519cf36537: Download complete\n",
      "eeb715f1b6ae: Verifying Checksum\n",
      "eeb715f1b6ae: Download complete\n",
      "6ee7c3767844: Verifying Checksum\n",
      "6ee7c3767844: Download complete\n",
      "9b13f06a8eff: Verifying Checksum\n",
      "9b13f06a8eff: Download complete\n",
      "62cfc3ccb8ab: Verifying Checksum\n",
      "62cfc3ccb8ab: Download complete\n",
      "4a7af9d757ee: Verifying Checksum\n",
      "4a7af9d757ee: Download complete\n",
      "2d4e93adbf58: Verifying Checksum\n",
      "2d4e93adbf58: Download complete\n",
      "0f1427a1ad9a: Verifying Checksum\n",
      "0f1427a1ad9a: Download complete\n",
      "9e003623bee8: Verifying Checksum\n",
      "9e003623bee8: Download complete\n",
      "97329cd6cca4: Download complete\n",
      "d3e37e76c9a7: Verifying Checksum\n",
      "d3e37e76c9a7: Download complete\n",
      "9fc8fd4f5d56: Verifying Checksum\n",
      "9fc8fd4f5d56: Download complete\n",
      "b7455bac32aa: Verifying Checksum\n",
      "b7455bac32aa: Download complete\n",
      "63561bab5267: Verifying Checksum\n",
      "63561bab5267: Download complete\n",
      "3bc226f3e817: Verifying Checksum\n",
      "3bc226f3e817: Download complete\n",
      "92473f7ef455: Pull complete\n",
      "fb52bde70123: Pull complete\n",
      "64788f86be3f: Pull complete\n",
      "33f6d5f2e001: Pull complete\n",
      "eeb715f1b6ae: Pull complete\n",
      "fe519cf36537: Pull complete\n",
      "58ff99196c15: Pull complete\n",
      "9b13f06a8eff: Pull complete\n",
      "2d4e93adbf58: Pull complete\n",
      "6ee7c3767844: Pull complete\n",
      "62cfc3ccb8ab: Pull complete\n",
      "4a7af9d757ee: Pull complete\n",
      "9e003623bee8: Pull complete\n",
      "3bc226f3e817: Pull complete\n",
      "0f1427a1ad9a: Pull complete\n",
      "d3e37e76c9a7: Pull complete\n",
      "97329cd6cca4: Pull complete\n",
      "9fc8fd4f5d56: Pull complete\n",
      "b7455bac32aa: Pull complete\n",
      "63561bab5267: Pull complete\n",
      "Digest: sha256:1ba0fe158be6cf30393d682a14b245ddcb6727074eec0217cedc80252795e38b\n",
      "Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_f7dca5f5f0dac270c156fcb7f532f287:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_f7dca5f5f0dac270c156fcb7f532f287:latest\n",
      "2022-02-28T19:41:00Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2022-02-28T19:41:00Z Check if container 5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95_DataSidecar already exist exited with 0, \n",
      "\n",
      "c62c4e3392590b22b118ec30ace9a80d56b7ba8d7df14a6445c35158ea118aae\n",
      "2022-02-28T19:41:01Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2022-02-28T19:41:01Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-9af48e30f1910bd1424dbec7ff690fff-b82835faa3322d12-01 -sshRequired=false] \n",
      "2022/02/28 19:41:01 Didn't get JobInfoJson from env, now read from file\n",
      "2022/02/28 19:41:01 Suceeded read JobInfoJson from file\n",
      "2022/02/28 19:41:02 Starting App Insight Logger for task:  containerSetup\n",
      "2022/02/28 19:41:02 Version: 3.0.01867.0001 Branch: .SourceBranch Commit: 925d6a4\n",
      "2022/02/28 19:41:02 Entered ContainerSetupTask - Preparing infiniband\n",
      "2022/02/28 19:41:02 Starting infiniband setup\n",
      "2022/02/28 19:41:02 Python Version found is Python 3.7.9\n",
      "\n",
      "2022/02/28 19:41:02 Returning Python Version as 3.7\n",
      "2022/02/28 19:41:02 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2022/02/28 19:41:02 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2022-02-28T19:41:02Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2022/02/28 19:41:02 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2022/02/28 19:41:02 Not setting up Infiniband in Container\n",
      "2022/02/28 19:41:02 Not setting up Infiniband in Container\n",
      "2022-02-28T19:41:02Z Not setting up Infiniband in Container\n",
      "2022/02/28 19:41:02 Python Version found is Python 3.7.9\n",
      "\n",
      "2022/02/28 19:41:02 Returning Python Version as 3.7\n",
      "2022/02/28 19:41:02 sshd inside container not required for job, skipping setup.\n",
      "2022/02/28 19:41:03 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "2022/02/28 19:41:03 App Insight Client has already been closed\n",
      "2022/02/28 19:41:03 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2022-02-28T19:41:03Z Starting docker container succeeded.\n",
      "2022-02-28T19:41:03Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_70e4add24c65bf530f9c4ed9ed5a8cf9b15facfc5b2124ce2243c82c68897141_d.txt\n",
      "===============================================================================================================\n",
      "[2022-02-28T19:41:05.120873] Entering job preparation.\n",
      "[2022-02-28T19:41:05.837097] Starting job preparation.\n",
      "[2022-02-28T19:41:05.837145] Extracting the control code.\n",
      "[2022-02-28T19:41:05.837499] Starting extract_project.\n",
      "[2022-02-28T19:41:05.837549] Starting to extract zip file.\n",
      "[2022-02-28T19:41:05.856837] Finished extracting zip file.\n",
      "[2022-02-28T19:41:05.861179] Using urllib.request Python 3.0 or later\n",
      "[2022-02-28T19:41:05.861347] Start fetching snapshots.\n",
      "[2022-02-28T19:41:05.861516] Start fetching snapshot.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 57\n",
      "[2022-02-28T19:41:06.221422] Finished fetching snapshot.\n",
      "[2022-02-28T19:41:06.221468] Start fetching snapshot.\n",
      "[2022-02-28T19:41:13.573813] Finished fetching snapshot.\n",
      "[2022-02-28T19:41:13.573862] Finished fetching snapshots.\n",
      "[2022-02-28T19:41:13.573877] Finished extract_project.\n",
      "[2022-02-28T19:41:13.573959] Finished fetching and extracting the control code.\n",
      "[2022-02-28T19:41:13.583888] Start run_history_prep.\n",
      "[2022-02-28T19:41:13.592433] Job preparation is complete.\n",
      "[2022-02-28T19:41:13.592760] Entering Data Context Managers in Sidecar\n",
      "[2022-02-28T19:41:13.593702] Running Sidecar prep cmd...\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.22.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('azure-core<1.22')).\n",
      "[2022-02-28T19:41:13.920113] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95\n",
      "[2022-02-28T19:41:13.921253] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      "[2022-02-28T19:41:14.136] Enter __enter__ of DatasetContextManager\n",
      "[2022-02-28T19:41:14.137] SDK version: azureml-core==1.38.0.post2 azureml-dataprep==2.27.0. Session id: 9ada353f-1446-4c1a-8a2f-aadca9f209d8. Run id: 5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95.\n",
      "[2022-02-28T19:41:14.137] Processing 'sekurit_batch'.\n",
      "[2022-02-28T19:41:14.137] Mode: 'mount'.\n",
      "[2022-02-28T19:41:14.137] Path on compute is specified: 'False'.\n",
      "[2022-02-28T19:41:17.344] Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('sekuritdatastore', 'batch-data/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"3c1b51f8-29e2-4bd3-b604-6f2e5348bf47\",\n",
      "    \"name\": \"batch-data\",\n",
      "    \"version\": 2,\n",
      "    \"description\": \"batch data\",\n",
      "    \"workspace\": \"Workspace.create(name='aml_ws', subscription_id='8f35cf98-68ff-457e-b1b3-e05921a0fd46', resource_group='rg-lr-dp100')\"\n",
      "  }\n",
      "}\n",
      "[2022-02-28T19:41:19.686] Mounting sekurit_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sekurit_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47 as folder.\n",
      "[2022-02-28T19:41:19.686] Processing 'inferences'.\n",
      "[2022-02-28T19:41:19.686] Mode: 'mount'.\n",
      "[2022-02-28T19:41:19.686] Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_sekuritdatastore'.\n",
      "[2022-02-28T19:41:19.791] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_sekuritdatastore\n",
      "[2022-02-28T19:41:19.791] Output is not a single file\n",
      "[2022-02-28T19:41:19.791] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_sekuritdatastore as folder\n",
      "[2022-02-28T19:41:20.287] Mounting sekurit_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sekurit_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47.\n",
      "[2022-02-28T19:41:21.288] Mounted sekurit_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sekurit_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47.\n",
      "[2022-02-28T19:41:21.288] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_sekuritdatastore.\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.22.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('azure-core<1.22')).\n",
      "[2022-02-28T19:41:26.386] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_sekuritdatastore.\n",
      "[2022-02-28T19:41:26.418] Exit __enter__ of DatasetContextManager\n",
      "uri entered in sidecar: None\n",
      "Set Dataset sekurit_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sekurit_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47\n",
      "Set OutputDataset inferences's target path to /mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_sekuritdatastore\n",
      "[2022-02-28T19:41:26.419577] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2022-02-28T19:41:27.270827] Ran Sidecar prep cmd.\n",
      "[2022-02-28T19:41:27.270925] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2022/02/28 19:42:30 Didn't get JobInfoJson from env, now read from file\n",
      "2022/02/28 19:42:30 Suceeded read JobInfoJson from file\n",
      "2022/02/28 19:42:30 Starting App Insight Logger for task:  runTaskLet\n",
      "2022/02/28 19:42:30 Version: 3.0.01867.0001 Branch: .SourceBranch Commit: 925d6a4\n",
      "2022/02/28 19:42:30 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "2022/02/28 19:42:30 Send process info logs to master server succeeded\n",
      "2022/02/28 19:42:30 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "2022/02/28 19:42:30 Send process info logs to master server succeeded\n",
      "[2022-02-28T19:42:30.225676] Entering context manager injector.\n",
      "[2022-02-28T19:42:30.953709] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.38.0', '--scoring_module_name', 'batch_sekurit.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'sekurit_batch'])\n",
      "Script type = None\n",
      "[2022-02-28T19:42:30.959122] Entering Run History Context Manager.\n",
      "[2022-02-28T19:42:31.882474] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95\n",
      "[2022-02-28T19:42:31.882525] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.38.0', '--scoring_module_name', 'batch_sekurit.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$inferences', '--input_fds_0', 'sekurit_batch']\n",
      "[2022-02-28T19:42:31.882557] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.38.0', '--scoring_module_name', 'batch_sekurit.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_sekuritdatastore', '--input_fds_0', 'sekurit_batch']\n",
      "\n",
      "2022/02/28 19:42:35 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[2022-02-28T19:43:33.301595] The experiment failed. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "3 items cleaning up...\n",
      "Cleanup took 0.24070072174072266 seconds\n",
      "azureml_common.parallel_run.exception_info.Exception: Run failed. Below is the error detail:\n",
      "EntryScriptException: Entry script error. The number of failed items is 100, which exceeds error threshold 10.\n",
      "The run() function in the entry script had raised exception for 60 times. Please check logs at logs/user/error/* for details.\n",
      "  * Error 'Input contains NaN, infinity or a value too large for dtype('float64').' occurred 60 times.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"driver/amlbi_main.py\", line 174, in <module>\n",
      "    main()\n",
      "  File \"driver/amlbi_main.py\", line 123, in main\n",
      "    boot(driver_dir)\n",
      "  File \"driver/amlbi_main.py\", line 58, in boot\n",
      "    booter.start()\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 372, in start\n",
      "    self.start_sys_main()\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 260, in start_sys_main\n",
      "    self.run_sys_main(cmd)\n",
      "  File \"driver/azureml_user/parallel_run/boot_simulator.py\", line 40, in run_sys_main\n",
      "    self.run(cmd)\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 201, in run\n",
      "    self.check_run_result(proc=proc, stdout=stdout, stderr=stderr)\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 211, in check_run_result\n",
      "    BootResult().check_result(stdout)\n",
      "  File \"driver/azureml_user/parallel_run/boot_result.py\", line 36, in check_result\n",
      "    raise Exception(message) from cause\n",
      "Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\n",
      "\n",
      "[2022-02-28T19:43:33.696955] Finished context manager injector with Exception.\n",
      "2022/02/28 19:43:34 Skipping parsing control script error. Reason: Error json file doesn't exist. This most likely means that no errors were written to the file. File path: /mnt/batch/tasks/workitems/f425bbc3-2c29-48d2-b057-d61b2fc6cbfe/job-1/5e5e0bc7-d9a7-4195-9_4b3cb51c-e4ae-40de-ae07-f28e27295e69/wd/runTaskLetTask_error.json\n",
      "2022/02/28 19:43:34 Wrapper cmd failed with err: exit status 1\n",
      "2022/02/28 19:43:34 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "2022/02/28 19:43:34 Send process info logs to master server succeeded\n",
      "2022/02/28 19:43:34 mpirun version string: {\n",
      "mpirun (Open MPI) 3.1.2\n",
      "\n",
      "Report bugs to http://www.open-mpi.org/community/help/\n",
      "}\n",
      "2022/02/28 19:43:34 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 2\n",
      "FilteredData: 0.\n",
      "2022/02/28 19:43:34 Process Exiting with Code:  1\n",
      "2022/02/28 19:43:35 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_70e4add24c65bf530f9c4ed9ed5a8cf9b15facfc5b2124ce2243c82c68897141_d.txt\n",
      "===============================================================================================================\n",
      "[2022-02-28T19:43:37.965145] Entering job release\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.22.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('azure-core<1.22')).\n",
      "[2022-02-28T19:43:38.965565] Starting job release\n",
      "[2022-02-28T19:43:38.966519] job release stage : upload_datastore starting...\n",
      "[2022-02-28T19:43:38.966044] Logging experiment finalizing status in history service.\n",
      "[2022-02-28T19:43:38.970265] job release stage : start importing azureml.history._tracking in run_history_release.Starting the daemon thread to refresh tokens in background for process with pid = 323\n",
      "[2022-02-28T19:43:38.971190] Entering context manager injector.[2022-02-28T19:43:38.971386] job release stage : copy_batchai_cached_logs starting...\n",
      "[2022-02-28T19:43:38.971508] job release stage : execute_job_release starting...\n",
      "\n",
      "\n",
      "[2022-02-28T19:43:38.972011] job release stage : copy_batchai_cached_logs completed...\n",
      "[2022-02-28T19:43:38.989581] job release stage : upload_datastore completed...\n",
      "[2022-02-28T19:43:39.061904] job release stage : send_run_telemetry starting...\n",
      "[2022-02-28T19:43:39.095015] get vm size and vm region successfully.\n",
      "[2022-02-28T19:43:39.110282] get compute meta data successfully.\n",
      "[2022-02-28T19:43:39.271762] job release stage : execute_job_release completed...\n",
      "[2022-02-28T19:43:39.373951] post artifact meta request successfully.\n",
      "[2022-02-28T19:43:39.423565] upload compute record artifact successfully.\n",
      "[2022-02-28T19:43:39.423668] job release stage : send_run_telemetry completed...\n",
      "[2022-02-28T19:43:39.424189] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2022-02-28T19:43:39.424456] Running Sidecar release cmd...\n",
      "[2022-02-28T19:43:39.437452] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95\n",
      "[2022-02-28T19:43:39.459] Enter __exit__ of DatasetContextManager\n",
      "[2022-02-28T19:43:39.459] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sekurit_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47.\n",
      "[2022-02-28T19:43:40.468] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sekurit_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47.\n",
      "[2022-02-28T19:43:40.468] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_sekuritdatastore.\n",
      "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_sekuritdatastore: Invalid argument\n",
      "[2022-02-28T19:43:40.486] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_sekuritdatastore.\n",
      "[2022-02-28T19:43:40.486] Exit __exit__ of DatasetContextManager\n",
      "[2022-02-28T19:43:40.486683] Removing absolute paths from host...\n",
      "[2022-02-28T19:43:40.487010] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2022-02-28T19:43:41.456872] Ran Sidecar release cmd.\n",
      "[2022-02-28T19:43:41.456987] Job release is complete\n",
      "\n",
      "StepRun(batch-score-sekurit) Execution Summary\n",
      "===============================================\n",
      "StepRun( batch-score-sekurit ) Status: Failed\n",
      "\n",
      "Warnings:\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": \"UserError\",\n",
      "    \"severity\": null,\n",
      "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n",
      "    \"messageFormat\": \"{Message}\",\n",
      "    \"messageParameters\": {\n",
      "      \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n",
      "    },\n",
      "    \"referenceCode\": null,\n",
      "    \"detailsUri\": null,\n",
      "    \"target\": null,\n",
      "    \"details\": [],\n",
      "    \"innerError\": {\n",
      "      \"code\": \"UserTrainingScriptFailed\",\n",
      "      \"innerError\": null\n",
      "    },\n",
      "    \"debugInfo\": null,\n",
      "    \"additionalInfo\": null\n",
      "  },\n",
      "  \"correlation\": {\n",
      "    \"operation\": \"0a24e9f9fb93f2b787f1d79f14ed689a\",\n",
      "    \"request\": \"28e50c6397e7c336\"\n",
      "  },\n",
      "  \"environment\": \"southeastasia\",\n",
      "  \"location\": \"southeastasia\",\n",
      "  \"time\": \"2022-02-28T19:43:56.5612933+00:00\",\n",
      "  \"componentName\": \"globaljobdispatcher\"\n",
      "}\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-af045af2bc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparallelrun_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipeline_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sekurit-batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    294\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0;32m--> 296\u001b[0;31m                                                              raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    297\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                                 \u001b[0;31m# If there are package conflicts in the user's environment, the run rehydration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0;32m--> 738\u001b[0;31m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "pipeline_run = Experiment(ws, 'sekurit-batch').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a377a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': '8601ef27-fb7d-4aa7-8249-1d3e4e271614',\n",
       " 'status': 'Failed',\n",
       " 'startTimeUtc': '2022-02-28T19:36:18.677084Z',\n",
       " 'endTimeUtc': '2022-02-28T19:43:57.832064Z',\n",
       " 'services': {},\n",
       " 'properties': {'azureml.runsource': 'azureml.PipelineRun',\n",
       "  'runSource': 'SDK',\n",
       "  'runType': 'SDK',\n",
       "  'azureml.parameters': '{}',\n",
       "  'azureml.continue_on_step_failure': 'False',\n",
       "  'azureml.pipelineComponent': 'pipelinerun'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.8601ef27-fb7d-4aa7-8249-1d3e4e271614/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=S2w%2Bi4l6xg%2BioAkTV3AMrWAbUXIdUJ6EHxs%2FJfca4n0%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-28T14%3A18%3A45Z&ske=2022-03-01T22%3A28%3A45Z&sks=b&skv=2019-07-07&st=2022-02-28T19%3A45%3A13Z&se=2022-03-01T03%3A55%3A13Z&sp=r',\n",
       "  'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.8601ef27-fb7d-4aa7-8249-1d3e4e271614/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=HIhnbL0BsAOloioorCoxgkEbXPH5epOfaSwYdZsUaFI%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-28T14%3A18%3A45Z&ske=2022-03-01T22%3A28%3A45Z&sks=b&skv=2019-07-07&st=2022-02-28T19%3A45%3A13Z&se=2022-03-01T03%3A55%3A13Z&sp=r',\n",
       "  'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.8601ef27-fb7d-4aa7-8249-1d3e4e271614/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=2XURE4wHpz1VDQeXVg2wkVCtVdC4n8qSHvP2T43f2UA%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-28T14%3A18%3A45Z&ske=2022-03-01T22%3A28%3A45Z&sks=b&skv=2019-07-07&st=2022-02-28T19%3A45%3A13Z&se=2022-03-01T03%3A55%3A13Z&sp=r'},\n",
       " 'submittedBy': 'Lalitha Raghavan'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775e3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c3aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa35560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b33c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AUTOML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50521f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "compute_name = 'computeclusterlr'\n",
    "training_cluster = ComputeTarget(workspace=ws, name=compute_name)\n",
    "\n",
    "aml_run_config = RunConfiguration()\n",
    "# Use just-specified compute target (\"cpu-cluster\")\n",
    "aml_run_config.target = training_cluster\n",
    "\n",
    "# Specify CondaDependencies obj, add necessary packages\n",
    "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn'], \n",
    "    pip_packages=['azureml-sdk[automl]', 'pyarrow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e99609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name='sekuritdataset')\n",
    "data = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7816e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Length</th>\n",
       "      <th>Type</th>\n",
       "      <th>Style</th>\n",
       "      <th>OEM</th>\n",
       "      <th>Engine Disp</th>\n",
       "      <th>Age of OEM</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Oil Price</th>\n",
       "      <th>Petrol</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Column17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Jan-14</td>\n",
       "      <td>16</td>\n",
       "      <td>102.10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1,207</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Feb-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.83</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>882</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mar-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.04</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>839</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Apr-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.87</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>547</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>May-14</td>\n",
       "      <td>16</td>\n",
       "      <td>105.71</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>571</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Length             Type      Style   OEM  Engine Disp  \\\n",
       "0  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "1  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "2  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "3  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "4  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "\n",
       "   Age of OEM    Year  Mileage  Oil Price  Petrol  Automatic  Price  Sales  \\\n",
       "0           8  Jan-14       16     102.10    True      False    5.0  1,207   \n",
       "1           8  Feb-14       16     104.83    True      False    5.0    882   \n",
       "2           8  Mar-14       16     104.04    True      False    5.0    839   \n",
       "3           8  Apr-14       16     104.87    True      False    5.0    547   \n",
       "4           8  May-14       16     105.71    True      False    5.0    571   \n",
       "\n",
       "  Column17  \n",
       "0     None  \n",
       "1     None  \n",
       "2     None  \n",
       "3     None  \n",
       "4     None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9367d17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl_sekurit_pipeline-v4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'automl_sekurit_pipeline-v4'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "515cec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sekurit_pipeline/dataprep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/dataprep.py\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
    "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
    "args = parser.parse_args()\n",
    "save_folder = args.prepped_data\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "data= run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# Drop unnecessary columns and other cleaning steps\n",
    "data=data.drop(['Column17','Year'],axis=1)\n",
    "\n",
    "data['Sales']=pd.to_numeric(data['Sales'],errors='coerce')\n",
    "data= data[data['Sales'].notna()]\n",
    "data = data.drop(data[data.Sales < 0].index)\n",
    "\n",
    "# Label Encoding\n",
    "list_of_columns = ['Model','Type','Style','OEM']\n",
    "data[list_of_columns] = data[list_of_columns].apply(lambda col:pd.Categorical(col).codes)\n",
    "\n",
    "# Boolean Encoding\n",
    "data[[\"Petrol\", \"Automatic\"]] *= 1\n",
    "\n",
    "# Normalize the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['Length','Engine Disp','Age of OEM','Mileage','Oil Price','Price']\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "\n",
    "# Log processed rows\n",
    "row_count = (len(data))\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "\n",
    "# Save the prepped data  **** AutoML is automatically taking csv files as strings. Best to convert to Parquet\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder,'prepped_data.parquet')\n",
    "data.to_parquet(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9be35959",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_cluster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6e3886c5dd22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                 arguments = ['--input-data', sekurit_ds.as_named_input('raw_data'),\n\u001b[1;32m     16\u001b[0m                                              '--prepped-data', prepped_data],\n\u001b[0;32m---> 17\u001b[0;31m                                 \u001b[0mcompute_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_cluster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                                 \u001b[0mrunconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maml_run_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                 allow_reuse = True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_cluster' is not defined"
     ]
    }
   ],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "\n",
    "# Get the training dataset\n",
    "sekurit_ds = ws.datasets.get(\"sekuritdataset\")\n",
    "\n",
    "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
    "prepped_data = OutputFileDatasetConfig(\"prepped_data\").read_parquet_files()\n",
    "\n",
    "# Step 1, Run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"dataprep.py\",\n",
    "                                arguments = ['--input-data', sekurit_ds.as_named_input('raw_data'),\n",
    "                                             '--prepped-data', prepped_data],\n",
    "                                compute_target = training_cluster,\n",
    "                                runconfig = aml_run_config,\n",
    "                                allow_reuse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fff074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepped_data = prepped_data.read_delimited_files()   ### You don't need this if reading from Parquet. For CSV you need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7c12b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman_correlation\n",
      "r2_score\n",
      "normalized_mean_absolute_error\n",
      "normalized_root_mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "import azureml.train.automl.utilities as automl_utils\n",
    "\n",
    "for metric in automl_utils.get_primary_metrics('regression'):\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06f248a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import TrainingOutput, PipelineData\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                            datastore=default_ds,\n",
    "                            pipeline_output_name='metrics_output',\n",
    "                            training_output=TrainingOutput(type='Metrics'))\n",
    "\n",
    "model_data = PipelineData(name='best_model_data',\n",
    "                          datastore=default_ds,\n",
    "                          pipeline_output_name='model_output',\n",
    "                          training_output=TrainingOutput(type='Model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562e42a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for Auto ML run.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 10,\n",
    "    \"experiment_timeout_hours\": 0.25,\n",
    "    \"enable_early_stopping\": True,\n",
    "    \"primary_metric\": 'normalized_root_mean_squared_error',\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"n_cross_validations\": 2\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(name='Automated ML Experiment',\n",
    "                             task='regression',\n",
    "                             debug_log='automated_ml_errors.log',\n",
    "                             compute_target=training_cluster,\n",
    "                             training_data = prepped_data,\n",
    "                             label_column_name=\"Sales\",\n",
    "                             **automl_settings)\n",
    "\n",
    "train_step = AutoMLStep(name='AutoML_Regression',\n",
    "    automl_config=automl_config,\n",
    "    passthru_automl_config=False,\n",
    "    outputs=[metrics_data,model_data],\n",
    "    enable_default_model_output=False,\n",
    "    enable_default_metrics_output=False,\n",
    "    allow_reuse=True)\n",
    "\n",
    "\n",
    "print(\"Ready for Auto ML run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9e9ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing $experiment_folder/register_model.py\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '$experiment_folder/register_model.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10339/437428965.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'$experiment_folder/register_model.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from azureml.core.model import Model, Dataset\\nfrom azureml.core.run import Run, _OfflineRun\\nfrom azureml.core import Workspace\\nimport argparse\\n\\nparser = argparse.ArgumentParser()\\nparser.add_argument(\"--model_name\", required=True)\\nparser.add_argument(\"--model_path\", required=True)\\nargs = parser.parse_args()\\n\\nprint(f\"model_name : {args.model_name}\")\\nprint(f\"model_path: {args.model_path}\")\\n\\nrun = Run.get_context()\\nws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\\n\\nmodel = Model.register(workspace=ws,\\n                       model_path=args.model_path,\\n                       model_name=args.model_name)\\n\\nprint(\"Registered version {0} of model {1}\".format(model.version, model.name))\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-98>\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '$experiment_folder/register_model.py'"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/register_model.py\n",
    "from azureml.core.model import Model, Dataset\n",
    "from azureml.core.run import Run, _OfflineRun\n",
    "from azureml.core import Workspace\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_name\", required=True)\n",
    "parser.add_argument(\"--model_path\", required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(f\"model_name : {args.model_name}\")\n",
    "print(f\"model_path: {args.model_path}\")\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_path=args.model_path,\n",
    "                       model_name=args.model_name)\n",
    "\n",
    "print(\"Registered version {0} of model {1}\".format(model.version, model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c125b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "# The model name with which to register the trained model in the workspace.\n",
    "model_name = PipelineParameter(\"model_name\", default_value=\"sekurit_model_v4\")\n",
    "\n",
    "register_step = PythonScriptStep(script_name=\"register_model.py\",\n",
    "                                 source_directory = experiment_folder,\n",
    "                                       name=\"register_model\",\n",
    "                                       allow_reuse=False,\n",
    "                                       arguments=[\"--model_name\", model_name, \"--model_path\", model_data],\n",
    "                                       inputs=[model_data],\n",
    "                                       compute_target=training_cluster,\n",
    "                                       runconfig=aml_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11cbc926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Prepare Data [fbd7120a][67ff3b5f-27f4-4b77-952c-dd8baf0ccd93], (This step will run and generate new outputs)Created step AutoML_Regression [431cd644][47a24634-fc8a-4fed-af9b-dc7bb0e6459d], (This step will run and generate new outputs)\n",
      "Created step register_model [c9e4e482][42c9db6c-a00e-49c2-944a-f0c7973db919], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun 9c29cc9e-7050-4749-af14-ed125a9373c1\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9c29cc9e-7050-4749-af14-ed125a9373c1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a4368c463a4345ad5397b50b14aa67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/9c29cc9e-7050-4749-af14-ed125a9373c1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\", \"run_id\": \"9c29cc9e-7050-4749-af14-ed125a9373c1\", \"run_properties\": {\"run_id\": \"9c29cc9e-7050-4749-af14-ed125a9373c1\", \"created_utc\": \"2022-02-23T19:28:58.603341Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{\\\"model_name\\\":\\\"sekurit_model_v4\\\"}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2022-02-23T19:58:44.506458Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=6LTRqP10BxeabEgM8iXZ%2BTC2bLuYFQJ%2F9QbtJCjH%2FHk%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A25Z&se=2022-02-24T04%3A53%3A25Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=yyMOp94IXb5DFGNmnybkuSAxJlaWEZ7HMy9X8xN3IRo%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A25Z&se=2022-02-24T04%3A53%3A25Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=HOzwJvlKc79UTbPsKD2VLQnet9UNBchh7vDCwFxHJXw%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A25Z&se=2022-02-24T04%3A53%3A25Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:29:45\", \"run_number\": \"1645644538\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"ae1c9977-3df9-42d6-8f38-63934b887388\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:30:56.078463Z\", \"created_time\": \"2022-02-23T19:29:01.971491Z\", \"end_time\": \"2022-02-23T19:32:40.865188Z\", \"duration\": \"0:03:38\", \"run_number\": 1645644541, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:29:01.971491Z\", \"is_reused\": \"\"}, {\"run_id\": \"60c326d6-9daa-4c00-96bd-4dbd0a9368a6\", \"name\": \"AutoML_Regression\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:32:59.439555Z\", \"created_time\": \"2022-02-23T19:32:42.482599Z\", \"end_time\": \"2022-02-23T19:56:19.792708Z\", \"duration\": \"0:23:37\", \"run_number\": 1645644762, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:32:42.482599Z\", \"is_reused\": \"\"}, {\"run_id\": \"80e3180f-800c-442c-b07e-2a38912cabb1\", \"name\": \"register_model\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:58:33.284063Z\", \"created_time\": \"2022-02-23T19:56:33.885332Z\", \"end_time\": \"2022-02-23T19:58:43.309692Z\", \"duration\": \"0:02:09\", \"run_number\": 1645646193, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:56:33.885332Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"452580cc\": {\"node_id\": \"452580cc\", \"name\": \"sekuritdataset\"}}, \"module_nodes\": {\"fbd7120a\": {\"node_id\": \"fbd7120a\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"ae1c9977-3df9-42d6-8f38-63934b887388\"}, \"431cd644\": {\"node_id\": \"431cd644\", \"name\": \"AutoML_Regression\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"60c326d6-9daa-4c00-96bd-4dbd0a9368a6\"}, \"c9e4e482\": {\"node_id\": \"c9e4e482\", \"name\": \"register_model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"80e3180f-800c-442c-b07e-2a38912cabb1\"}}, \"edges\": [{\"source_node_id\": \"452580cc\", \"source_node_name\": \"sekuritdataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"fbd7120a\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"fbd7120a\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"training_data\", \"dst_node_id\": \"431cd644\", \"dst_node_name\": \"AutoML_Regression\"}, {\"source_node_id\": \"431cd644\", \"source_node_name\": \"AutoML_Regression\", \"source_name\": \"metrics_data\", \"target_name\": \"best_model_data\", \"dst_node_id\": \"c9e4e482\", \"dst_node_name\": \"register_model\"}], \"child_runs\": [{\"run_id\": \"ae1c9977-3df9-42d6-8f38-63934b887388\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:30:56.078463Z\", \"created_time\": \"2022-02-23T19:29:01.971491Z\", \"end_time\": \"2022-02-23T19:32:40.865188Z\", \"duration\": \"0:03:38\", \"run_number\": 1645644541, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:29:01.971491Z\", \"is_reused\": \"\"}, {\"run_id\": \"60c326d6-9daa-4c00-96bd-4dbd0a9368a6\", \"name\": \"AutoML_Regression\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:32:59.439555Z\", \"created_time\": \"2022-02-23T19:32:42.482599Z\", \"end_time\": \"2022-02-23T19:56:19.792708Z\", \"duration\": \"0:23:37\", \"run_number\": 1645644762, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:32:42.482599Z\", \"is_reused\": \"\"}, {\"run_id\": \"80e3180f-800c-442c-b07e-2a38912cabb1\", \"name\": \"register_model\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:58:33.284063Z\", \"created_time\": \"2022-02-23T19:56:33.885332Z\", \"end_time\": \"2022-02-23T19:58:43.309692Z\", \"duration\": \"0:02:09\", \"run_number\": 1645646193, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:56:33.885332Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.37.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 9c29cc9e-7050-4749-af14-ed125a9373c1\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9c29cc9e-7050-4749-af14-ed125a9373c1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: ae1c9977-3df9-42d6-8f38-63934b887388\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ae1c9977-3df9-42d6-8f38-63934b887388?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "StepRun( Prepare Data ) Status: NotStarted\n",
      "StepRun( Prepare Data ) Status: Running\n",
      "\n",
      "StepRun(Prepare Data) Execution Summary\n",
      "========================================\n",
      "StepRun( Prepare Data ) Status: Finished\n",
      "{'runId': 'ae1c9977-3df9-42d6-8f38-63934b887388', 'target': 'computeclusterlr', 'status': 'Completed', 'startTimeUtc': '2022-02-23T19:30:56.078463Z', 'endTimeUtc': '2022-02-23T19:32:40.865188Z', 'services': {}, 'properties': {'ContentSnapshotId': '9b334f38-6012-4c80-a8b8-eb681b984678', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '67ff3b5f-27f4-4b77-952c-dd8baf0ccd93', 'azureml.moduleName': 'Prepare Data', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'fbd7120a', 'azureml.pipelinerunid': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipeline': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '6c4883fa-1f48-4ea1-a6d5-5fecfeedddd5'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': '7887285a-614a-4887-a824-6eb1e005cbc2'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'prepped_data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('sekuritdatastore', 'dataset/ae1c9977-3df9-42d6-8f38-63934b887388/prepped_data/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ReadParquetFile\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"7887285a-614a-4887-a824-6eb1e005cbc2\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='aml_ws', subscription_id='8f35cf98-68ff-457e-b1b3-e05921a0fd46', resource_group='rg-lr-dp100')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'dataprep.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', 'DatasetOutputConfig:prepped_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'computeclusterlr', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '6c4883fa-1f48-4ea1-a6d5-5fecfeedddd5', 'name': None, 'version': '3'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'prepped_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'sekuritdatastore', 'relativePath': None}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipelineRun.moduleNodeId': 'fbd7120a', 'azureml.pipelineRun.outputPortName': 'prepped_data'}, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"c18a1f66-4f50-4fe2-a024-5a8c419ade7b\",\\n      \"type\": \"Microsoft.DPrep.ReadParquetFileBlock\",\\n      \"arguments\": {\\n        \"preview\": false\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"aefbe3c9-c2ec-4042-b783-d537d937148e\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Experiment automl_sekurit_pipeline_v4 Environment', 'version': 'Autosave_2022-02-23T19:29:07Z_0cc69d3f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk[automl]~=1.37.0', 'pyarrow']}, 'pandas', 'scikit-learn'], 'name': 'azureml_0a58f5ea93884f5ab17d28fa937b0355'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211124.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/backgroundProcess.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=0t%2FM%2BaETvTf90TIslYIfpgLoWXVg5vS2Ns0ZpUUpWjs%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=2JdVW0%2BOIoA2DnvoT2BGDi%2FXVZAQRjkLj1km59LmEAc%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r', 'logs/azureml/dataprep/rslex.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/dataprep/rslex.log?sv=2019-07-07&sr=b&sig=9D%2BSZq36QffHrhvvnBDrx9FLfj5gUMBwcDC1H1P3COE%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=4PiV3vZlIpsiK7FGFR4Gober3gdFAm8%2FE9sBGzlr858%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=yJicceiuqRPpOfh8T3Hook867APs1dIbowXtrzyZ0iw%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=0sG59WZHdRuK5HSp1JaOhlOyo05Lkv%2BIMFUmv%2BYD%2BJY%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 60c326d6-9daa-4c00-96bd-4dbd0a9368a6\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/60c326d6-9daa-4c00-96bd-4dbd0a9368a6?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "StepRun( AutoML_Regression ) Status: Running\n",
      "\n",
      "StepRun(AutoML_Regression) Execution Summary\n",
      "=============================================\n",
      "StepRun( AutoML_Regression ) Status: Finished\n",
      "\n",
      "Warnings:\n",
      "Experiment timeout reached, hence experiment stopped. Current experiment timeout: 0 hour(s) 15 minute(s)\n",
      "{'runId': '60c326d6-9daa-4c00-96bd-4dbd0a9368a6', 'target': 'computeclusterlr', 'status': 'Completed', 'startTimeUtc': '2022-02-23T19:32:59.439555Z', 'endTimeUtc': '2022-02-23T19:56:19.792708Z', 'services': {}, 'warnings': [{'source': 'JasmineService', 'message': 'Experiment timeout reached, hence experiment stopped. Current experiment timeout: 0 hour(s) 15 minute(s)'}], 'properties': {'ContentSnapshotId': 'c3e131f1-d1e0-418e-be2f-41b329ada010', 'StepType': 'AutoMLStep', 'azureml.moduleid': '47a24634-fc8a-4fed-af9b-dc7bb0e6459d', 'azureml.moduleName': 'AutoML_Regression', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '431cd644', 'azureml.pipelinerunid': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipeline': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipelineComponent': 'masterautomlcloud', 'num_iterations': '1000', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'metrics': 'accuracy', 'primary_metric': 'normalized_root_mean_squared_error', 'train_split': '0', 'MaxTimeSeconds': '600', 'acquisition_parameter': '0', 'num_cross_validation': '2', 'target': 'computeclusterlr', 'RawAMLSettingsString': None, 'AMLSettingsJsonString': '{\"path\": null, \"name\": \"Automated ML Experiment\", \"subscription_id\": \"8f35cf98-68ff-457e-b1b3-e05921a0fd46\", \"resource_group\": \"rg-lr-dp100\", \"workspace_name\": \"aml_ws\", \"region\": \"southeastasia\", \"compute_target\": \"computeclusterlr\", \"spark_service\": null, \"azure_service\": null, \"many_models\": false, \"pipeline_fetch_max_batch_size\": 1, \"enable_batch_run\": false, \"enable_run_restructure\": false, \"start_auxiliary_runs_before_parent_complete\": false, \"enable_code_generation\": false, \"iterations\": 1000, \"primary_metric\": \"normalized_root_mean_squared_error\", \"task_type\": \"regression\", \"positive_label\": null, \"data_script\": null, \"test_size\": 0.0, \"test_include_predictions_only\": false, \"validation_size\": 0.0, \"n_cross_validations\": 2, \"y_min\": null, \"y_max\": null, \"num_classes\": null, \"featurization\": \"auto\", \"_ignore_package_version_incompatibilities\": false, \"is_timeseries\": false, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 1, \"iteration_timeout_minutes\": 10, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": 15, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": null, \"supported_models\": [\"ElasticNet\", \"XGBoostRegressor\", \"TensorFlowDNN\", \"KNN\", \"RandomForest\", \"TensorFlowLinearRegressor\", \"FastLinearRegressor\", \"SGD\", \"LightGBM\", \"OnlineGradientDescentRegressor\", \"ExtremeRandomTrees\", \"DecisionTree\", \"LassoLars\", \"GradientBoosting\"], \"private_models\": [\"TabnetRegressor\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"_debug_log\": \"automated_ml_errors.log\", \"show_warnings\": false, \"model_explainability\": true, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": false, \"enable_split_onnx_featurizer_estimator_models\": false, \"vm_type\": \"STANDARD_DS11_V2\", \"telemetry_verbosity\": 20, \"send_telemetry\": true, \"enable_dnn\": false, \"scenario\": \"SDK-1.13.0\", \"environment_label\": null, \"save_mlflow\": false, \"enable_categorical_indicators\": false, \"force_text_dnn\": false, \"enable_feature_sweeping\": true, \"enable_early_stopping\": true, \"early_stopping_n_iters\": 10, \"arguments\": null, \"dataset_id\": null, \"hyperdrive_config\": null, \"validation_dataset_id\": null, \"run_source\": null, \"metrics\": null, \"enable_metric_confidence\": false, \"enable_ensembling\": true, \"enable_stack_ensembling\": true, \"ensemble_iterations\": 15, \"enable_tf\": false, \"enable_subsampling\": null, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"force_streaming\": false, \"track_child_runs\": true, \"allowed_private_models\": [], \"label_column_name\": \"Sales\", \"weight_column_name\": null, \"cv_split_column_names\": null, \"enable_local_managed\": false, \"_local_managed_run_id\": null, \"cost_mode\": 1, \"lag_length\": 0, \"metric_operation\": \"minimize\", \"preprocess\": true}', 'DataPrepJsonString': '{\\\\\"training_data\\\\\":\\\\\"{\\\\\\\\n  \\\\\\\\\\\\\"blocks\\\\\\\\\\\\\": [\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"a20ec14e-9112-47e7-b4c1-3e8f71e27a8e\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.GetDatastoreFilesBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"datastores\\\\\\\\\\\\\": [\\\\\\\\n          {\\\\\\\\n            \\\\\\\\\\\\\"datastoreName\\\\\\\\\\\\\": \\\\\\\\\\\\\"sekuritdatastore\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"path\\\\\\\\\\\\\": \\\\\\\\\\\\\"dataset/ae1c9977-3df9-42d6-8f38-63934b887388/prepped_data/\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"resourceGroup\\\\\\\\\\\\\": \\\\\\\\\\\\\"rg-lr-dp100\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"subscription\\\\\\\\\\\\\": \\\\\\\\\\\\\"8f35cf98-68ff-457e-b1b3-e05921a0fd46\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"workspaceName\\\\\\\\\\\\\": \\\\\\\\\\\\\"aml_ws\\\\\\\\\\\\\"\\\\\\\\n          }\\\\\\\\n        ]\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"c18a1f66-4f50-4fe2-a024-5a8c419ade7b\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.ReadParquetFileBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"preview\\\\\\\\\\\\\": false\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"aefbe3c9-c2ec-4042-b783-d537d937148e\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.DropColumnsBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"columns\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\"type\\\\\\\\\\\\\": 0,\\\\\\\\n          \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\n            \\\\\\\\\\\\\"selectedColumns\\\\\\\\\\\\\": [\\\\\\\\n              \\\\\\\\\\\\\"Path\\\\\\\\\\\\\"\\\\\\\\n            ]\\\\\\\\n          }\\\\\\\\n        }\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    }\\\\\\\\n  ],\\\\\\\\n  \\\\\\\\\\\\\"inspectors\\\\\\\\\\\\\": [],\\\\\\\\n  \\\\\\\\\\\\\"meta\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\"savedDatasetId\\\\\\\\\\\\\": \\\\\\\\\\\\\"8421780e-d588-4160-ac76-36abda9a7061\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"datasetType\\\\\\\\\\\\\": \\\\\\\\\\\\\"tabular\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"subscriptionId\\\\\\\\\\\\\": \\\\\\\\\\\\\"8f35cf98-68ff-457e-b1b3-e05921a0fd46\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"workspaceId\\\\\\\\\\\\\": \\\\\\\\\\\\\"57a0fe81-1934-4a22-8898-5e401a74b8ea\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"workspaceLocation\\\\\\\\\\\\\": \\\\\\\\\\\\\"southeastasia\\\\\\\\\\\\\"\\\\\\\\n  }\\\\\\\\n}\\\\\",\\\\\"activities\\\\\":\\\\\"0\\\\\"}', 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'Orchestrator': 'automl', 'ClientType': 'Others', '_aml_system_scenario_identification': 'Remote.Parent', 'root_attribution': 'azureml.StepRun', 'snapshotId': 'c3e131f1-d1e0-418e-be2f-41b329ada010', 'SetupRunId': '60c326d6-9daa-4c00-96bd-4dbd0a9368a6_setup', 'SetupRunContainerId': 'dcid.60c326d6-9daa-4c00-96bd-4dbd0a9368a6_setup', 'ClientSdkVersion': '1.38.0', 'FeaturizationRunJsonPath': 'featurizer_container.json', 'FeaturizationRunId': '60c326d6-9daa-4c00-96bd-4dbd0a9368a6_featurize', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"has_extra_col\": true, \"dataset_classes\": 395, \"dataset_features\": 54, \"dataset_samples\": 1151, \"single_frequency_class_detected\": false}', 'ModelExplainRunId': '60c326d6-9daa-4c00-96bd-4dbd0a9368a6_ModelExplain'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.60c326d6-9daa-4c00-96bd-4dbd0a9368a6/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=jIacsDikGArUTgEYoufgdAlnRa5Ym33vxcwTS7QZNVs%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A42%3A50Z&se=2022-02-24T03%3A52%3A50Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.60c326d6-9daa-4c00-96bd-4dbd0a9368a6/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=xis0QXl8ZJHfPS8j9AbFiff4nzC2KZ7p81zcnQ9zcqo%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A42%3A50Z&se=2022-02-24T03%3A52%3A50Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.60c326d6-9daa-4c00-96bd-4dbd0a9368a6/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=wPhmLjCgPuBbE3%2FMWcFTTecLA1l2WIJS8811PJVpnZk%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A42%3A50Z&se=2022-02-24T03%3A52%3A50Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 80e3180f-800c-442c-b07e-2a38912cabb1\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/80e3180f-800c-442c-b07e-2a38912cabb1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "StepRun( register_model ) Status: Running\n",
      "\n",
      "StepRun(register_model) Execution Summary\n",
      "==========================================\n",
      "StepRun( register_model ) Status: Finished\n",
      "{'runId': '80e3180f-800c-442c-b07e-2a38912cabb1', 'target': 'computeclusterlr', 'status': 'Completed', 'startTimeUtc': '2022-02-23T19:58:33.284063Z', 'endTimeUtc': '2022-02-23T19:58:43.309692Z', 'services': {}, 'properties': {'ContentSnapshotId': '83941250-e2e4-47b2-894e-5dc296355ad5', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '42c9db6c-a00e-49c2-944a-f0c7973db919', 'azureml.moduleName': 'register_model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'c9e4e482', 'azureml.pipelinerunid': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipeline': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'register_model.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', '$AML_PARAMETER_model_name', '--model_path', '$AZUREML_DATAREFERENCE_best_model_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'computeclusterlr', 'dataReferences': {'best_model_data': {'dataStoreName': 'sekuritdatastore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/60c326d6-9daa-4c00-96bd-4dbd0a9368a6/best_model_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Experiment automl_sekurit_pipeline_v4 Environment', 'version': 'Autosave_2022-02-23T19:29:07Z_0cc69d3f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk[automl]~=1.37.0', 'pyarrow']}, 'pandas', 'scikit-learn'], 'name': 'azureml_0a58f5ea93884f5ab17d28fa937b0355'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211124.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_model_name': 'sekurit_model_v4'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=ec1aZ16%2F9mABMAl5cw9hVLW%2FHUkphdV0jCicuZsclGY%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A58%3A04Z&ske=2022-02-24T22%3A08%3A04Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A46%3A39Z&se=2022-02-24T03%3A56%3A39Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=PH8AJIrjCYdesy%2Fh%2FNrT32eNu1s9HwxfZz6OUEbMFwo%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A58%3A04Z&ske=2022-02-24T22%3A08%3A04Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A46%3A39Z&se=2022-02-24T03%3A56%3A39Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=OI3BAt7f1qZRgzOr%2BVaBwYke96uaTm3P6oU8DVL5oR4%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A58%3A04Z&ske=2022-02-24T22%3A08%3A04Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A46%3A39Z&se=2022-02-24T03%3A56%3A39Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'status': 'Completed', 'startTimeUtc': '2022-02-23T19:29:00.480396Z', 'endTimeUtc': '2022-02-23T19:58:44.506458Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"model_name\":\"sekurit_model_v4\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=2ajLD6QOcnIks2z8CSvNul6QuS6at%2Fq19ePtWvX9D0o%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A45%3A10Z&se=2022-02-24T03%3A55%3A10Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=BX7%2FGKm1RFvsxRJrT60XHRpoNYF1r2g4jvLLfjHjFPw%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A45%3A10Z&se=2022-02-24T03%3A55%3A10Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=Z9AiIhOt1L3IDTJAyRoZvb2aqx8qlph2ne0vEEM0NJc%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A45%3A10Z&se=2022-02-24T03%3A55%3A10Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42a55b642fe47a194f4bd5b32716343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "experiment = Experiment(workspace=ws, name='automl_sekurit_pipeline_v4')\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [prep_step, train_step, register_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ee725bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "register_model\n",
      "80e3180f-800c-442c-b07e-2a38912cabb1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8c27c813ea4b358b42e550390cd0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/80e3180f-800c-442c-b07e-2a38912cabb1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\", \"run_id\": \"80e3180f-800c-442c-b07e-2a38912cabb1\", \"run_properties\": {\"run_id\": \"80e3180f-800c-442c-b07e-2a38912cabb1\", \"created_utc\": \"2022-02-23T19:56:33.885332Z\", \"properties\": {\"ContentSnapshotId\": \"83941250-e2e4-47b2-894e-5dc296355ad5\", \"StepType\": \"PythonScriptStep\", \"ComputeTargetType\": \"AmlCompute\", \"azureml.moduleid\": \"42c9db6c-a00e-49c2-944a-f0c7973db919\", \"azureml.moduleName\": \"register_model\", \"azureml.runsource\": \"azureml.StepRun\", \"azureml.nodeid\": \"c9e4e482\", \"azureml.pipelinerunid\": \"9c29cc9e-7050-4749-af14-ed125a9373c1\", \"azureml.pipeline\": \"9c29cc9e-7050-4749-af14-ed125a9373c1\", \"azureml.pipelineComponent\": \"masterescloud\", \"_azureml.ComputeTargetType\": \"amlcompute\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"azureml.nodeid\": \"c9e4e482\", \"azureml.pipeline\": \"9c29cc9e-7050-4749-af14-ed125a9373c1\", \"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":1,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-02-23T19:58:43.309692Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=y%2BZXInfGqG36e5fB9lvna8yNeqIhfx5qCOQrnf%2FDXAs%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A55%3A20Z&ske=2022-02-24T22%3A05%3A20Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A28Z&se=2022-02-24T04%3A53%3A28Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=KMemqgz10V8LKZ8oJ3hFVL%2FwlYIMTmIY3RifqkjDYbE%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A55%3A20Z&ske=2022-02-24T22%3A05%3A20Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A28Z&se=2022-02-24T04%3A53%3A28Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=t8EwPzEBJj1%2BBYPufx287mS2UX0zW57NOBEkx3OMI2I%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A55%3A20Z&ske=2022-02-24T22%3A05%3A20Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A28Z&se=2022-02-24T04%3A53%3A28Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:02:09\", \"run_number\": \"1645646193\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2022-02-23 19:56:35Z] Experiment: automl_sekurit_pipeline_v4, Run target: computeclusterlr, Run Id: 80e3180f-800c-442c-b07e-2a38912cabb1, WorkspaceName: aml_ws, WorkspaceId: 57a0fe81-1934-4a22-8898-5e401a74b8ea\\n[2022-02-23 19:56:35Z] Starting run in Execution Service\\n[2022-02-23 19:56:36Z] RunId:[80e3180f-800c-442c-b07e-2a38912cabb1] ParentRunId:[9c29cc9e-7050-4749-af14-ed125a9373c1] ComputeTarget:[AmlCompute]\\n[2022-02-23 19:56:37Z] Job is in progress. Execution status: Preparing.\\n[2022-02-23 19:56:38Z] Job is in progress. Execution status: Queued.\\n[2022-02-23 19:56:39Z] Job is in progress. Execution status: Queued.\\n[2022-02-23 19:58:33Z] Job is in progress. Execution status: Running.\\n[2022-02-23 19:58:37Z] Job is in progress. Execution status: Running.\\n[2022-02-23 19:58:40Z] Job is in progress. Execution status: Finalizing.\\n[2022-02-23 19:58:43Z] Job finished, job RunId is 80e3180f-800c-442c-b07e-2a38912cabb1\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.37.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Get the run ID from pipeline run\n",
    "\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "#from azureml.widgets import RunDetails\n",
    "\n",
    "# workaround to get the automl run as its the last step in the pipeline \n",
    "# and get_steps() returns the steps from latest to first\n",
    "\n",
    "for step in pipeline_run.get_steps():\n",
    "    automl_step_run_id = step.id\n",
    "    print(step.name)\n",
    "    print(automl_step_run_id)\n",
    "    break\n",
    "\n",
    "automl_run = AutoMLRun(experiment = experiment, run_id=automl_step_run_id)\n",
    "RunDetails(automl_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3191e891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID 80e3180f-800c-442c-b07e-2a38912cabb1\n",
      "Run ID 60c326d6-9daa-4c00-96bd-4dbd0a9368a6\n",
      "\t {'experiment_status': ['DatasetEvaluation', 'FeaturesGeneration', 'DatasetFeaturization', 'DatasetFeaturizationCompleted', 'DatasetCrossValidationSplit', 'ModelSelection', 'BestRunExplainModel', 'ModelExplanationDataSetSetup', 'PickSurrogateModel', 'EngineeredFeatureExplanations', 'EngineeredFeatureExplanations', 'RawFeaturesExplanations', 'RawFeaturesExplanations', 'BestRunExplainModel']}\n",
      "\t {'experiment_status_description': ['Gathering dataset statistics.', 'Generating features for the dataset.', 'Beginning to fit featurizers and featurize the dataset.', 'Completed fit featurizers and featurizing the dataset.', 'Generating individually featurized CV splits.', 'Beginning model selection.', 'Best run model explanations started', 'Model explanations data setup completed', 'Choosing LightGBM as the surrogate model for explanations', 'Computation of engineered features started', 'Computation of engineered features completed', 'Computation of raw features started', 'Computation of raw features completed', 'Best run model explanations completed']}\n",
      "\t {'normalized_median_absolute_error': 0.0006741485692075984}\n",
      "\t {'spearman_correlation': 0.8355982244730783}\n",
      "\t {'root_mean_squared_log_error': 1.839731819152455}\n",
      "\t {'normalized_root_mean_squared_log_error': 0.1761676252585014}\n",
      "\t {'normalized_root_mean_squared_error': 0.014504898323119235}\n",
      "\t {'mean_absolute_error': 113.057680209187}\n",
      "\t {'root_mean_squared_error': 497.59053697460536}\n",
      "\t {'r2_score': 0.9184531312829576}\n",
      "\t {'normalized_mean_absolute_error': 0.003295661862970033}\n",
      "\t {'mean_absolute_percentage_error': 225.4678459526737}\n",
      "\t {'explained_variance': 0.9184597676288518}\n",
      "\t {'median_absolute_error': 23.126666666666665}\n",
      "Run ID ae1c9977-3df9-42d6-8f38-63934b887388\n",
      "\t {'processed_rows': 1151}\n"
     ]
    }
   ],
   "source": [
    "for run in pipeline_run.get_children():\n",
    "    print('Run ID', run.id)\n",
    "    for metric in run.get_metrics():\n",
    "        print('\\t', run.get_metrics(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe19ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sekurit_model_v4 version: 2\n",
      "\n",
      "\n",
      "sekurit_model_v2 version: 2\n",
      "\n",
      "\n",
      "sekurit_model_v2 version: 1\n",
      "\n",
      "\n",
      "sekurit_model_initial version: 2\n",
      "\n",
      "\n",
      "sekurit_model version: 5\n",
      "\t Training context : Auto ML in pipeline\n",
      "\t AUC : 0.014550774687038625\n",
      "\n",
      "\n",
      "AutoML0b24ea5a20 version: 1\n",
      "\n",
      "\n",
      "amlstudio-test-deploy-v2 version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "amlstudio-test-endpoint-lr version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "diabetes_model version: 11\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8832778417290374\n",
      "\t Accuracy : 0.8991111111111111\n",
      "\n",
      "\n",
      "diabetes_mitigated_20 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_19 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_18 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_17 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_16 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_15 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_14 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_13 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_12 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_11 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_10 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_9 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_8 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_7 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_6 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_5 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_4 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_3 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_2 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_1 version: 1\n",
      "\n",
      "\n",
      "diabetes_unmitigated version: 1\n",
      "\n",
      "\n",
      "diabetes_classifier version: 1\n",
      "\n",
      "\n",
      "diabetes_model version: 10\n",
      "\t Training context : Auto ML\n",
      "\t AUC : 0.9904812577250306\n",
      "\t Accuracy : 0.9520809898762654\n",
      "\n",
      "\n",
      "diabetes_model version: 9\n",
      "\t Training context : Hyperdrive\n",
      "\t AUC : 0.9885804604667666\n",
      "\t Accuracy : 0.9457777777777778\n",
      "\n",
      "\n",
      "diabetes_model version: 8\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8755584854967908\n",
      "\t Accuracy : 0.8863333333333333\n",
      "\n",
      "\n",
      "diabetes_model version: 7\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.879600975172894\n",
      "\t Accuracy : 0.8926666666666667\n",
      "\n",
      "\n",
      "diabetes_model version: 6\n",
      "\t Training context : Pipeline\n",
      "\t AUC : 0.8837616052365906\n",
      "\t Accuracy : 0.8988888888888888\n",
      "\n",
      "\n",
      "diabetes_model version: 5\n",
      "\t Training context : File dataset\n",
      "\t AUC : 0.8568743524381947\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 4\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8483964376337131\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8483999203940495\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC : 0.8484929598487486\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "\n",
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67f4d75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>automl-sekurit-pipeline-v4</td><td><a href=\"https://ml.azure.com/pipelines/55ec1f8e-8c06-49b9-b8a1-a8ff704bf5fb?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws\" target=\"_blank\" rel=\"noopener\">55ec1f8e-8c06-49b9-b8a1-a8ff704bf5fb</a></td><td>Active</td><td><a href=\"https://southeastasia.api.azureml.ms/pipelines/v1.0/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/PipelineRuns/PipelineSubmit/55ec1f8e-8c06-49b9-b8a1-a8ff704bf5fb\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: automl-sekurit-pipeline-v4,\n",
       "Id: 55ec1f8e-8c06-49b9-b8a1-a8ff704bf5fb,\n",
       "Status: Active,\n",
       "Endpoint: https://southeastasia.api.azureml.ms/pipelines/v1.0/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/PipelineRuns/PipelineSubmit/55ec1f8e-8c06-49b9-b8a1-a8ff704bf5fb)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Publish the pipeline from the run\n",
    "\n",
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"automl-sekurit-pipeline-v4\", description=\"Trains sekurit model in pipeline\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a69f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00bc3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sekurit_model version 7\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['sekurit_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2b9fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n",
    "from inference_schema.schema_decorators import input_schema, output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebe24a56",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelNotFoundException",
     "evalue": "ModelNotFoundException:\n\tMessage: Model sekurit_model.pkl not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/aml-comp-lr/code. For more info, set logging level to DEBUG.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Model sekurit_model.pkl not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/aml-comp-lr/code. For more info, set logging level to DEBUG.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelNotFoundException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-94b23a65b024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m  \u001b[0;31m# Get the path to the deployed model file and load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sekurit_model.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36mget_model_path\u001b[0;34m(model_name, version, _workspace)\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_path_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_workspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_path_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36m_get_model_path_local\u001b[0;34m(model_name, version)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# Probing azureml-models/<name>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_path_local_from_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;31m# Probing azureml-models/<name> exists, probing version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36m_get_model_path_local_from_root\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    870\u001b[0m         raise ModelNotFoundException(\"Model {} not found in cache at {} or in current working directory {}. \"\n\u001b[1;32m    871\u001b[0m                                      \"For more info, set logging level to DEBUG.\".format(model_name, MODELS_DIR,\n\u001b[0;32m--> 872\u001b[0;31m                                                                                          os.getcwd()))\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelNotFoundException\u001b[0m: ModelNotFoundException:\n\tMessage: Model sekurit_model.pkl not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/aml-comp-lr/code. For more info, set logging level to DEBUG.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Model sekurit_model.pkl not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/aml-comp-lr/code. For more info, set logging level to DEBUG.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core import Model\n",
    "\n",
    " # Get the path to the deployed model file and load it\n",
    "model_path = Model.get_model_path(\"sekurit_model\")\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "raw_data = '{\"data\":[[\"Grand Punto\", 4000, \"Compact-Regular\", \"Hatchback\",\"Fiat\", 1.4, 8, 16, 105.71, \"Y\", \"N\", 5]]}'\n",
    "\n",
    "data = json.loads(raw_data)[\"data\"]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2af08dd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b636d77a370a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrequest_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test result: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "request_headers = {}\n",
    "\n",
    "result = model.predict(data)\n",
    "print(\"Test result: \", {\"result\": result.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9578d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
