{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1d0708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.38.0 to work with aml_ws\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bbb5508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skdatastore - Default = True\n",
      "azureml_globaldatasets - Default = False\n",
      "workspaceworkingdirectory - Default = False\n",
      "workspacefilestore - Default = False\n",
      "workspaceartifactstore - Default = False\n",
      "workspaceblobstore - Default = False\n"
     ]
    }
   ],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76ed4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e988d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_datastore_name='skdatastore' # Name of the datastore to workspace\n",
    "container_name=os.getenv(\"BLOB_CONTAINER\", \"sk\") # Name of Azure blob container\n",
    "account_name=os.getenv(\"BLOB_ACCOUNTNAME\", \"amlws8080781874\") # Storage account name\n",
    "account_key=os.getenv(\"BLOB_ACCOUNT_KEY\", \"WIeZyihhWkyNGps+KHdbNaKOCtsxpKpXMIvmsfXkXQxz06hKLgu2fiaBUIIFPopdXRmzNTxt3ZIDJF/JcA1zMg==\") # Storage account access key\n",
    "\n",
    "blob_datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                         datastore_name=blob_datastore_name, \n",
    "                                                         container_name=container_name, \n",
    "                                                         account_name=account_name,\n",
    "                                                         account_key=account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49da1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name='skdataset')\n",
    "data = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f111fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Length</th>\n",
       "      <th>Type</th>\n",
       "      <th>Style</th>\n",
       "      <th>OEM</th>\n",
       "      <th>Engine Disp</th>\n",
       "      <th>Age of OEM</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Oil Price</th>\n",
       "      <th>Petrol</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Column17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Jan-14</td>\n",
       "      <td>16</td>\n",
       "      <td>102.10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1,207</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Feb-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.83</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>882</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mar-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.04</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>839</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Apr-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.87</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>547</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>May-14</td>\n",
       "      <td>16</td>\n",
       "      <td>105.71</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>571</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Length             Type      Style   OEM  Engine Disp  \\\n",
       "0  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "1  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "2  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "3  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "4  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "\n",
       "   Age of OEM    Year  Mileage  Oil Price  Petrol  Automatic  Price  Sales  \\\n",
       "0           8  Jan-14       16     102.10    True      False    5.0  1,207   \n",
       "1           8  Feb-14       16     104.83    True      False    5.0    882   \n",
       "2           8  Mar-14       16     104.04    True      False    5.0    839   \n",
       "3           8  Apr-14       16     104.87    True      False    5.0    547   \n",
       "4           8  May-14       16     105.71    True      False    5.0    571   \n",
       "\n",
       "  Column17  \n",
       "0     None  \n",
       "1     None  \n",
       "2     None  \n",
       "3     None  \n",
       "4     None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a5d6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'sk_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7afac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sk_pipeline/prep_sk.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/prep_sk.py\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
    "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
    "args = parser.parse_args()\n",
    "save_folder = args.prepped_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "data= run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# Drop unnecessary columns and other cleaning steps\n",
    "data=data.drop(['Year','Column17'],axis=1)\n",
    "\n",
    "data['Sales']=pd.to_numeric(data['Sales'],errors='coerce')\n",
    "data= data[data['Sales'].notna()]\n",
    "\n",
    "\n",
    "# Label Encoding\n",
    "list_of_columns = ['Model','Type','Style','OEM']\n",
    "data[list_of_columns] = data[list_of_columns].apply(lambda col:pd.Categorical(col).codes)\n",
    "\n",
    "# Boolean Encoding\n",
    "data[[\"Petrol\", \"Automatic\"]] *= 1\n",
    "\n",
    "# Normalize the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['Length','Engine Disp','Age of OEM','Mileage','Oil Price','Price']\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "\n",
    "# Log processed rows\n",
    "row_count = (len(data))\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "# Save the prepped data\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder,'data.csv')\n",
    "data.to_csv(save_path, index=False, header=True)\n",
    "\n",
    "# End the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fbeb95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sk_pipeline/sk_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/sk_training.py\n",
    "\n",
    "# Import libraries\n",
    "from azureml.core import Run, Model\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\n",
    "args = parser.parse_args()\n",
    "training_data = args.training_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the prepared data file in the training folder-\n",
    "print(\"Loading Data...\")\n",
    "file_path = os.path.join(training_data,'data.csv')\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = data[['Model','Length','Type','Style','OEM','Engine Disp','Age of OEM','Mileage','Oil Price','Petrol','Automatic','Price']].values, data['Sales'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train adecision tree model\n",
    "print('Training a logistic regression model')\n",
    "model = LogisticRegression(C=1/0.01, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "print(\"Saving model...\")\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "model_file = os.path.join('outputs', 'sk_model.pkl')\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "\n",
    "# Register the model\n",
    "print('Registering model...')\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'sk_model',\n",
    "               tags={'Training context':'Pipeline'},\n",
    "               properties={'Accuracy': np.float(acc)})\n",
    "\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c05f4348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"computeclusterlr\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9f92a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sk_pipeline/experiment_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/experiment_env.yml\n",
    "\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cd88205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
    "\n",
    "# Register the environment \n",
    "experiment_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'experiment_env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88ed4fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Get the training dataset\n",
    "sk_ds = ws.datasets.get(\"skdataset\")\n",
    "\n",
    "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
    "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
    "\n",
    "# Step 1, Run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"prep_sk.py\",\n",
    "                                arguments = ['--input-data', sk_ds.as_named_input('raw_data'),\n",
    "                                             '--prepped-data', prepped_data],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "# Step 2, run the training script\n",
    "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"sk_training.py\",\n",
    "                                arguments = ['--training-data', prepped_data.as_input()],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08229255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Prepare Data [39b82eec][2b9c70dc-0874-42dd-bdb0-b5edf07eb4df], (This step will run and generate new outputs)\n",
      "Created step Train and Register Model [202bf198][dd978f2d-11cd-438a-a935-c1f61e7c1f01], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun a858009b-9c6f-4337-a9cc-baa662bbff8c\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/a858009b-9c6f-4337-a9cc-baa662bbff8c?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9f8428aafc4d5a812788b14ad2f0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/a858009b-9c6f-4337-a9cc-baa662bbff8c?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\", \"run_id\": \"a858009b-9c6f-4337-a9cc-baa662bbff8c\", \"run_properties\": {\"run_id\": \"a858009b-9c6f-4337-a9cc-baa662bbff8c\", \"created_utc\": \"2022-02-24T21:45:05.7472Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2022-02-24T21:54:36.923436Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a858009b-9c6f-4337-a9cc-baa662bbff8c/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=9g49nDPnUP8M4r5oGgcisB%2BMVyRNBeb6WGmv9joB558%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T15%3A10%3A13Z&ske=2022-02-25T23%3A20%3A13Z&sks=b&skv=2019-07-07&st=2022-02-24T22%3A13%3A00Z&se=2022-02-25T06%3A23%3A00Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a858009b-9c6f-4337-a9cc-baa662bbff8c/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=Pl%2FmFQw0TxL1g89VPuUQTJc%2BoegTLnDWP44J0aTD0i0%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T15%3A10%3A13Z&ske=2022-02-25T23%3A20%3A13Z&sks=b&skv=2019-07-07&st=2022-02-24T22%3A13%3A00Z&se=2022-02-25T06%3A23%3A00Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a858009b-9c6f-4337-a9cc-baa662bbff8c/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=BAMEPFlEmUoVAv5fpFYPo%2BfCm%2FCC7IXE0YrsvYkQB%2FQ%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T15%3A10%3A13Z&ske=2022-02-25T23%3A20%3A13Z&sks=b&skv=2019-07-07&st=2022-02-24T22%3A13%3A00Z&se=2022-02-25T06%3A23%3A00Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:09:31\", \"run_number\": \"1645739105\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"a06b5b5d-3e78-4506-8be1-fb5d984e8b6d\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-02-24T21:52:29.284272Z\", \"created_time\": \"2022-02-24T21:45:08.296138Z\", \"end_time\": \"2022-02-24T21:54:05.652793Z\", \"duration\": \"0:08:57\", \"run_number\": 1645739108, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-24T21:45:08.296138Z\", \"is_reused\": \"\"}, {\"run_id\": \"086d73c0-07c6-4b90-9489-739e62f0d653\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-02-24T21:54:14.669357Z\", \"created_time\": \"2022-02-24T21:54:07.556241Z\", \"end_time\": \"2022-02-24T21:54:35.657639Z\", \"duration\": \"0:00:28\", \"run_number\": 1645739647, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-24T21:54:07.556241Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-02-24 21:45:08Z] Submitting 1 runs, first five are: 39b82eec:a06b5b5d-3e78-4506-8be1-fb5d984e8b6d\\n[2022-02-24 21:54:06Z] Completing processing run id a06b5b5d-3e78-4506-8be1-fb5d984e8b6d.\\n[2022-02-24 21:54:07Z] Submitting 1 runs, first five are: 202bf198:086d73c0-07c6-4b90-9489-739e62f0d653\\n[2022-02-24 21:54:36Z] Completing processing run id 086d73c0-07c6-4b90-9489-739e62f0d653.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"3cc57f4b\": {\"node_id\": \"3cc57f4b\", \"name\": \"skdataset\"}}, \"module_nodes\": {\"39b82eec\": {\"node_id\": \"39b82eec\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"a06b5b5d-3e78-4506-8be1-fb5d984e8b6d\"}, \"202bf198\": {\"node_id\": \"202bf198\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"086d73c0-07c6-4b90-9489-739e62f0d653\"}}, \"edges\": [{\"source_node_id\": \"3cc57f4b\", \"source_node_name\": \"skdataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"39b82eec\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"39b82eec\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"input_4742e640\", \"dst_node_id\": \"202bf198\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"a06b5b5d-3e78-4506-8be1-fb5d984e8b6d\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-02-24T21:52:29.284272Z\", \"created_time\": \"2022-02-24T21:45:08.296138Z\", \"end_time\": \"2022-02-24T21:54:05.652793Z\", \"duration\": \"0:08:57\", \"run_number\": 1645739108, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-24T21:45:08.296138Z\", \"is_reused\": \"\"}, {\"run_id\": \"086d73c0-07c6-4b90-9489-739e62f0d653\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2022-02-24T21:54:14.669357Z\", \"created_time\": \"2022-02-24T21:54:07.556241Z\", \"end_time\": \"2022-02-24T21:54:35.657639Z\", \"duration\": \"0:00:28\", \"run_number\": 1645739647, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-24T21:54:07.556241Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.38.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: a858009b-9c6f-4337-a9cc-baa662bbff8c\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/a858009b-9c6f-4337-a9cc-baa662bbff8c?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: a06b5b5d-3e78-4506-8be1-fb5d984e8b6d\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/a06b5b5d-3e78-4506-8be1-fb5d984e8b6d?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "StepRun( Prepare Data ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2022/02/24 21:45:15 Downloading source code...\n",
      "2022/02/24 21:45:16 Finished downloading source code\n",
      "2022/02/24 21:45:16 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2022/02/24 21:45:16 Successfully set up Docker network: acb_default_network\n",
      "2022/02/24 21:45:16 Setting up Docker configuration...\n",
      "2022/02/24 21:45:17 Successfully set up Docker configuration\n",
      "2022/02/24 21:45:17 Logging in to registry: 57a0fe8119344a2288985e401a74b8ea.azurecr.io\n",
      "2022/02/24 21:45:17 Successfully logged into 57a0fe8119344a2288985e401a74b8ea.azurecr.io\n",
      "2022/02/24 21:45:17 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/02/24 21:45:17 Scanning for dependencies...\n",
      "2022/02/24 21:45:18 Successfully scanned dependencies\n",
      "2022/02/24 21:45:18 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1@sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf\n",
      "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1@sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n",
      "2f94e549220a: Already exists\n",
      "2b2d92136c10: Pulling fs layer\n",
      "0b412d2669ed: Pulling fs layer\n",
      "805003cfcee6: Pulling fs layer\n",
      "ad877dc53455: Pulling fs layer\n",
      "afa783568628: Pulling fs layer\n",
      "d67cf86adb17: Pulling fs layer\n",
      "82770c3b2808: Pulling fs layer\n",
      "c991e53ceb53: Pulling fs layer\n",
      "ad877dc53455: Waiting\n",
      "afa783568628: Waiting\n",
      "d67cf86adb17: Waiting\n",
      "82770c3b2808: Waiting\n",
      "c991e53ceb53: Waiting\n",
      "0b412d2669ed: Verifying Checksum\n",
      "0b412d2669ed: Download complete\n",
      "805003cfcee6: Verifying Checksum\n",
      "805003cfcee6: Download complete\n",
      "afa783568628: Verifying Checksum\n",
      "afa783568628: Download complete\n",
      "d67cf86adb17: Verifying Checksum\n",
      "d67cf86adb17: Download complete\n",
      "2b2d92136c10: Verifying Checksum\n",
      "2b2d92136c10: Download complete\n",
      "c991e53ceb53: Verifying Checksum\n",
      "c991e53ceb53: Download complete\n",
      "82770c3b2808: Verifying Checksum\n",
      "82770c3b2808: Download complete\n",
      "ad877dc53455: Verifying Checksum\n",
      "ad877dc53455: Download complete\n",
      "2b2d92136c10: Pull complete\n",
      "0b412d2669ed: Pull complete\n",
      "805003cfcee6: Pull complete\n",
      "ad877dc53455: Pull complete\n",
      "afa783568628: Pull complete\n",
      "d67cf86adb17: Pull complete\n",
      "82770c3b2808: Pull complete\n",
      "c991e53ceb53: Pull complete\n",
      "Digest: sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1@sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf\n",
      " ---> 54296612fc48\n",
      "Step 2/21 : USER root\n",
      " ---> Running in 011b79044a84\n",
      "Removing intermediate container 011b79044a84\n",
      " ---> 1de7b918084e\n",
      "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in b332c5f55b6a\n",
      "Removing intermediate container b332c5f55b6a\n",
      " ---> fab9ade76761\n",
      "Step 4/21 : WORKDIR /\n",
      " ---> Running in 8e555de27707\n",
      "Removing intermediate container 8e555de27707\n",
      " ---> dd772558b3e8\n",
      "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 715f1f8f6598\n",
      "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 1b624b87d196\n",
      "Removing intermediate container 1b624b87d196\n",
      " ---> 3686dd49737b\n",
      "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> a03427119c51\n",
      "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 441d3ce30326\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "certifi-2021.5.30    | 139 KB    |            |   0% \n",
      "certifi-2021.5.30    | 139 KB    | ########## | 100% \n",
      "\n",
      "jedi-0.17.0          | 780 KB    |            |   0% \n",
      "jedi-0.17.0          | 780 KB    | ########## | 100% \n",
      "jedi-0.17.0          | 780 KB    | ########## | 100% \n",
      "\n",
      "libtiff-4.2.0        | 502 KB    |            |   0% \n",
      "libtiff-4.2.0        | 502 KB    | ########## | 100% \n",
      "\n",
      "numpy-base-1.19.2    | 4.1 MB    |            |   0% \n",
      "numpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n",
      "numpy-base-1.19.2    | 4.1 MB    | ########## | 100% \n",
      "\n",
      "pip-21.2.2           | 1.8 MB    |            |   0% \n",
      "pip-21.2.2           | 1.8 MB    | ########## | 100% \n",
      "pip-21.2.2           | 1.8 MB    | ########## | 100% \n",
      "\n",
      "parso-0.8.3          | 70 KB     |            |   0% \n",
      "parso-0.8.3          | 70 KB     | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 808 KB    |            |   0% \n",
      "sqlite-3.23.1        | 808 KB    | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 341 KB    |            |   0% \n",
      "xz-5.2.5             | 341 KB    | ########## | 100% \n",
      "\n",
      "cycler-0.11.0        | 12 KB     |            |   0% \n",
      "cycler-0.11.0        | 12 KB     | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 781 KB    |            |   0% \n",
      "ncurses-6.0          | 781 KB    | ########## | 100% \n",
      "ncurses-6.0          | 781 KB    | ########## | 100% \n",
      "\n",
      "ipykernel-5.3.4      | 181 KB    |            |   0% \n",
      "ipykernel-5.3.4      | 181 KB    | ########## | 100% \n",
      "\n",
      "pytz-2021.3          | 171 KB    |            |   0% \n",
      "pytz-2021.3          | 171 KB    | ########## | 100% \n",
      "\n",
      "nest-asyncio-1.5.1   | 10 KB     |            |   0% \n",
      "nest-asyncio-1.5.1   | 10 KB     | ########## | 100% \n",
      "\n",
      "ca-certificates-2021 | 115 KB    |            |   0% \n",
      "ca-certificates-2021 | 115 KB    | ########## | 100% \n",
      "\n",
      "pandas-1.1.5         | 8.2 MB    |            |   0% \n",
      "pandas-1.1.5         | 8.2 MB    | ########## | 100% \n",
      "pandas-1.1.5         | 8.2 MB    | ########## | 100% \n",
      "\n",
      "backcall-0.2.0       | 13 KB     |            |   0% \n",
      "backcall-0.2.0       | 13 KB     | ########## | 100% \n",
      "\n",
      "ipython-7.16.1       | 999 KB    |            |   0% \n",
      "ipython-7.16.1       | 999 KB    | ########## | 100% \n",
      "\n",
      "matplotlib-base-3.3. | 5.1 MB    |            |   0% \n",
      "matplotlib-base-3.3. | 5.1 MB    |            |   0% \n",
      "matplotlib-base-3.3. | 5.1 MB    | #1         |  11% \n",
      "matplotlib-base-3.3. | 5.1 MB    | ##4        |  24% \n",
      "matplotlib-base-3.3. | 5.1 MB    | ###8       |  38% \n",
      "matplotlib-base-3.3. | 5.1 MB    | #####2     |  52% \n",
      "matplotlib-base-3.3. | 5.1 MB    | ######9    |  69% \n",
      "matplotlib-base-3.3. | 5.1 MB    | #########3 |  93% \n",
      "matplotlib-base-3.3. | 5.1 MB    | ########## | 100% \n",
      "\n",
      "libxml2-2.9.12       | 1.2 MB    |            |   0% \n",
      "libxml2-2.9.12       | 1.2 MB    | ########## | 100% \n",
      "\n",
      "openjpeg-2.4.0       | 331 KB    |            |   0% \n",
      "openjpeg-2.4.0       | 331 KB    | ########## | 100% \n",
      "\n",
      "sip-4.19.8           | 274 KB    |            |   0% \n",
      "sip-4.19.8           | 274 KB    | ########## | 100% \n",
      "\n",
      "libwebp-base-1.2.2   | 440 KB    |            |   0% \n",
      "libwebp-base-1.2.2   | 440 KB    | ########## | 100% \n",
      "\n",
      "scipy-1.5.2          | 14.4 MB   |            |   0% \n",
      "scipy-1.5.2          | 14.4 MB   | #######2   |  73% \n",
      "scipy-1.5.2          | 14.4 MB   | ########## | 100% \n",
      "scipy-1.5.2          | 14.4 MB   | ########## | 100% \n",
      "\n",
      "traitlets-4.3.3      | 138 KB    |            |   0% \n",
      "traitlets-4.3.3      | 138 KB    | ########## | 100% \n",
      "\n",
      "zstd-1.4.9           | 480 KB    |            |   0% \n",
      "zstd-1.4.9           | 480 KB    | ########## | 100% \n",
      "\n",
      "mkl_random-1.1.1     | 327 KB    |            |   0% \n",
      "mkl_random-1.1.1     | 327 KB    | ########## | 100% \n",
      "\n",
      "pyparsing-3.0.4      | 81 KB     |            |   0% \n",
      "pyparsing-3.0.4      | 81 KB     | ########## | 100% \n",
      "\n",
      "pickleshare-0.7.5    | 13 KB     |            |   0% \n",
      "pickleshare-0.7.5    | 13 KB     | ########## | 100% \n",
      "\n",
      "libxcb-1.14          | 505 KB    |            |   0% \n",
      "libxcb-1.14          | 505 KB    | ########## | 100% \n",
      "\n",
      "_openmp_mutex-4.5    | 22 KB     |            |   0% \n",
      "_openmp_mutex-4.5    | 22 KB     | ########## | 100% \n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "\n",
      "wheel-0.37.1         | 33 KB     |            |   0% \n",
      "wheel-0.37.1         | 33 KB     | ########## | 100% \n",
      "\n",
      "lz4-c-1.9.3          | 185 KB    |            |   0% \n",
      "lz4-c-1.9.3          | 185 KB    | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 151 KB    |            |   0% \n",
      "libedit-3.1          | 151 KB    | ########## | 100% \n",
      "\n",
      "intel-openmp-2022.0. | 4.2 MB    |            |   0% \n",
      "intel-openmp-2022.0. | 4.2 MB    | ########## | 100% \n",
      "intel-openmp-2022.0. | 4.2 MB    | ########## | 100% \n",
      "\n",
      "gst-plugins-base-1.1 | 4.8 MB    |            |   0% \n",
      "gst-plugins-base-1.1 | 4.8 MB    | ########## | 100% \n",
      "gst-plugins-base-1.1 | 4.8 MB    | ########## | 100% \n",
      "\n",
      "gstreamer-1.14.0     | 3.1 MB    |            |   0% \n",
      "gstreamer-1.14.0     | 3.1 MB    | ########## | 100% \n",
      "gstreamer-1.14.0     | 3.1 MB    | ########## | 100% \n",
      "\n",
      "wcwidth-0.2.5        | 26 KB     |            |   0% \n",
      "wcwidth-0.2.5        | 26 KB     | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 2.2 MB    |            |   0% \n",
      "openssl-1.0.2u       | 2.2 MB    | ########## | 100% \n",
      "\n",
      "jpeg-9d              | 232 KB    |            |   0% \n",
      "jpeg-9d              | 232 KB    | ########## | 100% \n",
      "\n",
      "python-dateutil-2.8. | 233 KB    |            |   0% \n",
      "python-dateutil-2.8. | 233 KB    | ########## | 100% \n",
      "\n",
      "libsodium-1.0.18     | 244 KB    |            |   0% \n",
      "libsodium-1.0.18     | 244 KB    | ########## | 100% \n",
      "\n",
      "setuptools-58.0.4    | 788 KB    |            |   0% \n",
      "setuptools-58.0.4    | 788 KB    | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.2.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 23.6 MB   |            |   0% \n",
      "python-3.6.2         | 23.6 MB   | ####4      |  45% \n",
      "python-3.6.2         | 23.6 MB   | ########## | 100% \n",
      "python-3.6.2         | 23.6 MB   | ########## | 100% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "numpy-1.19.2         | 22 KB     |            |   0% \n",
      "numpy-1.19.2         | 22 KB     | ########## | 100% \n",
      "\n",
      "prompt-toolkit-3.0.2 | 259 KB    |            |   0% \n",
      "prompt-toolkit-3.0.2 | 259 KB    | ########## | 100% \n",
      "\n",
      "entrypoints-0.3      | 12 KB     |            |   0% \n",
      "entrypoints-0.3      | 12 KB     | ########## | 100% \n",
      "\n",
      "expat-2.4.4          | 169 KB    |            |   0% \n",
      "expat-2.4.4          | 169 KB    | ########## | 100% \n",
      "\n",
      "lcms2-2.12           | 312 KB    |            |   0% \n",
      "lcms2-2.12           | 312 KB    | ########## | 100% \n",
      "\n",
      "libgfortran4-7.5.0   | 995 KB    |            |   0% \n",
      "libgfortran4-7.5.0   | 995 KB    | ########## | 100% \n",
      "\n",
      "mkl-2020.2           | 138.3 MB  |            |   0% \n",
      "mkl-2020.2           | 138.3 MB  | 7          |   7% \n",
      "mkl-2020.2           | 138.3 MB  | #6         |  16% \n",
      "mkl-2020.2           | 138.3 MB  | ##5        |  25% \n",
      "mkl-2020.2           | 138.3 MB  | ###4       |  35% \n",
      "mkl-2020.2           | 138.3 MB  | ####2      |  42% \n",
      "mkl-2020.2           | 138.3 MB  | #####      |  51% \n",
      "mkl-2020.2           | 138.3 MB  | ######1    |  61% \n",
      "mkl-2020.2           | 138.3 MB  | #######1   |  72% \n",
      "mkl-2020.2           | 138.3 MB  | ########2  |  82% \n",
      "mkl-2020.2           | 138.3 MB  | #########2 |  93% \n",
      "mkl-2020.2           | 138.3 MB  | ########## | 100% \n",
      "\n",
      "pyzmq-22.2.1         | 454 KB    |            |   0% \n",
      "pyzmq-22.2.1         | 454 KB    | ########## | 100% \n",
      "\n",
      "jupyter_core-4.8.1   | 74 KB     |            |   0% \n",
      "jupyter_core-4.8.1   | 74 KB     | ########## | 100% \n",
      "\n",
      "decorator-5.1.1      | 12 KB     |            |   0% \n",
      "decorator-5.1.1      | 12 KB     | ########## | 100% \n",
      "\n",
      "libuuid-1.0.3        | 17 KB     |            |   0% \n",
      "libuuid-1.0.3        | 17 KB     | #########4 |  94% \n",
      "libuuid-1.0.3        | 17 KB     | ########## | 100% \n",
      "\n",
      "tk-8.6.11            | 3.0 MB    |            |   0% \n",
      "tk-8.6.11            | 3.0 MB    | ########## | 100% \n",
      "tk-8.6.11            | 3.0 MB    | ########## | 100% \n",
      "\n",
      "libgomp-9.3.0        | 311 KB    |            |   0% \n",
      "libgomp-9.3.0        | 311 KB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.3.0   | 3.1 MB    |            |   0% \n",
      "libstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \n",
      "\n",
      "mkl_fft-1.3.0        | 170 KB    |            |   0% \n",
      "mkl_fft-1.3.0        | 170 KB    | ########## | 100% \n",
      "\n",
      "mkl-service-2.3.0    | 52 KB     |            |   0% \n",
      "mkl-service-2.3.0    | 52 KB     | ########## | 100% \n",
      "\n",
      "ptyprocess-0.7.0     | 17 KB     |            |   0% \n",
      "ptyprocess-0.7.0     | 17 KB     | #########3 |  94% \n",
      "ptyprocess-0.7.0     | 17 KB     | ########## | 100% \n",
      "\n",
      "dbus-1.13.18         | 504 KB    |            |   0% \n",
      "dbus-1.13.18         | 504 KB    | ########## | 100% \n",
      "\n",
      "libgfortran-ng-7.5.0 | 22 KB     |            |   0% \n",
      "libgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \n",
      "\n",
      "qt-5.9.6             | 67.3 MB   |            |   0% \n",
      "qt-5.9.6             | 67.3 MB   | #7         |  17% \n",
      "qt-5.9.6             | 67.3 MB   | ###9       |  39% \n",
      "qt-5.9.6             | 67.3 MB   | #####9     |  60% \n",
      "qt-5.9.6             | 67.3 MB   | #######8   |  79% \n",
      "qt-5.9.6             | 67.3 MB   | #########7 |  97% \n",
      "qt-5.9.6             | 67.3 MB   | ########## | 100% \n",
      "\n",
      "zeromq-4.3.4         | 331 KB    |            |   0% \n",
      "zeromq-4.3.4         | 331 KB    | ########## | 100% \n",
      "\n",
      "olefile-0.46         | 48 KB     |            |   0% \n",
      "olefile-0.46         | 48 KB     | ########## | 100% \n",
      "\n",
      "ipython_genutils-0.2 | 27 KB     |            |   0% \n",
      "ipython_genutils-0.2 | 27 KB     | ########## | 100% \n",
      "\n",
      "scikit-learn-0.24.2  | 5.2 MB    |            |   0% \n",
      "scikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n",
      "scikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 848 KB    |            |   0% \n",
      "readline-7.0         | 848 KB    | ########## | 100% \n",
      "\n",
      "tornado-6.1          | 581 KB    |            |   0% \n",
      "tornado-6.1          | 581 KB    | ########## | 100% \n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      |            |   0% \n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 108 KB    |            |   0% \n",
      "zlib-1.2.11          | 108 KB    | ########## | 100% \n",
      "\n",
      "joblib-1.0.1         | 208 KB    |            |   0% \n",
      "joblib-1.0.1         | 208 KB    | ########## | 100% \n",
      "\n",
      "pyqt-5.9.2           | 4.5 MB    |            |   0% \n",
      "pyqt-5.9.2           | 4.5 MB    | ########## | 100% \n",
      "pyqt-5.9.2           | 4.5 MB    | ########## | 100% \n",
      "\n",
      "pygments-2.11.2      | 759 KB    |            |   0% \n",
      "pygments-2.11.2      | 759 KB    | ########## | 100% \n",
      "\n",
      "pcre-8.45            | 207 KB    |            |   0% \n",
      "pcre-8.45            | 207 KB    | ########## | 100% \n",
      "\n",
      "fontconfig-2.13.1    | 250 KB    |            |   0% \n",
      "fontconfig-2.13.1    | 250 KB    | ########## | 100% \n",
      "\n",
      "kiwisolver-1.3.1     | 86 KB     |            |   0% \n",
      "kiwisolver-1.3.1     | 86 KB     | ########## | 100% \n",
      "\n",
      "jupyter_client-7.1.2 | 93 KB     |            |   0% \n",
      "jupyter_client-7.1.2 | 93 KB     | ########## | 100% \n",
      "\n",
      "six-1.16.0           | 18 KB     |            |   0% \n",
      "six-1.16.0           | 18 KB     | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 48 KB     |            |   0% \n",
      "libffi-3.2.1         | 48 KB     | ########## | 100% \n",
      "\n",
      "pillow-8.3.1         | 637 KB    |            |   0% \n",
      "pillow-8.3.1         | 637 KB    | ########## | 100% \n",
      "\n",
      "freetype-2.11.0      | 618 KB    |            |   0% \n",
      "freetype-2.11.0      | 618 KB    | ########## | 100% \n",
      "\n",
      "glib-2.63.1          | 2.9 MB    |            |   0% \n",
      "glib-2.63.1          | 2.9 MB    | ########## | 100% \n",
      "glib-2.63.1          | 2.9 MB    | ########## | 100% \n",
      "\n",
      "icu-58.2             | 10.5 MB   |            |   0% \n",
      "icu-58.2             | 10.5 MB   | ########## | 100% \n",
      "icu-58.2             | 10.5 MB   | ########## | 100% \n",
      "\n",
      "libpng-1.6.37        | 278 KB    |            |   0% \n",
      "libpng-1.6.37        | 278 KB    | ########## | 100% \n",
      "\n",
      "matplotlib-3.3.4     | 26 KB     |            |   0% \n",
      "matplotlib-3.3.4     | 26 KB     | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.3.0      | 4.8 MB    |            |   0% \n",
      "libgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \n",
      "libgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \n",
      "\n",
      "pexpect-4.8.0        | 53 KB     |            |   0% \n",
      "pexpect-4.8.0        | 53 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \n",
      "\n",
      "    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n",
      "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
      "\n",
      "    For example:\n",
      "\n",
      "        $ conda install scikit-learn-intelex\n",
      "        $ python -m sklearnex my_application.py\n",
      "\n",
      "    \n",
      "\n",
      "done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.o272rs4i.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.38.0-py3-none-any.whl (3.0 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azureml-inference-server-http~=0.4.1\n",
      "  Downloading azureml_inference_server_http-0.4.10-py3-none-any.whl (38 kB)\n",
      "Collecting azureml-core~=1.38.0\n",
      "  Downloading azureml_core-1.38.0.post2-py3-none-any.whl (2.5 MB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.38.0\n",
      "  Downloading azureml_dataset_runtime-1.38.0-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from pyarrow->-r /azureml-environment-setup/condaenv.o272rs4i.requirements.txt (line 2)) (1.19.2)\n",
      "Collecting azure-mgmt-storage<20.0.0,>=16.0.0\n",
      "  Downloading azure_mgmt_storage-19.1.0-py3-none-any.whl (1.8 MB)\n",
      "Collecting msrest<1.0.0,>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting ndg-httpsclient<=0.5.1\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting docker<6.0.0\n",
      "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Collecting pyopenssl<22.0.0\n",
      "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
      "Collecting pkginfo\n",
      "  Downloading pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting adal<=1.2.7,>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "Collecting jmespath<1.0.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting msal-extensions<0.4,>=0.3.0\n",
      "  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting paramiko<3.0.0,>=2.0.8\n",
      "  Downloading paramiko-2.9.2-py2.py3-none-any.whl (210 kB)\n",
      "Collecting azure-mgmt-resource<21.0.0,>=15.0.0\n",
      "  Downloading azure_mgmt_resource-20.1.0-py3-none-any.whl (2.3 MB)\n",
      "Collecting urllib3<=1.26.7,>=1.23\n",
      "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "Requirement already satisfied: pytz in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from azureml-core~=1.38.0->azureml-defaults->-r /azureml-environment-setup/condaenv.o272rs4i.requirements.txt (line 1)) (2021.3)\n",
      "Collecting packaging<22.0,>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting humanfriendly<11.0,>=4.7\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
      "Collecting knack~=0.8.2\n",
      "  Downloading knack-0.8.2-py3-none-any.whl (59 kB)\n",
      "Collecting msal<2.0.0,>=1.15.0\n",
      "  Downloading msal-1.17.0-py2.py3-none-any.whl (79 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting contextlib2<22.0.0\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting argcomplete<2.0\n",
      "  Downloading argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting azure-mgmt-containerregistry<9.0.0,>=8.2.0\n",
      "  Downloading azure_mgmt_containerregistry-8.2.0-py2.py3-none-any.whl (928 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from azureml-core~=1.38.0->azureml-defaults->-r /azureml-environment-setup/condaenv.o272rs4i.requirements.txt (line 1)) (2.8.2)\n",
      "Collecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting azure-core<1.22\n",
      "  Downloading azure_core-1.21.1-py2.py3-none-any.whl (178 kB)\n",
      "Collecting requests[socks]<3.0.0,>=2.19.1\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting importlib-metadata<5,>=0.23\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from azure-core<1.22->azureml-core~=1.38.0->azureml-defaults->-r /azureml-environment-setup/condaenv.o272rs4i.requirements.txt (line 1)) (1.16.0)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
      "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting azureml-dataprep<2.27.0a,>=2.26.0a\n",
      "  Downloading azureml_dataprep-2.26.0-py3-none-any.whl (39.4 MB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting azure-identity==1.7.0\n",
      "  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\n",
      "Collecting azureml-dataprep-rslex~=2.2.0dev0\n",
      "  Downloading azureml_dataprep_rslex-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (13.4 MB)\n",
      "Collecting cloudpickle<3.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
      "  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting inference-schema==1.3.0\n",
      "  Downloading inference_schema-1.3.0-py3-none-any.whl (19 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "Collecting itsdangerous<2.0,>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting Werkzeug>=0.14\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->-r /azureml-environment-setup/condaenv.o272rs4i.requirements.txt (line 1)) (58.0.4)\n",
      "Collecting wrapt<=1.12.1,>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.15.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (405 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: pygments in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from knack~=0.8.2->azureml-core~=1.38.0->azureml-defaults->-r /azureml-environment-setup/condaenv.o272rs4i.requirements.txt (line 1)) (2.11.2)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\n",
      "Collecting portalocker<3,>=1.0\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.38.0->azureml-defaults->-r /azureml-environment-setup/condaenv.o272rs4i.requirements.txt (line 1)) (2021.5.30)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib/python3.6/site-packages (from packaging<22.0,>=20.0->azureml-core~=1.38.0->azureml-defaults->-r /azureml-environment-setup/condaenv.o272rs4i.requirements.txt (line 1)) (3.0.4)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (61 kB)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, wrapt\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=ad284f6f5411a1cfac7eff0aa2b0adda967cc27040fcb9a12e82dd88c90c1b9b\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=3b3bd67368046c34721d1004a49f6598d75a5c9b505af77d9f8d0e4614b1850b\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69940 sha256=3453fa8049a1c18d292f5000f8a2ca5bb6945ad6fa72540dba79f83eca1f2032\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built json-logging-py fusepy wrapt\n",
      "Installing collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, requests, portalocker, oauthlib, msal, zipp, typing-extensions, requests-oauthlib, msal-extensions, isodate, distro, azure-core, msrest, MarkupSafe, importlib-metadata, dotnetcore2, dataclasses, cloudpickle, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, wrapt, Werkzeug, websocket-client, tabulate, pyyaml, PySocks, pyopenssl, pynacl, pyasn1, pyarrow, msrestazure, jmespath, Jinja2, jeepney, itsdangerous, colorama, click, bcrypt, backports.weakref, azureml-dataprep, azure-mgmt-core, azure-common, argcomplete, SecretStorage, pkginfo, pathspec, paramiko, packaging, ndg-httpsclient, knack, jsonpickle, inference-schema, humanfriendly, gunicorn, fusepy, flask, docker, contextlib2, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, applicationinsights, json-logging-py, configparser, azureml-inference-server-http, azureml-core, azureml-defaults\n",
      "Successfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.3.0 PySocks-1.7.1 SecretStorage-3.3.1 Werkzeug-2.0.3 adal-1.2.7 applicationinsights-0.11.10 argcomplete-1.12.3 azure-common-1.1.28 azure-core-1.21.1 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.2.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-20.1.0 azure-mgmt-storage-19.1.0 azureml-core-1.38.0.post2 azureml-dataprep-2.26.0 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.2.0 azureml-dataset-runtime-1.38.0 azureml-defaults-1.38.0 azureml-inference-server-http-0.4.10 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.0 cffi-1.15.0 charset-normalizer-2.0.12 click-8.0.4 cloudpickle-2.0.0 colorama-0.4.4 configparser-3.7.4 contextlib2-21.6.0 cryptography-36.0.1 dataclasses-0.8 distro-1.7.0 docker-5.0.3 dotnetcore2-2.1.23 flask-1.0.3 fusepy-3.0.1 gunicorn-20.1.0 humanfriendly-10.0 idna-3.3 importlib-metadata-4.8.3 inference-schema-1.3.0 isodate-0.6.1 itsdangerous-1.1.0 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.1.0 knack-0.8.2 msal-1.17.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.0 packaging-21.3 paramiko-2.9.2 pathspec-0.9.0 pkginfo-1.8.2 portalocker-2.4.0 pyarrow-3.0.0 pyasn1-0.4.8 pycparser-2.21 pynacl-1.5.0 pyopenssl-21.0.0 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 tabulate-0.8.9 typing-extensions-4.1.1 urllib3-1.26.7 websocket-client-1.2.3 wrapt-1.12.1 zipp-3.6.0\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 4.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mWARNING: /root/.conda/pkgs does not exist\n",
      "\n",
      "Removing intermediate container 441d3ce30326\n",
      " ---> ec1b746f9e86\n",
      "Step 9/21 : ENV PATH /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/bin:$PATH\n",
      " ---> Running in d1a2e4036ddf\n",
      "Removing intermediate container d1a2e4036ddf\n",
      " ---> 120ac2999350\n",
      "Step 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> cec3a920ba72\n",
      "Step 11/21 : RUN echo \"Copying environment context\"\n",
      " ---> Running in 0939b2100d03\n",
      "Copying environment context\n",
      "Removing intermediate container 0939b2100d03\n",
      " ---> a8754306f788\n",
      "Step 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> d54f5a6d88d7\n",
      "Step 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n",
      " ---> Running in ab9f76ab4163\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container ab9f76ab4163\n",
      " ---> ec2947a35f16\n",
      "Step 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n",
      " ---> Running in f654bf8579ac\n",
      "Removing intermediate container f654bf8579ac\n",
      " ---> 215c1241c4ea\n",
      "Step 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in b8b7bddaff28\n",
      "Removing intermediate container b8b7bddaff28\n",
      " ---> 6b9407a0b3b8\n",
      "Step 16/21 : ENV CONDA_DEFAULT_ENV=azureml_0c5a9aa2def4b3c2501c1f40287a356b CONDA_PREFIX=/azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b\n",
      " ---> Running in 95daa21bac37\n",
      "Removing intermediate container 95daa21bac37\n",
      " ---> dfdc89c5c08e\n",
      "Step 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> bd242fa48ad2\n",
      "Step 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in cb5f40032e45\n",
      "Removing intermediate container cb5f40032e45\n",
      " ---> 07f098d992b6\n",
      "Step 19/21 : RUN rm -rf azureml-environment-setup\n",
      " ---> Running in b4df9c0d323d\n",
      "Removing intermediate container b4df9c0d323d\n",
      " ---> 0cf971107f4b\n",
      "Step 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 819785c39558\n",
      "Removing intermediate container 819785c39558\n",
      " ---> c6d399e40b79\n",
      "Step 21/21 : CMD [\"bash\"]\n",
      " ---> Running in bca8ddcfcc78\n",
      "Removing intermediate container bca8ddcfcc78\n",
      " ---> e34a53bc09be\n",
      "Successfully built e34a53bc09be\n",
      "Successfully tagged 57a0fe8119344a2288985e401a74b8ea.azurecr.io/azureml/azureml_518da681c57f375733c089918b8d5dc9:latest\n",
      "Successfully tagged 57a0fe8119344a2288985e401a74b8ea.azurecr.io/azureml/azureml_518da681c57f375733c089918b8d5dc9:1\n",
      "2022/02/24 21:47:39 Successfully executed container: acb_step_0\n",
      "2022/02/24 21:47:39 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/02/24 21:47:39 Pushing image: 57a0fe8119344a2288985e401a74b8ea.azurecr.io/azureml/azureml_518da681c57f375733c089918b8d5dc9:1, attempt 1\n",
      "The push refers to repository [57a0fe8119344a2288985e401a74b8ea.azurecr.io/azureml/azureml_518da681c57f375733c089918b8d5dc9]\n",
      "27fd5e4ea47a: Preparing\n",
      "7e2ec0314d6a: Preparing\n",
      "ba86dd02bb12: Preparing\n",
      "325f37e0caca: Preparing\n",
      "674c29e1fa14: Preparing\n",
      "6dd536cf66de: Preparing\n",
      "9d0a7184e8f2: Preparing\n",
      "7906bca00e80: Preparing\n",
      "e60e19d988fd: Preparing\n",
      "b14ef30121ef: Preparing\n",
      "5a63f0a64b99: Preparing\n",
      "cfd97667b73b: Preparing\n",
      "dda643f89a6b: Preparing\n",
      "06f4d263b25f: Preparing\n",
      "5ecae586bbba: Preparing\n",
      "eb66e810a3df: Preparing\n",
      "081c0f822cac: Preparing\n",
      "0be4c2d28ad7: Preparing\n",
      "40a154bd3352: Preparing\n",
      "6dd536cf66de: Waiting\n",
      "9d0a7184e8f2: Waiting\n",
      "7906bca00e80: Waiting\n",
      "e60e19d988fd: Waiting\n",
      "b14ef30121ef: Waiting\n",
      "5a63f0a64b99: Waiting\n",
      "cfd97667b73b: Waiting\n",
      "dda643f89a6b: Waiting\n",
      "06f4d263b25f: Waiting\n",
      "5ecae586bbba: Waiting\n",
      "eb66e810a3df: Waiting\n",
      "0be4c2d28ad7: Waiting\n",
      "081c0f822cac: Waiting\n",
      "40a154bd3352: Waiting\n",
      "27fd5e4ea47a: Pushed\n",
      "325f37e0caca: Pushed\n",
      "674c29e1fa14: Pushed\n",
      "ba86dd02bb12: Pushed\n",
      "7e2ec0314d6a: Pushed\n",
      "9d0a7184e8f2: Pushed\n",
      "7906bca00e80: Pushed\n",
      "e60e19d988fd: Pushed\n",
      "b14ef30121ef: Pushed\n",
      "5a63f0a64b99: Pushed\n",
      "cfd97667b73b: Pushed\n",
      "dda643f89a6b: Pushed\n",
      "06f4d263b25f: Pushed\n",
      "081c0f822cac: Pushed\n",
      "eb66e810a3df: Pushed\n",
      "5ecae586bbba: Pushed\n",
      "40a154bd3352: Pushed\n",
      "0be4c2d28ad7: Pushed\n",
      "6dd536cf66de: Pushed\n",
      "1: digest: sha256:b94eb5f5e42714c7ba50a914e623f16996f12214a0dac4377ab11f052cf5e8c3 size: 4307\n",
      "2022/02/24 21:49:40 Successfully pushed image: 57a0fe8119344a2288985e401a74b8ea.azurecr.io/azureml/azureml_518da681c57f375733c089918b8d5dc9:1\n",
      "2022/02/24 21:49:40 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/02/24 21:49:40 Pushing image: 57a0fe8119344a2288985e401a74b8ea.azurecr.io/azureml/azureml_518da681c57f375733c089918b8d5dc9:latest, attempt 1\n",
      "The push refers to repository [57a0fe8119344a2288985e401a74b8ea.azurecr.io/azureml/azureml_518da681c57f375733c089918b8d5dc9]\n",
      "27fd5e4ea47a: Preparing\n",
      "7e2ec0314d6a: Preparing\n",
      "ba86dd02bb12: Preparing\n",
      "325f37e0caca: Preparing\n",
      "674c29e1fa14: Preparing\n",
      "6dd536cf66de: Preparing\n",
      "9d0a7184e8f2: Preparing\n",
      "7906bca00e80: Preparing\n",
      "e60e19d988fd: Preparing\n",
      "b14ef30121ef: Preparing\n",
      "5a63f0a64b99: Preparing\n",
      "cfd97667b73b: Preparing\n",
      "dda643f89a6b: Preparing\n",
      "06f4d263b25f: Preparing\n",
      "5ecae586bbba: Preparing\n",
      "eb66e810a3df: Preparing\n",
      "081c0f822cac: Preparing\n",
      "0be4c2d28ad7: Preparing\n",
      "40a154bd3352: Preparing\n",
      "6dd536cf66de: Waiting\n",
      "9d0a7184e8f2: Waiting\n",
      "7906bca00e80: Waiting\n",
      "e60e19d988fd: Waiting\n",
      "b14ef30121ef: Waiting\n",
      "5a63f0a64b99: Waiting\n",
      "cfd97667b73b: Waiting\n",
      "dda643f89a6b: Waiting\n",
      "06f4d263b25f: Waiting\n",
      "5ecae586bbba: Waiting\n",
      "eb66e810a3df: Waiting\n",
      "081c0f822cac: Waiting\n",
      "0be4c2d28ad7: Waiting\n",
      "40a154bd3352: Waiting\n",
      "325f37e0caca: Layer already exists\n",
      "27fd5e4ea47a: Layer already exists\n",
      "ba86dd02bb12: Layer already exists\n",
      "7e2ec0314d6a: Layer already exists\n",
      "674c29e1fa14: Layer already exists\n",
      "9d0a7184e8f2: Layer already exists\n",
      "6dd536cf66de: Layer already exists\n",
      "7906bca00e80: Layer already exists\n",
      "b14ef30121ef: Layer already exists\n",
      "e60e19d988fd: Layer already exists\n",
      "5a63f0a64b99: Layer already exists\n",
      "dda643f89a6b: Layer already exists\n",
      "cfd97667b73b: Layer already exists\n",
      "5ecae586bbba: Layer already exists\n",
      "eb66e810a3df: Layer already exists\n",
      "081c0f822cac: Layer already exists\n",
      "0be4c2d28ad7: Layer already exists\n",
      "40a154bd3352: Layer already exists\n",
      "06f4d263b25f: Layer already exists\n",
      "latest: digest: sha256:b94eb5f5e42714c7ba50a914e623f16996f12214a0dac4377ab11f052cf5e8c3 size: 4307\n",
      "2022/02/24 21:49:43 Successfully pushed image: 57a0fe8119344a2288985e401a74b8ea.azurecr.io/azureml/azureml_518da681c57f375733c089918b8d5dc9:latest\n",
      "2022/02/24 21:49:43 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 141.661458)\n",
      "2022/02/24 21:49:43 Populating digests for step ID: acb_step_0...\n",
      "2022/02/24 21:49:44 Successfully populated digests for step ID: acb_step_0\n",
      "2022/02/24 21:49:44 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 121.121638)\n",
      "2022/02/24 21:49:44 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 2.336044)\n",
      "2022/02/24 21:49:44 The following dependencies were found:\n",
      "2022/02/24 21:49:44 \n",
      "- image:\n",
      "    registry: 57a0fe8119344a2288985e401a74b8ea.azurecr.io\n",
      "    repository: azureml/azureml_518da681c57f375733c089918b8d5dc9\n",
      "    tag: latest\n",
      "    digest: sha256:b94eb5f5e42714c7ba50a914e623f16996f12214a0dac4377ab11f052cf5e8c3\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20220113.v1\n",
      "    digest: sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 57a0fe8119344a2288985e401a74b8ea.azurecr.io\n",
      "    repository: azureml/azureml_518da681c57f375733c089918b8d5dc9\n",
      "    tag: \"1\"\n",
      "    digest: sha256:b94eb5f5e42714c7ba50a914e623f16996f12214a0dac4377ab11f052cf5e8c3\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20220113.v1\n",
      "    digest: sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cmc was successful after 4m30s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StepRun(Prepare Data) Execution Summary\n",
      "========================================\n",
      "StepRun( Prepare Data ) Status: Finished\n",
      "{'runId': 'a06b5b5d-3e78-4506-8be1-fb5d984e8b6d', 'target': 'computeclusterlr', 'status': 'Completed', 'startTimeUtc': '2022-02-24T21:52:29.284272Z', 'endTimeUtc': '2022-02-24T21:54:05.652793Z', 'services': {}, 'properties': {'ContentSnapshotId': '4a6ed810-2ff9-4a9a-b9c0-eb4be41616db', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '2b9c70dc-0874-42dd-bdb0-b5edf07eb4df', 'azureml.moduleName': 'Prepare Data', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '39b82eec', 'azureml.pipelinerunid': 'a858009b-9c6f-4337-a9cc-baa662bbff8c', 'azureml.pipeline': 'a858009b-9c6f-4337-a9cc-baa662bbff8c', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '6c4883fa-1f48-4ea1-a6d5-5fecfeedddd5'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': 'a81e687b-334f-438c-add6-a03aaf409319'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'prepped_data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('skdatastore', 'dataset/a06b5b5d-3e78-4506-8be1-fb5d984e8b6d/prepped_data/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"a81e687b-334f-438c-add6-a03aaf409319\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='aml_ws', subscription_id='8f35cf98-68ff-457e-b1b3-e05921a0fd46', resource_group='rg-lr-dp100')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'prep_sk.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', 'DatasetOutputConfig:prepped_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'computeclusterlr', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '6c4883fa-1f48-4ea1-a6d5-5fecfeedddd5', 'name': None, 'version': '3'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'prepped_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'skdatastore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': 'a858009b-9c6f-4337-a9cc-baa662bbff8c', 'azureml.pipelineRun.moduleNodeId': '39b82eec', 'azureml.pipelineRun.outputPortName': 'prepped_data'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '2', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a06b5b5d-3e78-4506-8be1-fb5d984e8b6d/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=3Ss7Mr5uctcxKNwl6kotEjUHB4ItyhwHP%2BM4qcKFwvo%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T14%3A17%3A28Z&ske=2022-02-25T22%3A27%3A28Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A40%3A13Z&se=2022-02-25T05%3A50%3A13Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a06b5b5d-3e78-4506-8be1-fb5d984e8b6d/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=5qe%2FMuo9PwQtJPXo8FQUeP9dMvbO5m58EobvlxzHbC4%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T15%3A10%3A13Z&ske=2022-02-25T23%3A20%3A13Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A44%3A02Z&se=2022-02-25T05%3A54%3A02Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a06b5b5d-3e78-4506-8be1-fb5d984e8b6d/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=cxJJR0vL8MS5hBufy1CKj2vsjhLPcMuO0AytYuFQ50c%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T15%3A10%3A13Z&ske=2022-02-25T23%3A20%3A13Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A44%3A02Z&se=2022-02-25T05%3A54%3A02Z&sp=r', 'logs/azureml/dataprep/rslex.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a06b5b5d-3e78-4506-8be1-fb5d984e8b6d/logs/azureml/dataprep/rslex.log?sv=2019-07-07&sr=b&sig=xihIH4SyBxzdazuKX92ha53h%2BVzwDQE3s5kyTS4SuO0%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T15%3A10%3A13Z&ske=2022-02-25T23%3A20%3A13Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A44%3A02Z&se=2022-02-25T05%3A54%3A02Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a06b5b5d-3e78-4506-8be1-fb5d984e8b6d/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=UhzwFVrfG0lhnpFls6HIJF3naqLKgcOmGpn%2BBaJj0pg%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T15%3A10%3A13Z&ske=2022-02-25T23%3A20%3A13Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A44%3A02Z&se=2022-02-25T05%3A54%3A02Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a06b5b5d-3e78-4506-8be1-fb5d984e8b6d/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=0D0n75134z6e%2Bgi11UPsRYyQYaB%2BftdHhTRlZvPDJ2E%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T15%3A10%3A13Z&ske=2022-02-25T23%3A20%3A13Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A44%3A02Z&se=2022-02-25T05%3A54%3A02Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a06b5b5d-3e78-4506-8be1-fb5d984e8b6d/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=RrrMO9ymnUV%2BqI76KIbJ%2BG3MUbY3cM27YQpZ%2FGP%2B2Pw%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T15%3A10%3A13Z&ske=2022-02-25T23%3A20%3A13Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A44%3A02Z&se=2022-02-25T05%3A54%3A02Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 086d73c0-07c6-4b90-9489-739e62f0d653\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/086d73c0-07c6-4b90-9489-739e62f0d653?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "StepRun( Train and Register Model ) Status: Running\n",
      "\n",
      "StepRun(Train and Register Model) Execution Summary\n",
      "====================================================\n",
      "StepRun( Train and Register Model ) Status: Finished\n",
      "{'runId': '086d73c0-07c6-4b90-9489-739e62f0d653', 'target': 'computeclusterlr', 'status': 'Completed', 'startTimeUtc': '2022-02-24T21:54:14.669357Z', 'endTimeUtc': '2022-02-24T21:54:35.657639Z', 'services': {}, 'properties': {'ContentSnapshotId': '4a6ed810-2ff9-4a9a-b9c0-eb4be41616db', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'dd978f2d-11cd-438a-a935-c1f61e7c1f01', 'azureml.moduleName': 'Train and Register Model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '202bf198', 'azureml.pipelinerunid': 'a858009b-9c6f-4337-a9cc-baa662bbff8c', 'azureml.pipeline': 'a858009b-9c6f-4337-a9cc-baa662bbff8c', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'a81e687b-334f-438c-add6-a03aaf409319'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input_4742e640', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'sk_training.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--training-data', 'DatasetConsumptionConfig:input_4742e640'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'computeclusterlr', 'dataReferences': {}, 'data': {'input_4742e640': {'dataLocation': {'dataset': {'id': 'a81e687b-334f-438c-add6-a03aaf409319', 'name': None, 'version': None}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'environmentVariableName': 'input_4742e640', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': '2', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.086d73c0-07c6-4b90-9489-739e62f0d653/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=GhnaaT4TuhWELn9lC2ZgyAE%2BaOEvVIM8imzOmnnDr%2BA%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T14%3A17%3A32Z&ske=2022-02-25T22%3A27%3A32Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A44%3A12Z&se=2022-02-25T05%3A54%3A12Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.086d73c0-07c6-4b90-9489-739e62f0d653/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=LvDxbfyRAnh8pLQA7ZrAEqHZqlA4%2Ff6Xomt1jJ3znYo%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T14%3A17%3A32Z&ske=2022-02-25T22%3A27%3A32Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A44%3A12Z&se=2022-02-25T05%3A54%3A12Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.086d73c0-07c6-4b90-9489-739e62f0d653/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=qODP%2BPg1os8LSkwqqXf4KmLtnRj8Kn6NsWFmKK6U1CQ%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T14%3A17%3A32Z&ske=2022-02-25T22%3A27%3A32Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A44%3A12Z&se=2022-02-25T05%3A54%3A12Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'a858009b-9c6f-4337-a9cc-baa662bbff8c', 'status': 'Completed', 'startTimeUtc': '2022-02-24T21:45:07.01696Z', 'endTimeUtc': '2022-02-24T21:54:36.923436Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a858009b-9c6f-4337-a9cc-baa662bbff8c/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=V37dyMQoVQtglFYWHFQC%2B%2BjzRdSof53pN%2BzaY0RFzu4%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T14%3A17%3A28Z&ske=2022-02-25T22%3A27%3A28Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A40%3A29Z&se=2022-02-25T05%3A50%3A29Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a858009b-9c6f-4337-a9cc-baa662bbff8c/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=AaNNWxntIR8%2FTx8DnF3DhQix0GYp1eL6bkllflCRVZM%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T14%3A17%3A28Z&ske=2022-02-25T22%3A27%3A28Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A40%3A29Z&se=2022-02-25T05%3A50%3A29Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.a858009b-9c6f-4337-a9cc-baa662bbff8c/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=A4n6cm7JE9ljl4g3l%2B0WRJb0UeibdV2%2B3URylDvdnZg%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-24T14%3A17%3A28Z&ske=2022-02-25T22%3A27%3A28Z&sks=b&skv=2019-07-07&st=2022-02-24T21%3A40%3A29Z&se=2022-02-25T05%3A50%3A29Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [prep_step, train_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace=ws, name = 'azml-sk-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "615abec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Register Model :\n",
      "\t Accuracy : 0.5057803468208093\n",
      "Prepare Data :\n",
      "\t processed_rows : 1151\n"
     ]
    }
   ],
   "source": [
    "for run in pipeline_run.get_children():\n",
    "    print(run.name, ':')\n",
    "    metrics = run.get_metrics()\n",
    "    for metric_name in metrics:\n",
    "        print('\\t',metric_name, \":\", metrics[metric_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5aa4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_model version: 7\n",
      "\t Training context : Pipeline\n",
      "\t Accuracy : 0.5057803468208093\n",
      "\n",
      "\n",
      "sk_model_v4 version: 2\n",
      "\n",
      "\n",
      "sk_model_v2 version: 2\n",
      "\n",
      "\n",
      "sk_model_v2 version: 1\n",
      "\n",
      "\n",
      "sk_model_initial version: 2\n",
      "\n",
      "\n",
      "sk_model version: 5\n",
      "\t Training context : Auto ML in pipeline\n",
      "\t AUC : 0.014550774687038625\n",
      "\n",
      "\n",
      "AutoML0b24ea5a20 version: 1\n",
      "\n",
      "\n",
      "amlstudio-test-deploy-v2 version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "amlstudio-test-endpoint-lr version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "diabetes_model version: 11\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8832778417290374\n",
      "\t Accuracy : 0.8991111111111111\n",
      "\n",
      "\n",
      "diabetes_mitigated_20 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_19 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_18 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_17 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_16 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_15 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_14 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_13 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_12 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_11 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_10 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_9 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_8 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_7 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_6 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_5 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_4 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_3 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_2 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_1 version: 1\n",
      "\n",
      "\n",
      "diabetes_unmitigated version: 1\n",
      "\n",
      "\n",
      "diabetes_classifier version: 1\n",
      "\n",
      "\n",
      "diabetes_model version: 10\n",
      "\t Training context : Auto ML\n",
      "\t AUC : 0.9904812577250306\n",
      "\t Accuracy : 0.9520809898762654\n",
      "\n",
      "\n",
      "diabetes_model version: 9\n",
      "\t Training context : Hyperdrive\n",
      "\t AUC : 0.9885804604667666\n",
      "\t Accuracy : 0.9457777777777778\n",
      "\n",
      "\n",
      "diabetes_model version: 8\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8755584854967908\n",
      "\t Accuracy : 0.8863333333333333\n",
      "\n",
      "\n",
      "diabetes_model version: 7\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.879600975172894\n",
      "\t Accuracy : 0.8926666666666667\n",
      "\n",
      "\n",
      "diabetes_model version: 6\n",
      "\t Training context : Pipeline\n",
      "\t AUC : 0.8837616052365906\n",
      "\t Accuracy : 0.8988888888888888\n",
      "\n",
      "\n",
      "diabetes_model version: 5\n",
      "\t Training context : File dataset\n",
      "\t AUC : 0.8568743524381947\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 4\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8483964376337131\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8483999203940495\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC : 0.8484929598487486\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87e9ac42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>azml-sk-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/4378c267-0738-4788-a7a3-79e6886e88d1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws\" target=\"_blank\" rel=\"noopener\">4378c267-0738-4788-a7a3-79e6886e88d1</a></td><td>Active</td><td><a href=\"https://southeastasia.api.azureml.ms/pipelines/v1.0/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/PipelineRuns/PipelineSubmit/4378c267-0738-4788-a7a3-79e6886e88d1\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: azml-sk-pipeline,\n",
       "Id: 4378c267-0738-4788-a7a3-79e6886e88d1,\n",
       "Status: Active,\n",
       "Endpoint: https://southeastasia.api.azureml.ms/pipelines/v1.0/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/PipelineRuns/PipelineSubmit/4378c267-0738-4788-a7a3-79e6886e88d1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Publish the pipeline from the run\n",
    "\n",
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"azml-sk-pipeline\", description=\"Trains and registers a logistic regression on sk data\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01774225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://southeastasia.api.azureml.ms/pipelines/v1.0/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/PipelineRuns/PipelineSubmit/4378c267-0738-4788-a7a3-79e6886e88d1\n"
     ]
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rerun pipeline from published endpoint - Triggers a fresh pipeline but it will be faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5893aa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication header ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print(\"Authentication header ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "experiment_name = 'azml-sk-pipeline'\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f450e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "published_pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34daef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets deploy for real time inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3c2908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_model version 7\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['sk_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec34c636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sk_service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the deployment files\n",
    "deployment_folder = './sk_service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'score_sk.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51f7b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sk_service/score_sk.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "from azureml.core import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "   \n",
    "    model_path = Model.get_model_path(\"sk_model\")\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(data):\n",
    "    result = model.predict(data)\n",
    "    return {\"result\": result.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbafab01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./sk_service/score_sk.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "\n",
    "\n",
    "input_sample = [{\n",
    "    \"Model\": \"Grand Punto\",\n",
    "    \"Length\": 4000,\n",
    "    \"Type\":\"Compact-Regular\",\n",
    "    \"Style\":\"Hatchback\",\n",
    "    \"OEM\":\"Fiat\",\n",
    "    \"Engine Disp\":1.4,\n",
    "    \"Age of OEM\":8,\n",
    "    \"Mileage\":16,\n",
    "    \"Oil Price\":102.1,\n",
    "    \"Petrol\":\"Y\", \n",
    "    \"Automatic\":\"N\",\n",
    "    \"Price\":5\n",
    "  }]\n",
    "output_sample = [[1207]]\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path(\"sk_model\")\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "#input_sample = {'Model':['Grand Punto'],'Length':[4000],'Type':['Compact-Regular'],'Style':['Hatchback'],'OEM':['Fiat'],'Engine Disp':[1.4],'Age of OEM':[8],'Year':['1/14/2022'],'Mileage':[16], 'Oil Price':[102.1], 'Petrol':['Y'], 'Automatic':['N'], 'Price':[5]}\n",
    "#output_sample = {'prediction':[[1207]]}\n",
    "\n",
    "\n",
    "\n",
    "# Inference_schema generates a schema for your web service\n",
    "# It then creates an OpenAPI (Swagger) specification for the web service\n",
    "# at http://<scoring_base_url>/swagger.json\n",
    "\n",
    "@input_schema('data', StandardPythonParameterType(input_sample))\n",
    "@output_schema(StandardPythonParameterType(output_sample))\n",
    "\n",
    "def run(data):\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        pred = model.predict(df)\n",
    "        result = {\"predict\":pred.tolist()}\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede91305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-02-25 04:30:31+00:00 Creating Container Registry if not exists.\n",
      "2022-02-25 04:30:31+00:00 Registering the environment.\n",
      "2022-02-25 04:30:33+00:00 Use the existing image.\n",
      "2022-02-25 04:30:33+00:00 Generating deployment configuration.\n",
      "2022-02-25 04:30:34+00:00 Submitting deployment to compute..\n",
      "2022-02-25 04:30:37+00:00 Checking the status of deployment sk-service."
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Configure the scoring environment\n",
    "service_env = Environment(name='service-env')\n",
    "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk']\n",
    "for package in python_packages:\n",
    "    service_env.python.conda_dependencies.add_pip_package(package)\n",
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script=script_file,\n",
    "                                   environment=service_env)\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"sk-service\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de711a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://df4f6411-cd20-4228-882b-19853b6a7dd8.southeastasia.azurecontainer.io/score\n",
      "http://df4f6411-cd20-4228-882b-19853b6a7dd8.southeastasia.azurecontainer.io/swagger.json\n"
     ]
    }
   ],
   "source": [
    "# Get service from Workspace\n",
    "from azureml.core import Webservice\n",
    "\n",
    "service = Webservice(workspace=ws, name='sk-service')\n",
    "\n",
    "print(service.scoring_uri)\n",
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9bf113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = service.scoring_uri\n",
    "\n",
    "test_data = {\n",
    "  'data': [{\n",
    "    \"Model\": \"Grand Punto\",\n",
    "    \"Length\": 4000,\n",
    "    \"Type\":\"Compact-Regular\",\n",
    "    \"Style\":\"Hatchback\",\n",
    "    \"OEM\":\"Fiat\",\n",
    "    \"Engine Disp\":1.4,\n",
    "    \"Age of OEM\":8,\n",
    "    \"Year\":\"'1/14/2022\",\n",
    "    \"Mileage\":16,\n",
    "    \"Oil Price\":102.1,\n",
    "    \"Petrol\":\"Y\", \n",
    "    \"Automatic\":\"N\",\n",
    "    \"Price\":5\n",
    "  }]\n",
    "}\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "resp = requests.post(url, json=test_data, headers=headers)\n",
    "\n",
    "print(\"Prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248ce97",
   "metadata": {},
   "source": [
    "## Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110579f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.38.0 to work with aml_ws\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a213a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skdatastore - Default = True\n",
      "azureml_globaldatasets - Default = False\n",
      "workspaceworkingdirectory - Default = False\n",
      "workspacefilestore - Default = False\n",
      "workspaceartifactstore - Default = False\n",
      "workspaceblobstore - Default = False\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a73af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created!\n",
      "Saving files...\n",
      "files saved!\n",
      "Uploading files to datastore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 100 files\n",
      "Uploading batch-data/1.csv\n",
      "Uploaded batch-data/1.csv, 1 files out of an estimated total of 100\n",
      "Uploading batch-data/10.csv\n",
      "Uploaded batch-data/10.csv, 2 files out of an estimated total of 100\n",
      "Uploading batch-data/100.csv\n",
      "Uploaded batch-data/100.csv, 3 files out of an estimated total of 100\n",
      "Uploading batch-data/11.csv\n",
      "Uploaded batch-data/11.csv, 4 files out of an estimated total of 100\n",
      "Uploading batch-data/12.csv\n",
      "Uploaded batch-data/12.csv, 5 files out of an estimated total of 100\n",
      "Uploading batch-data/13.csv\n",
      "Uploaded batch-data/13.csv, 6 files out of an estimated total of 100\n",
      "Uploading batch-data/14.csv\n",
      "Uploaded batch-data/14.csv, 7 files out of an estimated total of 100\n",
      "Uploading batch-data/15.csv\n",
      "Uploaded batch-data/15.csv, 8 files out of an estimated total of 100\n",
      "Uploading batch-data/16.csv\n",
      "Uploaded batch-data/16.csv, 9 files out of an estimated total of 100\n",
      "Uploading batch-data/17.csv\n",
      "Uploaded batch-data/17.csv, 10 files out of an estimated total of 100\n",
      "Uploading batch-data/18.csv\n",
      "Uploaded batch-data/18.csv, 11 files out of an estimated total of 100\n",
      "Uploading batch-data/19.csv\n",
      "Uploaded batch-data/19.csv, 12 files out of an estimated total of 100\n",
      "Uploading batch-data/2.csv\n",
      "Uploaded batch-data/2.csv, 13 files out of an estimated total of 100\n",
      "Uploading batch-data/20.csv\n",
      "Uploaded batch-data/20.csv, 14 files out of an estimated total of 100\n",
      "Uploading batch-data/21.csv\n",
      "Uploaded batch-data/21.csv, 15 files out of an estimated total of 100\n",
      "Uploading batch-data/22.csv\n",
      "Uploaded batch-data/22.csv, 16 files out of an estimated total of 100\n",
      "Uploading batch-data/23.csv\n",
      "Uploaded batch-data/23.csv, 17 files out of an estimated total of 100\n",
      "Uploading batch-data/24.csv\n",
      "Uploaded batch-data/24.csv, 18 files out of an estimated total of 100\n",
      "Uploading batch-data/25.csv\n",
      "Uploaded batch-data/25.csv, 19 files out of an estimated total of 100\n",
      "Uploading batch-data/26.csv\n",
      "Uploaded batch-data/26.csv, 20 files out of an estimated total of 100\n",
      "Uploading batch-data/27.csv\n",
      "Uploaded batch-data/27.csv, 21 files out of an estimated total of 100\n",
      "Uploading batch-data/28.csv\n",
      "Uploaded batch-data/28.csv, 22 files out of an estimated total of 100\n",
      "Uploading batch-data/29.csv\n",
      "Uploaded batch-data/29.csv, 23 files out of an estimated total of 100\n",
      "Uploading batch-data/3.csv\n",
      "Uploaded batch-data/3.csv, 24 files out of an estimated total of 100\n",
      "Uploading batch-data/30.csv\n",
      "Uploaded batch-data/30.csv, 25 files out of an estimated total of 100\n",
      "Uploading batch-data/31.csv\n",
      "Uploaded batch-data/31.csv, 26 files out of an estimated total of 100\n",
      "Uploading batch-data/32.csv\n",
      "Uploaded batch-data/32.csv, 27 files out of an estimated total of 100\n",
      "Uploading batch-data/33.csv\n",
      "Uploaded batch-data/33.csv, 28 files out of an estimated total of 100\n",
      "Uploading batch-data/34.csv\n",
      "Uploaded batch-data/34.csv, 29 files out of an estimated total of 100\n",
      "Uploading batch-data/35.csv\n",
      "Uploaded batch-data/35.csv, 30 files out of an estimated total of 100\n",
      "Uploading batch-data/36.csv\n",
      "Uploaded batch-data/36.csv, 31 files out of an estimated total of 100\n",
      "Uploading batch-data/37.csv\n",
      "Uploaded batch-data/37.csv, 32 files out of an estimated total of 100\n",
      "Uploading batch-data/38.csv\n",
      "Uploaded batch-data/38.csv, 33 files out of an estimated total of 100\n",
      "Uploading batch-data/39.csv\n",
      "Uploaded batch-data/39.csv, 34 files out of an estimated total of 100\n",
      "Uploading batch-data/4.csv\n",
      "Uploaded batch-data/4.csv, 35 files out of an estimated total of 100\n",
      "Uploading batch-data/40.csv\n",
      "Uploaded batch-data/40.csv, 36 files out of an estimated total of 100\n",
      "Uploading batch-data/41.csv\n",
      "Uploaded batch-data/41.csv, 37 files out of an estimated total of 100\n",
      "Uploading batch-data/42.csv\n",
      "Uploaded batch-data/42.csv, 38 files out of an estimated total of 100\n",
      "Uploading batch-data/43.csv\n",
      "Uploaded batch-data/43.csv, 39 files out of an estimated total of 100\n",
      "Uploading batch-data/44.csv\n",
      "Uploaded batch-data/44.csv, 40 files out of an estimated total of 100\n",
      "Uploading batch-data/45.csv\n",
      "Uploaded batch-data/45.csv, 41 files out of an estimated total of 100\n",
      "Uploading batch-data/46.csv\n",
      "Uploaded batch-data/46.csv, 42 files out of an estimated total of 100\n",
      "Uploading batch-data/47.csv\n",
      "Uploaded batch-data/47.csv, 43 files out of an estimated total of 100\n",
      "Uploading batch-data/48.csv\n",
      "Uploaded batch-data/48.csv, 44 files out of an estimated total of 100\n",
      "Uploading batch-data/49.csv\n",
      "Uploaded batch-data/49.csv, 45 files out of an estimated total of 100\n",
      "Uploading batch-data/5.csv\n",
      "Uploaded batch-data/5.csv, 46 files out of an estimated total of 100\n",
      "Uploading batch-data/50.csv\n",
      "Uploaded batch-data/50.csv, 47 files out of an estimated total of 100\n",
      "Uploading batch-data/51.csv\n",
      "Uploaded batch-data/51.csv, 48 files out of an estimated total of 100\n",
      "Uploading batch-data/52.csv\n",
      "Uploaded batch-data/52.csv, 49 files out of an estimated total of 100\n",
      "Uploading batch-data/53.csv\n",
      "Uploaded batch-data/53.csv, 50 files out of an estimated total of 100\n",
      "Uploading batch-data/54.csv\n",
      "Uploaded batch-data/54.csv, 51 files out of an estimated total of 100\n",
      "Uploading batch-data/55.csv\n",
      "Uploaded batch-data/55.csv, 52 files out of an estimated total of 100\n",
      "Uploading batch-data/56.csv\n",
      "Uploaded batch-data/56.csv, 53 files out of an estimated total of 100\n",
      "Uploading batch-data/57.csv\n",
      "Uploaded batch-data/57.csv, 54 files out of an estimated total of 100\n",
      "Uploading batch-data/58.csv\n",
      "Uploaded batch-data/58.csv, 55 files out of an estimated total of 100\n",
      "Uploading batch-data/59.csv\n",
      "Uploaded batch-data/59.csv, 56 files out of an estimated total of 100\n",
      "Uploading batch-data/6.csv\n",
      "Uploaded batch-data/6.csv, 57 files out of an estimated total of 100\n",
      "Uploading batch-data/60.csv\n",
      "Uploaded batch-data/60.csv, 58 files out of an estimated total of 100\n",
      "Uploading batch-data/61.csv\n",
      "Uploaded batch-data/61.csv, 59 files out of an estimated total of 100\n",
      "Uploading batch-data/62.csv\n",
      "Uploaded batch-data/62.csv, 60 files out of an estimated total of 100\n",
      "Uploading batch-data/63.csv\n",
      "Uploaded batch-data/63.csv, 61 files out of an estimated total of 100\n",
      "Uploading batch-data/64.csv\n",
      "Uploaded batch-data/64.csv, 62 files out of an estimated total of 100\n",
      "Uploading batch-data/65.csv\n",
      "Uploaded batch-data/65.csv, 63 files out of an estimated total of 100\n",
      "Uploading batch-data/66.csv\n",
      "Uploaded batch-data/66.csv, 64 files out of an estimated total of 100\n",
      "Uploading batch-data/67.csv\n",
      "Uploaded batch-data/67.csv, 65 files out of an estimated total of 100\n",
      "Uploading batch-data/68.csv\n",
      "Uploaded batch-data/68.csv, 66 files out of an estimated total of 100\n",
      "Uploading batch-data/69.csv\n",
      "Uploaded batch-data/69.csv, 67 files out of an estimated total of 100\n",
      "Uploading batch-data/7.csv\n",
      "Uploaded batch-data/7.csv, 68 files out of an estimated total of 100\n",
      "Uploading batch-data/70.csv\n",
      "Uploaded batch-data/70.csv, 69 files out of an estimated total of 100\n",
      "Uploading batch-data/71.csv\n",
      "Uploaded batch-data/71.csv, 70 files out of an estimated total of 100\n",
      "Uploading batch-data/72.csv\n",
      "Uploaded batch-data/72.csv, 71 files out of an estimated total of 100\n",
      "Uploading batch-data/73.csv\n",
      "Uploaded batch-data/73.csv, 72 files out of an estimated total of 100\n",
      "Uploading batch-data/74.csv\n",
      "Uploaded batch-data/74.csv, 73 files out of an estimated total of 100\n",
      "Uploading batch-data/75.csv\n",
      "Uploaded batch-data/75.csv, 74 files out of an estimated total of 100\n",
      "Uploading batch-data/76.csv\n",
      "Uploaded batch-data/76.csv, 75 files out of an estimated total of 100\n",
      "Uploading batch-data/77.csv\n",
      "Uploaded batch-data/77.csv, 76 files out of an estimated total of 100\n",
      "Uploading batch-data/78.csv\n",
      "Uploaded batch-data/78.csv, 77 files out of an estimated total of 100\n",
      "Uploading batch-data/79.csv\n",
      "Uploaded batch-data/79.csv, 78 files out of an estimated total of 100\n",
      "Uploading batch-data/8.csv\n",
      "Uploaded batch-data/8.csv, 79 files out of an estimated total of 100\n",
      "Uploading batch-data/80.csv\n",
      "Uploaded batch-data/80.csv, 80 files out of an estimated total of 100\n",
      "Uploading batch-data/81.csv\n",
      "Uploaded batch-data/81.csv, 81 files out of an estimated total of 100\n",
      "Uploading batch-data/82.csv\n",
      "Uploaded batch-data/82.csv, 82 files out of an estimated total of 100\n",
      "Uploading batch-data/83.csv\n",
      "Uploaded batch-data/83.csv, 83 files out of an estimated total of 100\n",
      "Uploading batch-data/84.csv\n",
      "Uploaded batch-data/84.csv, 84 files out of an estimated total of 100\n",
      "Uploading batch-data/85.csv\n",
      "Uploaded batch-data/85.csv, 85 files out of an estimated total of 100\n",
      "Uploading batch-data/86.csv\n",
      "Uploaded batch-data/86.csv, 86 files out of an estimated total of 100\n",
      "Uploading batch-data/87.csv\n",
      "Uploaded batch-data/87.csv, 87 files out of an estimated total of 100\n",
      "Uploading batch-data/88.csv\n",
      "Uploaded batch-data/88.csv, 88 files out of an estimated total of 100\n",
      "Uploading batch-data/89.csv\n",
      "Uploaded batch-data/89.csv, 89 files out of an estimated total of 100\n",
      "Uploading batch-data/9.csv\n",
      "Uploaded batch-data/9.csv, 90 files out of an estimated total of 100\n",
      "Uploading batch-data/90.csv\n",
      "Uploaded batch-data/90.csv, 91 files out of an estimated total of 100\n",
      "Uploading batch-data/91.csv\n",
      "Uploaded batch-data/91.csv, 92 files out of an estimated total of 100\n",
      "Uploading batch-data/92.csv\n",
      "Uploaded batch-data/92.csv, 93 files out of an estimated total of 100\n",
      "Uploading batch-data/93.csv\n",
      "Uploaded batch-data/93.csv, 94 files out of an estimated total of 100\n",
      "Uploading batch-data/94.csv\n",
      "Uploaded batch-data/94.csv, 95 files out of an estimated total of 100\n",
      "Uploading batch-data/95.csv\n",
      "Uploaded batch-data/95.csv, 96 files out of an estimated total of 100\n",
      "Uploading batch-data/96.csv\n",
      "Uploaded batch-data/96.csv, 97 files out of an estimated total of 100\n",
      "Uploading batch-data/97.csv\n",
      "Uploaded batch-data/97.csv, 98 files out of an estimated total of 100\n",
      "Uploading batch-data/98.csv\n",
      "Uploaded batch-data/98.csv, 99 files out of an estimated total of 100\n",
      "Uploading batch-data/99.csv\n",
      "Uploaded batch-data/99.csv, 100 files out of an estimated total of 100\n",
      "Uploaded 100 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "sk = Dataset.get_by_name(ws, name='skdataset')\n",
    "data = sk.to_pandas_dataframe()\n",
    "# Get a 100-item sample of the feature columns \n",
    "sample = data[['Model','Length','Type','Style','OEM','Engine Disp','Age of OEM','Year','Mileage','Oil Price','Petrol','Automatic','Price']].sample(n=100).values\n",
    "\n",
    "# Create a folder\n",
    "batch_folder = './batch-data'\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "print(\"Folder created!\")\n",
    "\n",
    "# Save each sample as a separate file\n",
    "print(\"Saving files...\")\n",
    "for i in range(100):\n",
    "    fname = str(i+1) + '.csv'\n",
    "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\n",
    "print(\"files saved!\")\n",
    "\n",
    "# Upload the files to the default datastore\n",
    "print(\"Uploading files to datastore...\")\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\n",
    "\n",
    "# Register a dataset for the input data\n",
    "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\n",
    "try:\n",
    "    batch_data_set = batch_data_set.register(workspace=ws, \n",
    "                                             name='batch-data',\n",
    "                                             description='batch data',\n",
    "                                             create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5aabff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"computeclusterlr\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8968f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'batch_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "326966b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_pipeline/batch_sk.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_sk.py\n",
    "import os\n",
    "import numpy as np\n",
    "from azureml.core import Model\n",
    "import joblib\n",
    "\n",
    "\n",
    "def init():\n",
    "    # Runs when the pipeline step is initialized\n",
    "    global model\n",
    "\n",
    "    # load the model\n",
    "    model_path = Model.get_model_path('sk_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "def run(mini_batch):\n",
    "    # This runs for each batch\n",
    "    resultList = []\n",
    "\n",
    "    # process each file in the batch\n",
    "    for f in mini_batch:\n",
    "        # Read the comma-delimited data into an array\n",
    "        data = np.genfromtxt(f, delimiter=',')\n",
    "        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\n",
    "        prediction = model.predict(data.reshape(1, -1))\n",
    "        # Append prediction to results\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb0e92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_pipeline/batch_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_env.yml\n",
    "\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05e5b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# Create an Environment for the experiment\n",
    "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_env.yml\")\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "print('Configuration ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34de0f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "\n",
    "output_dir = OutputFileDatasetConfig(name='inferences')\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=experiment_folder,\n",
    "    entry_script=\"batch_sk.py\",\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    compute_target=pipeline_cluster,\n",
    "    node_count=2)\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name='batch-score-sk',\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[batch_data_set.as_named_input('sk_batch')],\n",
    "    output=output_dir,\n",
    "    arguments=[],\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print('Steps defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "095c6ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batch-score-sk [a68d958d][169b673a-52c7-4dbe-b358-e72e5ea0d9a3], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 8601ef27-fb7d-4aa7-8249-1d3e4e271614\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/8601ef27-fb7d-4aa7-8249-1d3e4e271614?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "PipelineRunId: 8601ef27-fb7d-4aa7-8249-1d3e4e271614\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/8601ef27-fb7d-4aa7-8249-1d3e4e271614?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "StepRun( batch-score-sk ) Status: NotStarted\n",
      "StepRun( batch-score-sk ) Status: Queued\n",
      "StepRun( batch-score-sk ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_70e4add24c65bf530f9c4ed9ed5a8cf9b15facfc5b2124ce2243c82c68897141_d.txt\n",
      "========================================================================================================================\n",
      "2022-02-28T19:40:21Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24747 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2022-02-28T19:40:21Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/mounts/workspaceblobstore -- stdout/stderr: \n",
      "2022-02-28T19:40:22Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2022-02-28T19:40:22Z Starting output-watcher...\n",
      "2022-02-28T19:40:22Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2022-02-28T19:40:22Z Executing 'Copy ACR Details file' on 10.0.0.6\n",
      "2022-02-28T19:40:22Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2022-02-28T19:40:22Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "2022-02-28T19:40:23Z Copy ACR Details file succeeded on 10.0.0.6. Output: \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_f7dca5f5f0dac270c156fcb7f532f287\n",
      "92473f7ef455: Pulling fs layer\n",
      "fb52bde70123: Pulling fs layer\n",
      "64788f86be3f: Pulling fs layer\n",
      "33f6d5f2e001: Pulling fs layer\n",
      "eeb715f1b6ae: Pulling fs layer\n",
      "fe519cf36537: Pulling fs layer\n",
      "58ff99196c15: Pulling fs layer\n",
      "9b13f06a8eff: Pulling fs layer\n",
      "2d4e93adbf58: Pulling fs layer\n",
      "6ee7c3767844: Pulling fs layer\n",
      "62cfc3ccb8ab: Pulling fs layer\n",
      "4a7af9d757ee: Pulling fs layer\n",
      "9e003623bee8: Pulling fs layer\n",
      "3bc226f3e817: Pulling fs layer\n",
      "0f1427a1ad9a: Pulling fs layer\n",
      "d3e37e76c9a7: Pulling fs layer\n",
      "97329cd6cca4: Pulling fs layer\n",
      "9fc8fd4f5d56: Pulling fs layer\n",
      "b7455bac32aa: Pulling fs layer\n",
      "63561bab5267: Pulling fs layer\n",
      "33f6d5f2e001: Waiting\n",
      "eeb715f1b6ae: Waiting\n",
      "fe519cf36537: Waiting\n",
      "58ff99196c15: Waiting\n",
      "9b13f06a8eff: Waiting\n",
      "2d4e93adbf58: Waiting\n",
      "6ee7c3767844: Waiting\n",
      "62cfc3ccb8ab: Waiting\n",
      "4a7af9d757ee: Waiting\n",
      "9e003623bee8: Waiting\n",
      "3bc226f3e817: Waiting\n",
      "0f1427a1ad9a: Waiting\n",
      "d3e37e76c9a7: Waiting\n",
      "97329cd6cca4: Waiting\n",
      "9fc8fd4f5d56: Waiting\n",
      "b7455bac32aa: Waiting\n",
      "63561bab5267: Waiting\n",
      "fb52bde70123: Verifying Checksum\n",
      "fb52bde70123: Download complete\n",
      "64788f86be3f: Verifying Checksum\n",
      "64788f86be3f: Download complete\n",
      "33f6d5f2e001: Verifying Checksum\n",
      "33f6d5f2e001: Download complete\n",
      "92473f7ef455: Verifying Checksum\n",
      "92473f7ef455: Download complete\n",
      "58ff99196c15: Verifying Checksum\n",
      "58ff99196c15: Download complete\n",
      "fe519cf36537: Verifying Checksum\n",
      "fe519cf36537: Download complete\n",
      "eeb715f1b6ae: Verifying Checksum\n",
      "eeb715f1b6ae: Download complete\n",
      "6ee7c3767844: Verifying Checksum\n",
      "6ee7c3767844: Download complete\n",
      "9b13f06a8eff: Verifying Checksum\n",
      "9b13f06a8eff: Download complete\n",
      "62cfc3ccb8ab: Verifying Checksum\n",
      "62cfc3ccb8ab: Download complete\n",
      "4a7af9d757ee: Verifying Checksum\n",
      "4a7af9d757ee: Download complete\n",
      "2d4e93adbf58: Verifying Checksum\n",
      "2d4e93adbf58: Download complete\n",
      "0f1427a1ad9a: Verifying Checksum\n",
      "0f1427a1ad9a: Download complete\n",
      "9e003623bee8: Verifying Checksum\n",
      "9e003623bee8: Download complete\n",
      "97329cd6cca4: Download complete\n",
      "d3e37e76c9a7: Verifying Checksum\n",
      "d3e37e76c9a7: Download complete\n",
      "9fc8fd4f5d56: Verifying Checksum\n",
      "9fc8fd4f5d56: Download complete\n",
      "b7455bac32aa: Verifying Checksum\n",
      "b7455bac32aa: Download complete\n",
      "63561bab5267: Verifying Checksum\n",
      "63561bab5267: Download complete\n",
      "3bc226f3e817: Verifying Checksum\n",
      "3bc226f3e817: Download complete\n",
      "92473f7ef455: Pull complete\n",
      "fb52bde70123: Pull complete\n",
      "64788f86be3f: Pull complete\n",
      "33f6d5f2e001: Pull complete\n",
      "eeb715f1b6ae: Pull complete\n",
      "fe519cf36537: Pull complete\n",
      "58ff99196c15: Pull complete\n",
      "9b13f06a8eff: Pull complete\n",
      "2d4e93adbf58: Pull complete\n",
      "6ee7c3767844: Pull complete\n",
      "62cfc3ccb8ab: Pull complete\n",
      "4a7af9d757ee: Pull complete\n",
      "9e003623bee8: Pull complete\n",
      "3bc226f3e817: Pull complete\n",
      "0f1427a1ad9a: Pull complete\n",
      "d3e37e76c9a7: Pull complete\n",
      "97329cd6cca4: Pull complete\n",
      "9fc8fd4f5d56: Pull complete\n",
      "b7455bac32aa: Pull complete\n",
      "63561bab5267: Pull complete\n",
      "Digest: sha256:1ba0fe158be6cf30393d682a14b245ddcb6727074eec0217cedc80252795e38b\n",
      "Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_f7dca5f5f0dac270c156fcb7f532f287:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_f7dca5f5f0dac270c156fcb7f532f287:latest\n",
      "2022-02-28T19:41:00Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2022-02-28T19:41:00Z Check if container 5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95_DataSidecar already exist exited with 0, \n",
      "\n",
      "c62c4e3392590b22b118ec30ace9a80d56b7ba8d7df14a6445c35158ea118aae\n",
      "2022-02-28T19:41:01Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2022-02-28T19:41:01Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-9af48e30f1910bd1424dbec7ff690fff-b82835faa3322d12-01 -sshRequired=false] \n",
      "2022/02/28 19:41:01 Didn't get JobInfoJson from env, now read from file\n",
      "2022/02/28 19:41:01 Suceeded read JobInfoJson from file\n",
      "2022/02/28 19:41:02 Starting App Insight Logger for task:  containerSetup\n",
      "2022/02/28 19:41:02 Version: 3.0.01867.0001 Branch: .SourceBranch Commit: 925d6a4\n",
      "2022/02/28 19:41:02 Entered ContainerSetupTask - Preparing infiniband\n",
      "2022/02/28 19:41:02 Starting infiniband setup\n",
      "2022/02/28 19:41:02 Python Version found is Python 3.7.9\n",
      "\n",
      "2022/02/28 19:41:02 Returning Python Version as 3.7\n",
      "2022/02/28 19:41:02 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2022/02/28 19:41:02 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2022-02-28T19:41:02Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2022/02/28 19:41:02 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2022/02/28 19:41:02 Not setting up Infiniband in Container\n",
      "2022/02/28 19:41:02 Not setting up Infiniband in Container\n",
      "2022-02-28T19:41:02Z Not setting up Infiniband in Container\n",
      "2022/02/28 19:41:02 Python Version found is Python 3.7.9\n",
      "\n",
      "2022/02/28 19:41:02 Returning Python Version as 3.7\n",
      "2022/02/28 19:41:02 sshd inside container not required for job, skipping setup.\n",
      "2022/02/28 19:41:03 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "2022/02/28 19:41:03 App Insight Client has already been closed\n",
      "2022/02/28 19:41:03 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2022-02-28T19:41:03Z Starting docker container succeeded.\n",
      "2022-02-28T19:41:03Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_70e4add24c65bf530f9c4ed9ed5a8cf9b15facfc5b2124ce2243c82c68897141_d.txt\n",
      "===============================================================================================================\n",
      "[2022-02-28T19:41:05.120873] Entering job preparation.\n",
      "[2022-02-28T19:41:05.837097] Starting job preparation.\n",
      "[2022-02-28T19:41:05.837145] Extracting the control code.\n",
      "[2022-02-28T19:41:05.837499] Starting extract_project.\n",
      "[2022-02-28T19:41:05.837549] Starting to extract zip file.\n",
      "[2022-02-28T19:41:05.856837] Finished extracting zip file.\n",
      "[2022-02-28T19:41:05.861179] Using urllib.request Python 3.0 or later\n",
      "[2022-02-28T19:41:05.861347] Start fetching snapshots.\n",
      "[2022-02-28T19:41:05.861516] Start fetching snapshot.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 57\n",
      "[2022-02-28T19:41:06.221422] Finished fetching snapshot.\n",
      "[2022-02-28T19:41:06.221468] Start fetching snapshot.\n",
      "[2022-02-28T19:41:13.573813] Finished fetching snapshot.\n",
      "[2022-02-28T19:41:13.573862] Finished fetching snapshots.\n",
      "[2022-02-28T19:41:13.573877] Finished extract_project.\n",
      "[2022-02-28T19:41:13.573959] Finished fetching and extracting the control code.\n",
      "[2022-02-28T19:41:13.583888] Start run_history_prep.\n",
      "[2022-02-28T19:41:13.592433] Job preparation is complete.\n",
      "[2022-02-28T19:41:13.592760] Entering Data Context Managers in Sidecar\n",
      "[2022-02-28T19:41:13.593702] Running Sidecar prep cmd...\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.22.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('azure-core<1.22')).\n",
      "[2022-02-28T19:41:13.920113] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95\n",
      "[2022-02-28T19:41:13.921253] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      "[2022-02-28T19:41:14.136] Enter __enter__ of DatasetContextManager\n",
      "[2022-02-28T19:41:14.137] SDK version: azureml-core==1.38.0.post2 azureml-dataprep==2.27.0. Session id: 9ada353f-1446-4c1a-8a2f-aadca9f209d8. Run id: 5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95.\n",
      "[2022-02-28T19:41:14.137] Processing 'sk_batch'.\n",
      "[2022-02-28T19:41:14.137] Mode: 'mount'.\n",
      "[2022-02-28T19:41:14.137] Path on compute is specified: 'False'.\n",
      "[2022-02-28T19:41:17.344] Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('skdatastore', 'batch-data/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"3c1b51f8-29e2-4bd3-b604-6f2e5348bf47\",\n",
      "    \"name\": \"batch-data\",\n",
      "    \"version\": 2,\n",
      "    \"description\": \"batch data\",\n",
      "    \"workspace\": \"Workspace.create(name='aml_ws', subscription_id='8f35cf98-68ff-457e-b1b3-e05921a0fd46', resource_group='rg-lr-dp100')\"\n",
      "  }\n",
      "}\n",
      "[2022-02-28T19:41:19.686] Mounting sk_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sk_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47 as folder.\n",
      "[2022-02-28T19:41:19.686] Processing 'inferences'.\n",
      "[2022-02-28T19:41:19.686] Mode: 'mount'.\n",
      "[2022-02-28T19:41:19.686] Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_skdatastore'.\n",
      "[2022-02-28T19:41:19.791] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_skdatastore\n",
      "[2022-02-28T19:41:19.791] Output is not a single file\n",
      "[2022-02-28T19:41:19.791] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_skdatastore as folder\n",
      "[2022-02-28T19:41:20.287] Mounting sk_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sk_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47.\n",
      "[2022-02-28T19:41:21.288] Mounted sk_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sk_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47.\n",
      "[2022-02-28T19:41:21.288] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_skdatastore.\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.22.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('azure-core<1.22')).\n",
      "[2022-02-28T19:41:26.386] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_skdatastore.\n",
      "[2022-02-28T19:41:26.418] Exit __enter__ of DatasetContextManager\n",
      "uri entered in sidecar: None\n",
      "Set Dataset sk_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sk_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47\n",
      "Set OutputDataset inferences's target path to /mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_skdatastore\n",
      "[2022-02-28T19:41:26.419577] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2022-02-28T19:41:27.270827] Ran Sidecar prep cmd.\n",
      "[2022-02-28T19:41:27.270925] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2022/02/28 19:42:30 Didn't get JobInfoJson from env, now read from file\n",
      "2022/02/28 19:42:30 Suceeded read JobInfoJson from file\n",
      "2022/02/28 19:42:30 Starting App Insight Logger for task:  runTaskLet\n",
      "2022/02/28 19:42:30 Version: 3.0.01867.0001 Branch: .SourceBranch Commit: 925d6a4\n",
      "2022/02/28 19:42:30 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "2022/02/28 19:42:30 Send process info logs to master server succeeded\n",
      "2022/02/28 19:42:30 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "2022/02/28 19:42:30 Send process info logs to master server succeeded\n",
      "[2022-02-28T19:42:30.225676] Entering context manager injector.\n",
      "[2022-02-28T19:42:30.953709] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.38.0', '--scoring_module_name', 'batch_sk.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'sk_batch'])\n",
      "Script type = None\n",
      "[2022-02-28T19:42:30.959122] Entering Run History Context Manager.\n",
      "[2022-02-28T19:42:31.882474] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95\n",
      "[2022-02-28T19:42:31.882525] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.38.0', '--scoring_module_name', 'batch_sk.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$inferences', '--input_fds_0', 'sk_batch']\n",
      "[2022-02-28T19:42:31.882557] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.38.0', '--scoring_module_name', 'batch_sk.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_skdatastore', '--input_fds_0', 'sk_batch']\n",
      "\n",
      "2022/02/28 19:42:35 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[2022-02-28T19:43:33.301595] The experiment failed. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "3 items cleaning up...\n",
      "Cleanup took 0.24070072174072266 seconds\n",
      "azureml_common.parallel_run.exception_info.Exception: Run failed. Below is the error detail:\n",
      "EntryScriptException: Entry script error. The number of failed items is 100, which exceeds error threshold 10.\n",
      "The run() function in the entry script had raised exception for 60 times. Please check logs at logs/user/error/* for details.\n",
      "  * Error 'Input contains NaN, infinity or a value too large for dtype('float64').' occurred 60 times.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"driver/amlbi_main.py\", line 174, in <module>\n",
      "    main()\n",
      "  File \"driver/amlbi_main.py\", line 123, in main\n",
      "    boot(driver_dir)\n",
      "  File \"driver/amlbi_main.py\", line 58, in boot\n",
      "    booter.start()\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 372, in start\n",
      "    self.start_sys_main()\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 260, in start_sys_main\n",
      "    self.run_sys_main(cmd)\n",
      "  File \"driver/azureml_user/parallel_run/boot_simulator.py\", line 40, in run_sys_main\n",
      "    self.run(cmd)\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 201, in run\n",
      "    self.check_run_result(proc=proc, stdout=stdout, stderr=stderr)\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 211, in check_run_result\n",
      "    BootResult().check_result(stdout)\n",
      "  File \"driver/azureml_user/parallel_run/boot_result.py\", line 36, in check_result\n",
      "    raise Exception(message) from cause\n",
      "Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\n",
      "\n",
      "[2022-02-28T19:43:33.696955] Finished context manager injector with Exception.\n",
      "2022/02/28 19:43:34 Skipping parsing control script error. Reason: Error json file doesn't exist. This most likely means that no errors were written to the file. File path: /mnt/batch/tasks/workitems/f425bbc3-2c29-48d2-b057-d61b2fc6cbfe/job-1/5e5e0bc7-d9a7-4195-9_4b3cb51c-e4ae-40de-ae07-f28e27295e69/wd/runTaskLetTask_error.json\n",
      "2022/02/28 19:43:34 Wrapper cmd failed with err: exit status 1\n",
      "2022/02/28 19:43:34 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "2022/02/28 19:43:34 Send process info logs to master server succeeded\n",
      "2022/02/28 19:43:34 mpirun version string: {\n",
      "mpirun (Open MPI) 3.1.2\n",
      "\n",
      "Report bugs to http://www.open-mpi.org/community/help/\n",
      "}\n",
      "2022/02/28 19:43:34 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 2\n",
      "FilteredData: 0.\n",
      "2022/02/28 19:43:34 Process Exiting with Code:  1\n",
      "2022/02/28 19:43:35 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_70e4add24c65bf530f9c4ed9ed5a8cf9b15facfc5b2124ce2243c82c68897141_d.txt\n",
      "===============================================================================================================\n",
      "[2022-02-28T19:43:37.965145] Entering job release\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.22.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('azure-core<1.22')).\n",
      "[2022-02-28T19:43:38.965565] Starting job release\n",
      "[2022-02-28T19:43:38.966519] job release stage : upload_datastore starting...\n",
      "[2022-02-28T19:43:38.966044] Logging experiment finalizing status in history service.\n",
      "[2022-02-28T19:43:38.970265] job release stage : start importing azureml.history._tracking in run_history_release.Starting the daemon thread to refresh tokens in background for process with pid = 323\n",
      "[2022-02-28T19:43:38.971190] Entering context manager injector.[2022-02-28T19:43:38.971386] job release stage : copy_batchai_cached_logs starting...\n",
      "[2022-02-28T19:43:38.971508] job release stage : execute_job_release starting...\n",
      "\n",
      "\n",
      "[2022-02-28T19:43:38.972011] job release stage : copy_batchai_cached_logs completed...\n",
      "[2022-02-28T19:43:38.989581] job release stage : upload_datastore completed...\n",
      "[2022-02-28T19:43:39.061904] job release stage : send_run_telemetry starting...\n",
      "[2022-02-28T19:43:39.095015] get vm size and vm region successfully.\n",
      "[2022-02-28T19:43:39.110282] get compute meta data successfully.\n",
      "[2022-02-28T19:43:39.271762] job release stage : execute_job_release completed...\n",
      "[2022-02-28T19:43:39.373951] post artifact meta request successfully.\n",
      "[2022-02-28T19:43:39.423565] upload compute record artifact successfully.\n",
      "[2022-02-28T19:43:39.423668] job release stage : send_run_telemetry completed...\n",
      "[2022-02-28T19:43:39.424189] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2022-02-28T19:43:39.424456] Running Sidecar release cmd...\n",
      "[2022-02-28T19:43:39.437452] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95\n",
      "[2022-02-28T19:43:39.459] Enter __exit__ of DatasetContextManager\n",
      "[2022-02-28T19:43:39.459] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sk_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47.\n",
      "[2022-02-28T19:43:40.468] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/sk_batch_3c1b51f8-29e2-4bd3-b604-6f2e5348bf47.\n",
      "[2022-02-28T19:43:40.468] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_skdatastore.\n",
      "fuse: failed to unmount /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_skdatastore: Invalid argument\n",
      "[2022-02-28T19:43:40.486] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/aml_ws/azureml/5e5e0bc7-d9a7-4195-92f0-6be91ba6ce95/wd/inferences_skdatastore.\n",
      "[2022-02-28T19:43:40.486] Exit __exit__ of DatasetContextManager\n",
      "[2022-02-28T19:43:40.486683] Removing absolute paths from host...\n",
      "[2022-02-28T19:43:40.487010] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2022-02-28T19:43:41.456872] Ran Sidecar release cmd.\n",
      "[2022-02-28T19:43:41.456987] Job release is complete\n",
      "\n",
      "StepRun(batch-score-sk) Execution Summary\n",
      "===============================================\n",
      "StepRun( batch-score-sk ) Status: Failed\n",
      "\n",
      "Warnings:\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": \"UserError\",\n",
      "    \"severity\": null,\n",
      "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n",
      "    \"messageFormat\": \"{Message}\",\n",
      "    \"messageParameters\": {\n",
      "      \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n",
      "    },\n",
      "    \"referenceCode\": null,\n",
      "    \"detailsUri\": null,\n",
      "    \"target\": null,\n",
      "    \"details\": [],\n",
      "    \"innerError\": {\n",
      "      \"code\": \"UserTrainingScriptFailed\",\n",
      "      \"innerError\": null\n",
      "    },\n",
      "    \"debugInfo\": null,\n",
      "    \"additionalInfo\": null\n",
      "  },\n",
      "  \"correlation\": {\n",
      "    \"operation\": \"0a24e9f9fb93f2b787f1d79f14ed689a\",\n",
      "    \"request\": \"28e50c6397e7c336\"\n",
      "  },\n",
      "  \"environment\": \"southeastasia\",\n",
      "  \"location\": \"southeastasia\",\n",
      "  \"time\": \"2022-02-28T19:43:56.5612933+00:00\",\n",
      "  \"componentName\": \"globaljobdispatcher\"\n",
      "}\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-af045af2bc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparallelrun_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpipeline_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sk-batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    294\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0;32m--> 296\u001b[0;31m                                                              raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    297\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                                 \u001b[0;31m# If there are package conflicts in the user's environment, the run rehydration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0;32m--> 738\u001b[0;31m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "pipeline_run = Experiment(ws, 'sk-batch').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a377a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': '8601ef27-fb7d-4aa7-8249-1d3e4e271614',\n",
       " 'status': 'Failed',\n",
       " 'startTimeUtc': '2022-02-28T19:36:18.677084Z',\n",
       " 'endTimeUtc': '2022-02-28T19:43:57.832064Z',\n",
       " 'services': {},\n",
       " 'properties': {'azureml.runsource': 'azureml.PipelineRun',\n",
       "  'runSource': 'SDK',\n",
       "  'runType': 'SDK',\n",
       "  'azureml.parameters': '{}',\n",
       "  'azureml.continue_on_step_failure': 'False',\n",
       "  'azureml.pipelineComponent': 'pipelinerun'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.8601ef27-fb7d-4aa7-8249-1d3e4e271614/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=S2w%2Bi4l6xg%2BioAkTV3AMrWAbUXIdUJ6EHxs%2FJfca4n0%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-28T14%3A18%3A45Z&ske=2022-03-01T22%3A28%3A45Z&sks=b&skv=2019-07-07&st=2022-02-28T19%3A45%3A13Z&se=2022-03-01T03%3A55%3A13Z&sp=r',\n",
       "  'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.8601ef27-fb7d-4aa7-8249-1d3e4e271614/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=HIhnbL0BsAOloioorCoxgkEbXPH5epOfaSwYdZsUaFI%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-28T14%3A18%3A45Z&ske=2022-03-01T22%3A28%3A45Z&sks=b&skv=2019-07-07&st=2022-02-28T19%3A45%3A13Z&se=2022-03-01T03%3A55%3A13Z&sp=r',\n",
       "  'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.8601ef27-fb7d-4aa7-8249-1d3e4e271614/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=2XURE4wHpz1VDQeXVg2wkVCtVdC4n8qSHvP2T43f2UA%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-28T14%3A18%3A45Z&ske=2022-03-01T22%3A28%3A45Z&sks=b&skv=2019-07-07&st=2022-02-28T19%3A45%3A13Z&se=2022-03-01T03%3A55%3A13Z&sp=r'},\n",
       " 'submittedBy': 'Lalitha Raghavan'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775e3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c3aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa35560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b33c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AUTOML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50521f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "compute_name = 'computeclusterlr'\n",
    "training_cluster = ComputeTarget(workspace=ws, name=compute_name)\n",
    "\n",
    "aml_run_config = RunConfiguration()\n",
    "# Use just-specified compute target (\"cpu-cluster\")\n",
    "aml_run_config.target = training_cluster\n",
    "\n",
    "# Specify CondaDependencies obj, add necessary packages\n",
    "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn'], \n",
    "    pip_packages=['azureml-sdk[automl]', 'pyarrow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e99609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name='skdataset')\n",
    "data = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7816e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Length</th>\n",
       "      <th>Type</th>\n",
       "      <th>Style</th>\n",
       "      <th>OEM</th>\n",
       "      <th>Engine Disp</th>\n",
       "      <th>Age of OEM</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Oil Price</th>\n",
       "      <th>Petrol</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Column17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Jan-14</td>\n",
       "      <td>16</td>\n",
       "      <td>102.10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1,207</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Feb-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.83</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>882</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mar-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.04</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>839</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>Apr-14</td>\n",
       "      <td>16</td>\n",
       "      <td>104.87</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>547</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grand Punto</td>\n",
       "      <td>4000</td>\n",
       "      <td>Compact-Regular</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8</td>\n",
       "      <td>May-14</td>\n",
       "      <td>16</td>\n",
       "      <td>105.71</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>571</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Length             Type      Style   OEM  Engine Disp  \\\n",
       "0  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "1  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "2  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "3  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "4  Grand Punto    4000  Compact-Regular  Hatchback  Fiat          1.4   \n",
       "\n",
       "   Age of OEM    Year  Mileage  Oil Price  Petrol  Automatic  Price  Sales  \\\n",
       "0           8  Jan-14       16     102.10    True      False    5.0  1,207   \n",
       "1           8  Feb-14       16     104.83    True      False    5.0    882   \n",
       "2           8  Mar-14       16     104.04    True      False    5.0    839   \n",
       "3           8  Apr-14       16     104.87    True      False    5.0    547   \n",
       "4           8  May-14       16     105.71    True      False    5.0    571   \n",
       "\n",
       "  Column17  \n",
       "0     None  \n",
       "1     None  \n",
       "2     None  \n",
       "3     None  \n",
       "4     None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9367d17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl_sk_pipeline-v4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'automl_sk_pipeline-v4'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "515cec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sk_pipeline/dataprep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/dataprep.py\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
    "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
    "args = parser.parse_args()\n",
    "save_folder = args.prepped_data\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "data= run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# Drop unnecessary columns and other cleaning steps\n",
    "data=data.drop(['Column17','Year'],axis=1)\n",
    "\n",
    "data['Sales']=pd.to_numeric(data['Sales'],errors='coerce')\n",
    "data= data[data['Sales'].notna()]\n",
    "data = data.drop(data[data.Sales < 0].index)\n",
    "\n",
    "# Label Encoding\n",
    "list_of_columns = ['Model','Type','Style','OEM']\n",
    "data[list_of_columns] = data[list_of_columns].apply(lambda col:pd.Categorical(col).codes)\n",
    "\n",
    "# Boolean Encoding\n",
    "data[[\"Petrol\", \"Automatic\"]] *= 1\n",
    "\n",
    "# Normalize the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['Length','Engine Disp','Age of OEM','Mileage','Oil Price','Price']\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "\n",
    "# Log processed rows\n",
    "row_count = (len(data))\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "\n",
    "# Save the prepped data  **** AutoML is automatically taking csv files as strings. Best to convert to Parquet\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder,'prepped_data.parquet')\n",
    "data.to_parquet(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9be35959",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_cluster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6e3886c5dd22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                 arguments = ['--input-data', sk_ds.as_named_input('raw_data'),\n\u001b[1;32m     16\u001b[0m                                              '--prepped-data', prepped_data],\n\u001b[0;32m---> 17\u001b[0;31m                                 \u001b[0mcompute_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_cluster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                                 \u001b[0mrunconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maml_run_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                 allow_reuse = True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_cluster' is not defined"
     ]
    }
   ],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "\n",
    "# Get the training dataset\n",
    "sk_ds = ws.datasets.get(\"skdataset\")\n",
    "\n",
    "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
    "prepped_data = OutputFileDatasetConfig(\"prepped_data\").read_parquet_files()\n",
    "\n",
    "# Step 1, Run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"dataprep.py\",\n",
    "                                arguments = ['--input-data', sk_ds.as_named_input('raw_data'),\n",
    "                                             '--prepped-data', prepped_data],\n",
    "                                compute_target = training_cluster,\n",
    "                                runconfig = aml_run_config,\n",
    "                                allow_reuse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fff074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepped_data = prepped_data.read_delimited_files()   ### You don't need this if reading from Parquet. For CSV you need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7c12b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman_correlation\n",
      "r2_score\n",
      "normalized_mean_absolute_error\n",
      "normalized_root_mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "import azureml.train.automl.utilities as automl_utils\n",
    "\n",
    "for metric in automl_utils.get_primary_metrics('regression'):\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06f248a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import TrainingOutput, PipelineData\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                            datastore=default_ds,\n",
    "                            pipeline_output_name='metrics_output',\n",
    "                            training_output=TrainingOutput(type='Metrics'))\n",
    "\n",
    "model_data = PipelineData(name='best_model_data',\n",
    "                          datastore=default_ds,\n",
    "                          pipeline_output_name='model_output',\n",
    "                          training_output=TrainingOutput(type='Model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562e42a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for Auto ML run.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 10,\n",
    "    \"experiment_timeout_hours\": 0.25,\n",
    "    \"enable_early_stopping\": True,\n",
    "    \"primary_metric\": 'normalized_root_mean_squared_error',\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"n_cross_validations\": 2\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(name='Automated ML Experiment',\n",
    "                             task='regression',\n",
    "                             debug_log='automated_ml_errors.log',\n",
    "                             compute_target=training_cluster,\n",
    "                             training_data = prepped_data,\n",
    "                             label_column_name=\"Sales\",\n",
    "                             **automl_settings)\n",
    "\n",
    "train_step = AutoMLStep(name='AutoML_Regression',\n",
    "    automl_config=automl_config,\n",
    "    passthru_automl_config=False,\n",
    "    outputs=[metrics_data,model_data],\n",
    "    enable_default_model_output=False,\n",
    "    enable_default_metrics_output=False,\n",
    "    allow_reuse=True)\n",
    "\n",
    "\n",
    "print(\"Ready for Auto ML run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9e9ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing $experiment_folder/register_model.py\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '$experiment_folder/register_model.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10339/437428965.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'$experiment_folder/register_model.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from azureml.core.model import Model, Dataset\\nfrom azureml.core.run import Run, _OfflineRun\\nfrom azureml.core import Workspace\\nimport argparse\\n\\nparser = argparse.ArgumentParser()\\nparser.add_argument(\"--model_name\", required=True)\\nparser.add_argument(\"--model_path\", required=True)\\nargs = parser.parse_args()\\n\\nprint(f\"model_name : {args.model_name}\")\\nprint(f\"model_path: {args.model_path}\")\\n\\nrun = Run.get_context()\\nws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\\n\\nmodel = Model.register(workspace=ws,\\n                       model_path=args.model_path,\\n                       model_name=args.model_name)\\n\\nprint(\"Registered version {0} of model {1}\".format(model.version, model.name))\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-98>\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '$experiment_folder/register_model.py'"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/register_model.py\n",
    "from azureml.core.model import Model, Dataset\n",
    "from azureml.core.run import Run, _OfflineRun\n",
    "from azureml.core import Workspace\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_name\", required=True)\n",
    "parser.add_argument(\"--model_path\", required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(f\"model_name : {args.model_name}\")\n",
    "print(f\"model_path: {args.model_path}\")\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_path=args.model_path,\n",
    "                       model_name=args.model_name)\n",
    "\n",
    "print(\"Registered version {0} of model {1}\".format(model.version, model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c125b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "# The model name with which to register the trained model in the workspace.\n",
    "model_name = PipelineParameter(\"model_name\", default_value=\"sk_model_v4\")\n",
    "\n",
    "register_step = PythonScriptStep(script_name=\"register_model.py\",\n",
    "                                 source_directory = experiment_folder,\n",
    "                                       name=\"register_model\",\n",
    "                                       allow_reuse=False,\n",
    "                                       arguments=[\"--model_name\", model_name, \"--model_path\", model_data],\n",
    "                                       inputs=[model_data],\n",
    "                                       compute_target=training_cluster,\n",
    "                                       runconfig=aml_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11cbc926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Prepare Data [fbd7120a][67ff3b5f-27f4-4b77-952c-dd8baf0ccd93], (This step will run and generate new outputs)Created step AutoML_Regression [431cd644][47a24634-fc8a-4fed-af9b-dc7bb0e6459d], (This step will run and generate new outputs)\n",
      "Created step register_model [c9e4e482][42c9db6c-a00e-49c2-944a-f0c7973db919], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun 9c29cc9e-7050-4749-af14-ed125a9373c1\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9c29cc9e-7050-4749-af14-ed125a9373c1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a4368c463a4345ad5397b50b14aa67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/9c29cc9e-7050-4749-af14-ed125a9373c1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\", \"run_id\": \"9c29cc9e-7050-4749-af14-ed125a9373c1\", \"run_properties\": {\"run_id\": \"9c29cc9e-7050-4749-af14-ed125a9373c1\", \"created_utc\": \"2022-02-23T19:28:58.603341Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{\\\"model_name\\\":\\\"sk_model_v4\\\"}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2022-02-23T19:58:44.506458Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=6LTRqP10BxeabEgM8iXZ%2BTC2bLuYFQJ%2F9QbtJCjH%2FHk%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A25Z&se=2022-02-24T04%3A53%3A25Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=yyMOp94IXb5DFGNmnybkuSAxJlaWEZ7HMy9X8xN3IRo%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A25Z&se=2022-02-24T04%3A53%3A25Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=HOzwJvlKc79UTbPsKD2VLQnet9UNBchh7vDCwFxHJXw%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A25Z&se=2022-02-24T04%3A53%3A25Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:29:45\", \"run_number\": \"1645644538\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"ae1c9977-3df9-42d6-8f38-63934b887388\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:30:56.078463Z\", \"created_time\": \"2022-02-23T19:29:01.971491Z\", \"end_time\": \"2022-02-23T19:32:40.865188Z\", \"duration\": \"0:03:38\", \"run_number\": 1645644541, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:29:01.971491Z\", \"is_reused\": \"\"}, {\"run_id\": \"60c326d6-9daa-4c00-96bd-4dbd0a9368a6\", \"name\": \"AutoML_Regression\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:32:59.439555Z\", \"created_time\": \"2022-02-23T19:32:42.482599Z\", \"end_time\": \"2022-02-23T19:56:19.792708Z\", \"duration\": \"0:23:37\", \"run_number\": 1645644762, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:32:42.482599Z\", \"is_reused\": \"\"}, {\"run_id\": \"80e3180f-800c-442c-b07e-2a38912cabb1\", \"name\": \"register_model\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:58:33.284063Z\", \"created_time\": \"2022-02-23T19:56:33.885332Z\", \"end_time\": \"2022-02-23T19:58:43.309692Z\", \"duration\": \"0:02:09\", \"run_number\": 1645646193, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:56:33.885332Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"452580cc\": {\"node_id\": \"452580cc\", \"name\": \"skdataset\"}}, \"module_nodes\": {\"fbd7120a\": {\"node_id\": \"fbd7120a\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"ae1c9977-3df9-42d6-8f38-63934b887388\"}, \"431cd644\": {\"node_id\": \"431cd644\", \"name\": \"AutoML_Regression\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"60c326d6-9daa-4c00-96bd-4dbd0a9368a6\"}, \"c9e4e482\": {\"node_id\": \"c9e4e482\", \"name\": \"register_model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"80e3180f-800c-442c-b07e-2a38912cabb1\"}}, \"edges\": [{\"source_node_id\": \"452580cc\", \"source_node_name\": \"skdataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"fbd7120a\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"fbd7120a\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"training_data\", \"dst_node_id\": \"431cd644\", \"dst_node_name\": \"AutoML_Regression\"}, {\"source_node_id\": \"431cd644\", \"source_node_name\": \"AutoML_Regression\", \"source_name\": \"metrics_data\", \"target_name\": \"best_model_data\", \"dst_node_id\": \"c9e4e482\", \"dst_node_name\": \"register_model\"}], \"child_runs\": [{\"run_id\": \"ae1c9977-3df9-42d6-8f38-63934b887388\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:30:56.078463Z\", \"created_time\": \"2022-02-23T19:29:01.971491Z\", \"end_time\": \"2022-02-23T19:32:40.865188Z\", \"duration\": \"0:03:38\", \"run_number\": 1645644541, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:29:01.971491Z\", \"is_reused\": \"\"}, {\"run_id\": \"60c326d6-9daa-4c00-96bd-4dbd0a9368a6\", \"name\": \"AutoML_Regression\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:32:59.439555Z\", \"created_time\": \"2022-02-23T19:32:42.482599Z\", \"end_time\": \"2022-02-23T19:56:19.792708Z\", \"duration\": \"0:23:37\", \"run_number\": 1645644762, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:32:42.482599Z\", \"is_reused\": \"\"}, {\"run_id\": \"80e3180f-800c-442c-b07e-2a38912cabb1\", \"name\": \"register_model\", \"status\": \"Finished\", \"start_time\": \"2022-02-23T19:58:33.284063Z\", \"created_time\": \"2022-02-23T19:56:33.885332Z\", \"end_time\": \"2022-02-23T19:58:43.309692Z\", \"duration\": \"0:02:09\", \"run_number\": 1645646193, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-02-23T19:56:33.885332Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.37.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 9c29cc9e-7050-4749-af14-ed125a9373c1\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/9c29cc9e-7050-4749-af14-ed125a9373c1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: ae1c9977-3df9-42d6-8f38-63934b887388\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/ae1c9977-3df9-42d6-8f38-63934b887388?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "StepRun( Prepare Data ) Status: NotStarted\n",
      "StepRun( Prepare Data ) Status: Running\n",
      "\n",
      "StepRun(Prepare Data) Execution Summary\n",
      "========================================\n",
      "StepRun( Prepare Data ) Status: Finished\n",
      "{'runId': 'ae1c9977-3df9-42d6-8f38-63934b887388', 'target': 'computeclusterlr', 'status': 'Completed', 'startTimeUtc': '2022-02-23T19:30:56.078463Z', 'endTimeUtc': '2022-02-23T19:32:40.865188Z', 'services': {}, 'properties': {'ContentSnapshotId': '9b334f38-6012-4c80-a8b8-eb681b984678', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '67ff3b5f-27f4-4b77-952c-dd8baf0ccd93', 'azureml.moduleName': 'Prepare Data', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'fbd7120a', 'azureml.pipelinerunid': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipeline': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '6c4883fa-1f48-4ea1-a6d5-5fecfeedddd5'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': '7887285a-614a-4887-a824-6eb1e005cbc2'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'prepped_data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('skdatastore', 'dataset/ae1c9977-3df9-42d6-8f38-63934b887388/prepped_data/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ReadParquetFile\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"7887285a-614a-4887-a824-6eb1e005cbc2\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='aml_ws', subscription_id='8f35cf98-68ff-457e-b1b3-e05921a0fd46', resource_group='rg-lr-dp100')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'dataprep.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', 'DatasetOutputConfig:prepped_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'computeclusterlr', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '6c4883fa-1f48-4ea1-a6d5-5fecfeedddd5', 'name': None, 'version': '3'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'prepped_data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'skdatastore', 'relativePath': None}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipelineRun.moduleNodeId': 'fbd7120a', 'azureml.pipelineRun.outputPortName': 'prepped_data'}, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"c18a1f66-4f50-4fe2-a024-5a8c419ade7b\",\\n      \"type\": \"Microsoft.DPrep.ReadParquetFileBlock\",\\n      \"arguments\": {\\n        \"preview\": false\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"aefbe3c9-c2ec-4042-b783-d537d937148e\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Experiment automl_sk_pipeline_v4 Environment', 'version': 'Autosave_2022-02-23T19:29:07Z_0cc69d3f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk[automl]~=1.37.0', 'pyarrow']}, 'pandas', 'scikit-learn'], 'name': 'azureml_0a58f5ea93884f5ab17d28fa937b0355'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211124.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/backgroundProcess.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=0t%2FM%2BaETvTf90TIslYIfpgLoWXVg5vS2Ns0ZpUUpWjs%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=2JdVW0%2BOIoA2DnvoT2BGDi%2FXVZAQRjkLj1km59LmEAc%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r', 'logs/azureml/dataprep/rslex.log': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/dataprep/rslex.log?sv=2019-07-07&sr=b&sig=9D%2BSZq36QffHrhvvnBDrx9FLfj5gUMBwcDC1H1P3COE%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=4PiV3vZlIpsiK7FGFR4Gober3gdFAm8%2FE9sBGzlr858%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=yJicceiuqRPpOfh8T3Hook867APs1dIbowXtrzyZ0iw%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.ae1c9977-3df9-42d6-8f38-63934b887388/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=0sG59WZHdRuK5HSp1JaOhlOyo05Lkv%2BIMFUmv%2BYD%2BJY%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A22Z&ske=2022-02-24T22%3A00%3A22Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A22%3A37Z&se=2022-02-24T03%3A32%3A37Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 60c326d6-9daa-4c00-96bd-4dbd0a9368a6\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/60c326d6-9daa-4c00-96bd-4dbd0a9368a6?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "StepRun( AutoML_Regression ) Status: Running\n",
      "\n",
      "StepRun(AutoML_Regression) Execution Summary\n",
      "=============================================\n",
      "StepRun( AutoML_Regression ) Status: Finished\n",
      "\n",
      "Warnings:\n",
      "Experiment timeout reached, hence experiment stopped. Current experiment timeout: 0 hour(s) 15 minute(s)\n",
      "{'runId': '60c326d6-9daa-4c00-96bd-4dbd0a9368a6', 'target': 'computeclusterlr', 'status': 'Completed', 'startTimeUtc': '2022-02-23T19:32:59.439555Z', 'endTimeUtc': '2022-02-23T19:56:19.792708Z', 'services': {}, 'warnings': [{'source': 'JasmineService', 'message': 'Experiment timeout reached, hence experiment stopped. Current experiment timeout: 0 hour(s) 15 minute(s)'}], 'properties': {'ContentSnapshotId': 'c3e131f1-d1e0-418e-be2f-41b329ada010', 'StepType': 'AutoMLStep', 'azureml.moduleid': '47a24634-fc8a-4fed-af9b-dc7bb0e6459d', 'azureml.moduleName': 'AutoML_Regression', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '431cd644', 'azureml.pipelinerunid': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipeline': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipelineComponent': 'masterautomlcloud', 'num_iterations': '1000', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'metrics': 'accuracy', 'primary_metric': 'normalized_root_mean_squared_error', 'train_split': '0', 'MaxTimeSeconds': '600', 'acquisition_parameter': '0', 'num_cross_validation': '2', 'target': 'computeclusterlr', 'RawAMLSettingsString': None, 'AMLSettingsJsonString': '{\"path\": null, \"name\": \"Automated ML Experiment\", \"subscription_id\": \"8f35cf98-68ff-457e-b1b3-e05921a0fd46\", \"resource_group\": \"rg-lr-dp100\", \"workspace_name\": \"aml_ws\", \"region\": \"southeastasia\", \"compute_target\": \"computeclusterlr\", \"spark_service\": null, \"azure_service\": null, \"many_models\": false, \"pipeline_fetch_max_batch_size\": 1, \"enable_batch_run\": false, \"enable_run_restructure\": false, \"start_auxiliary_runs_before_parent_complete\": false, \"enable_code_generation\": false, \"iterations\": 1000, \"primary_metric\": \"normalized_root_mean_squared_error\", \"task_type\": \"regression\", \"positive_label\": null, \"data_script\": null, \"test_size\": 0.0, \"test_include_predictions_only\": false, \"validation_size\": 0.0, \"n_cross_validations\": 2, \"y_min\": null, \"y_max\": null, \"num_classes\": null, \"featurization\": \"auto\", \"_ignore_package_version_incompatibilities\": false, \"is_timeseries\": false, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 1, \"iteration_timeout_minutes\": 10, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": 15, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": null, \"supported_models\": [\"ElasticNet\", \"XGBoostRegressor\", \"TensorFlowDNN\", \"KNN\", \"RandomForest\", \"TensorFlowLinearRegressor\", \"FastLinearRegressor\", \"SGD\", \"LightGBM\", \"OnlineGradientDescentRegressor\", \"ExtremeRandomTrees\", \"DecisionTree\", \"LassoLars\", \"GradientBoosting\"], \"private_models\": [\"TabnetRegressor\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"_debug_log\": \"automated_ml_errors.log\", \"show_warnings\": false, \"model_explainability\": true, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": false, \"enable_split_onnx_featurizer_estimator_models\": false, \"vm_type\": \"STANDARD_DS11_V2\", \"telemetry_verbosity\": 20, \"send_telemetry\": true, \"enable_dnn\": false, \"scenario\": \"SDK-1.13.0\", \"environment_label\": null, \"save_mlflow\": false, \"enable_categorical_indicators\": false, \"force_text_dnn\": false, \"enable_feature_sweeping\": true, \"enable_early_stopping\": true, \"early_stopping_n_iters\": 10, \"arguments\": null, \"dataset_id\": null, \"hyperdrive_config\": null, \"validation_dataset_id\": null, \"run_source\": null, \"metrics\": null, \"enable_metric_confidence\": false, \"enable_ensembling\": true, \"enable_stack_ensembling\": true, \"ensemble_iterations\": 15, \"enable_tf\": false, \"enable_subsampling\": null, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"force_streaming\": false, \"track_child_runs\": true, \"allowed_private_models\": [], \"label_column_name\": \"Sales\", \"weight_column_name\": null, \"cv_split_column_names\": null, \"enable_local_managed\": false, \"_local_managed_run_id\": null, \"cost_mode\": 1, \"lag_length\": 0, \"metric_operation\": \"minimize\", \"preprocess\": true}', 'DataPrepJsonString': '{\\\\\"training_data\\\\\":\\\\\"{\\\\\\\\n  \\\\\\\\\\\\\"blocks\\\\\\\\\\\\\": [\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"a20ec14e-9112-47e7-b4c1-3e8f71e27a8e\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.GetDatastoreFilesBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"datastores\\\\\\\\\\\\\": [\\\\\\\\n          {\\\\\\\\n            \\\\\\\\\\\\\"datastoreName\\\\\\\\\\\\\": \\\\\\\\\\\\\"skdatastore\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"path\\\\\\\\\\\\\": \\\\\\\\\\\\\"dataset/ae1c9977-3df9-42d6-8f38-63934b887388/prepped_data/\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"resourceGroup\\\\\\\\\\\\\": \\\\\\\\\\\\\"rg-lr-dp100\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"subscription\\\\\\\\\\\\\": \\\\\\\\\\\\\"8f35cf98-68ff-457e-b1b3-e05921a0fd46\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\"workspaceName\\\\\\\\\\\\\": \\\\\\\\\\\\\"aml_ws\\\\\\\\\\\\\"\\\\\\\\n          }\\\\\\\\n        ]\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"c18a1f66-4f50-4fe2-a024-5a8c419ade7b\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.ReadParquetFileBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"preview\\\\\\\\\\\\\": false\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"aefbe3c9-c2ec-4042-b783-d537d937148e\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.DropColumnsBlock\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\"columns\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\"type\\\\\\\\\\\\\": 0,\\\\\\\\n          \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\n            \\\\\\\\\\\\\"selectedColumns\\\\\\\\\\\\\": [\\\\\\\\n              \\\\\\\\\\\\\"Path\\\\\\\\\\\\\"\\\\\\\\n            ]\\\\\\\\n          }\\\\\\\\n        }\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {},\\\\\\\\n      \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true,\\\\\\\\n      \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null\\\\\\\\n    }\\\\\\\\n  ],\\\\\\\\n  \\\\\\\\\\\\\"inspectors\\\\\\\\\\\\\": [],\\\\\\\\n  \\\\\\\\\\\\\"meta\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\"savedDatasetId\\\\\\\\\\\\\": \\\\\\\\\\\\\"8421780e-d588-4160-ac76-36abda9a7061\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"datasetType\\\\\\\\\\\\\": \\\\\\\\\\\\\"tabular\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"subscriptionId\\\\\\\\\\\\\": \\\\\\\\\\\\\"8f35cf98-68ff-457e-b1b3-e05921a0fd46\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"workspaceId\\\\\\\\\\\\\": \\\\\\\\\\\\\"57a0fe81-1934-4a22-8898-5e401a74b8ea\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\"workspaceLocation\\\\\\\\\\\\\": \\\\\\\\\\\\\"southeastasia\\\\\\\\\\\\\"\\\\\\\\n  }\\\\\\\\n}\\\\\",\\\\\"activities\\\\\":\\\\\"0\\\\\"}', 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'Orchestrator': 'automl', 'ClientType': 'Others', '_aml_system_scenario_identification': 'Remote.Parent', 'root_attribution': 'azureml.StepRun', 'snapshotId': 'c3e131f1-d1e0-418e-be2f-41b329ada010', 'SetupRunId': '60c326d6-9daa-4c00-96bd-4dbd0a9368a6_setup', 'SetupRunContainerId': 'dcid.60c326d6-9daa-4c00-96bd-4dbd0a9368a6_setup', 'ClientSdkVersion': '1.38.0', 'FeaturizationRunJsonPath': 'featurizer_container.json', 'FeaturizationRunId': '60c326d6-9daa-4c00-96bd-4dbd0a9368a6_featurize', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"has_extra_col\": true, \"dataset_classes\": 395, \"dataset_features\": 54, \"dataset_samples\": 1151, \"single_frequency_class_detected\": false}', 'ModelExplainRunId': '60c326d6-9daa-4c00-96bd-4dbd0a9368a6_ModelExplain'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.60c326d6-9daa-4c00-96bd-4dbd0a9368a6/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=jIacsDikGArUTgEYoufgdAlnRa5Ym33vxcwTS7QZNVs%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A42%3A50Z&se=2022-02-24T03%3A52%3A50Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.60c326d6-9daa-4c00-96bd-4dbd0a9368a6/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=xis0QXl8ZJHfPS8j9AbFiff4nzC2KZ7p81zcnQ9zcqo%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A42%3A50Z&se=2022-02-24T03%3A52%3A50Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.60c326d6-9daa-4c00-96bd-4dbd0a9368a6/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=wPhmLjCgPuBbE3%2FMWcFTTecLA1l2WIJS8811PJVpnZk%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A42%3A50Z&se=2022-02-24T03%3A52%3A50Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 80e3180f-800c-442c-b07e-2a38912cabb1\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/80e3180f-800c-442c-b07e-2a38912cabb1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\n",
      "StepRun( register_model ) Status: Running\n",
      "\n",
      "StepRun(register_model) Execution Summary\n",
      "==========================================\n",
      "StepRun( register_model ) Status: Finished\n",
      "{'runId': '80e3180f-800c-442c-b07e-2a38912cabb1', 'target': 'computeclusterlr', 'status': 'Completed', 'startTimeUtc': '2022-02-23T19:58:33.284063Z', 'endTimeUtc': '2022-02-23T19:58:43.309692Z', 'services': {}, 'properties': {'ContentSnapshotId': '83941250-e2e4-47b2-894e-5dc296355ad5', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '42c9db6c-a00e-49c2-944a-f0c7973db919', 'azureml.moduleName': 'register_model', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'c9e4e482', 'azureml.pipelinerunid': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipeline': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'register_model.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_name', '$AML_PARAMETER_model_name', '--model_path', '$AZUREML_DATAREFERENCE_best_model_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'computeclusterlr', 'dataReferences': {'best_model_data': {'dataStoreName': 'skdatastore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/60c326d6-9daa-4c00-96bd-4dbd0a9368a6/best_model_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'Experiment automl_sk_pipeline_v4 Environment', 'version': 'Autosave_2022-02-23T19:29:07Z_0cc69d3f', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk[automl]~=1.37.0', 'pyarrow']}, 'pandas', 'scikit-learn'], 'name': 'azureml_0a58f5ea93884f5ab17d28fa937b0355'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211124.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {'AML_PARAMETER_model_name': 'sk_model_v4'}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=ec1aZ16%2F9mABMAl5cw9hVLW%2FHUkphdV0jCicuZsclGY%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A58%3A04Z&ske=2022-02-24T22%3A08%3A04Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A46%3A39Z&se=2022-02-24T03%3A56%3A39Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=PH8AJIrjCYdesy%2Fh%2FNrT32eNu1s9HwxfZz6OUEbMFwo%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A58%3A04Z&ske=2022-02-24T22%3A08%3A04Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A46%3A39Z&se=2022-02-24T03%3A56%3A39Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=OI3BAt7f1qZRgzOr%2BVaBwYke96uaTm3P6oU8DVL5oR4%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A58%3A04Z&ske=2022-02-24T22%3A08%3A04Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A46%3A39Z&se=2022-02-24T03%3A56%3A39Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '9c29cc9e-7050-4749-af14-ed125a9373c1', 'status': 'Completed', 'startTimeUtc': '2022-02-23T19:29:00.480396Z', 'endTimeUtc': '2022-02-23T19:58:44.506458Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"model_name\":\"sk_model_v4\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=2ajLD6QOcnIks2z8CSvNul6QuS6at%2Fq19ePtWvX9D0o%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A45%3A10Z&se=2022-02-24T03%3A55%3A10Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=BX7%2FGKm1RFvsxRJrT60XHRpoNYF1r2g4jvLLfjHjFPw%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A45%3A10Z&se=2022-02-24T03%3A55%3A10Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.9c29cc9e-7050-4749-af14-ed125a9373c1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=Z9AiIhOt1L3IDTJAyRoZvb2aqx8qlph2ne0vEEM0NJc%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A50%3A21Z&ske=2022-02-24T22%3A00%3A21Z&sks=b&skv=2019-07-07&st=2022-02-23T19%3A45%3A10Z&se=2022-02-24T03%3A55%3A10Z&sp=r'}, 'submittedBy': 'Lalitha Raghavan'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42a55b642fe47a194f4bd5b32716343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "experiment = Experiment(workspace=ws, name='automl_sk_pipeline_v4')\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [prep_step, train_step, register_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ee725bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "register_model\n",
      "80e3180f-800c-442c-b07e-2a38912cabb1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8c27c813ea4b358b42e550390cd0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/80e3180f-800c-442c-b07e-2a38912cabb1?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws&tid=e339bd4b-2e3b-4035-a452-2112d502f2ff\", \"run_id\": \"80e3180f-800c-442c-b07e-2a38912cabb1\", \"run_properties\": {\"run_id\": \"80e3180f-800c-442c-b07e-2a38912cabb1\", \"created_utc\": \"2022-02-23T19:56:33.885332Z\", \"properties\": {\"ContentSnapshotId\": \"83941250-e2e4-47b2-894e-5dc296355ad5\", \"StepType\": \"PythonScriptStep\", \"ComputeTargetType\": \"AmlCompute\", \"azureml.moduleid\": \"42c9db6c-a00e-49c2-944a-f0c7973db919\", \"azureml.moduleName\": \"register_model\", \"azureml.runsource\": \"azureml.StepRun\", \"azureml.nodeid\": \"c9e4e482\", \"azureml.pipelinerunid\": \"9c29cc9e-7050-4749-af14-ed125a9373c1\", \"azureml.pipeline\": \"9c29cc9e-7050-4749-af14-ed125a9373c1\", \"azureml.pipelineComponent\": \"masterescloud\", \"_azureml.ComputeTargetType\": \"amlcompute\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"azureml.nodeid\": \"c9e4e482\", \"azureml.pipeline\": \"9c29cc9e-7050-4749-af14-ed125a9373c1\", \"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":1,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-02-23T19:58:43.309692Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=y%2BZXInfGqG36e5fB9lvna8yNeqIhfx5qCOQrnf%2FDXAs%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A55%3A20Z&ske=2022-02-24T22%3A05%3A20Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A28Z&se=2022-02-24T04%3A53%3A28Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=KMemqgz10V8LKZ8oJ3hFVL%2FwlYIMTmIY3RifqkjDYbE%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A55%3A20Z&ske=2022-02-24T22%3A05%3A20Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A28Z&se=2022-02-24T04%3A53%3A28Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://amlws8080781874.blob.core.windows.net/azureml/ExperimentRun/dcid.80e3180f-800c-442c-b07e-2a38912cabb1/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=t8EwPzEBJj1%2BBYPufx287mS2UX0zW57NOBEkx3OMI2I%3D&skoid=4d39dcde-4abc-4c80-95b6-29e56284a6f3&sktid=e339bd4b-2e3b-4035-a452-2112d502f2ff&skt=2022-02-23T13%3A55%3A20Z&ske=2022-02-24T22%3A05%3A20Z&sks=b&skv=2019-07-07&st=2022-02-23T20%3A43%3A28Z&se=2022-02-24T04%3A53%3A28Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:02:09\", \"run_number\": \"1645646193\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2022-02-23 19:56:35Z] Experiment: automl_sk_pipeline_v4, Run target: computeclusterlr, Run Id: 80e3180f-800c-442c-b07e-2a38912cabb1, WorkspaceName: aml_ws, WorkspaceId: 57a0fe81-1934-4a22-8898-5e401a74b8ea\\n[2022-02-23 19:56:35Z] Starting run in Execution Service\\n[2022-02-23 19:56:36Z] RunId:[80e3180f-800c-442c-b07e-2a38912cabb1] ParentRunId:[9c29cc9e-7050-4749-af14-ed125a9373c1] ComputeTarget:[AmlCompute]\\n[2022-02-23 19:56:37Z] Job is in progress. Execution status: Preparing.\\n[2022-02-23 19:56:38Z] Job is in progress. Execution status: Queued.\\n[2022-02-23 19:56:39Z] Job is in progress. Execution status: Queued.\\n[2022-02-23 19:58:33Z] Job is in progress. Execution status: Running.\\n[2022-02-23 19:58:37Z] Job is in progress. Execution status: Running.\\n[2022-02-23 19:58:40Z] Job is in progress. Execution status: Finalizing.\\n[2022-02-23 19:58:43Z] Job finished, job RunId is 80e3180f-800c-442c-b07e-2a38912cabb1\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.37.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Get the run ID from pipeline run\n",
    "\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "#from azureml.widgets import RunDetails\n",
    "\n",
    "# workaround to get the automl run as its the last step in the pipeline \n",
    "# and get_steps() returns the steps from latest to first\n",
    "\n",
    "for step in pipeline_run.get_steps():\n",
    "    automl_step_run_id = step.id\n",
    "    print(step.name)\n",
    "    print(automl_step_run_id)\n",
    "    break\n",
    "\n",
    "automl_run = AutoMLRun(experiment = experiment, run_id=automl_step_run_id)\n",
    "RunDetails(automl_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3191e891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID 80e3180f-800c-442c-b07e-2a38912cabb1\n",
      "Run ID 60c326d6-9daa-4c00-96bd-4dbd0a9368a6\n",
      "\t {'experiment_status': ['DatasetEvaluation', 'FeaturesGeneration', 'DatasetFeaturization', 'DatasetFeaturizationCompleted', 'DatasetCrossValidationSplit', 'ModelSelection', 'BestRunExplainModel', 'ModelExplanationDataSetSetup', 'PickSurrogateModel', 'EngineeredFeatureExplanations', 'EngineeredFeatureExplanations', 'RawFeaturesExplanations', 'RawFeaturesExplanations', 'BestRunExplainModel']}\n",
      "\t {'experiment_status_description': ['Gathering dataset statistics.', 'Generating features for the dataset.', 'Beginning to fit featurizers and featurize the dataset.', 'Completed fit featurizers and featurizing the dataset.', 'Generating individually featurized CV splits.', 'Beginning model selection.', 'Best run model explanations started', 'Model explanations data setup completed', 'Choosing LightGBM as the surrogate model for explanations', 'Computation of engineered features started', 'Computation of engineered features completed', 'Computation of raw features started', 'Computation of raw features completed', 'Best run model explanations completed']}\n",
      "\t {'normalized_median_absolute_error': 0.0006741485692075984}\n",
      "\t {'spearman_correlation': 0.8355982244730783}\n",
      "\t {'root_mean_squared_log_error': 1.839731819152455}\n",
      "\t {'normalized_root_mean_squared_log_error': 0.1761676252585014}\n",
      "\t {'normalized_root_mean_squared_error': 0.014504898323119235}\n",
      "\t {'mean_absolute_error': 113.057680209187}\n",
      "\t {'root_mean_squared_error': 497.59053697460536}\n",
      "\t {'r2_score': 0.9184531312829576}\n",
      "\t {'normalized_mean_absolute_error': 0.003295661862970033}\n",
      "\t {'mean_absolute_percentage_error': 225.4678459526737}\n",
      "\t {'explained_variance': 0.9184597676288518}\n",
      "\t {'median_absolute_error': 23.126666666666665}\n",
      "Run ID ae1c9977-3df9-42d6-8f38-63934b887388\n",
      "\t {'processed_rows': 1151}\n"
     ]
    }
   ],
   "source": [
    "for run in pipeline_run.get_children():\n",
    "    print('Run ID', run.id)\n",
    "    for metric in run.get_metrics():\n",
    "        print('\\t', run.get_metrics(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe19ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_model_v4 version: 2\n",
      "\n",
      "\n",
      "sk_model_v2 version: 2\n",
      "\n",
      "\n",
      "sk_model_v2 version: 1\n",
      "\n",
      "\n",
      "sk_model_initial version: 2\n",
      "\n",
      "\n",
      "sk_model version: 5\n",
      "\t Training context : Auto ML in pipeline\n",
      "\t AUC : 0.014550774687038625\n",
      "\n",
      "\n",
      "AutoML0b24ea5a20 version: 1\n",
      "\n",
      "\n",
      "amlstudio-test-deploy-v2 version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "amlstudio-test-endpoint-lr version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "diabetes_model version: 11\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8832778417290374\n",
      "\t Accuracy : 0.8991111111111111\n",
      "\n",
      "\n",
      "diabetes_mitigated_20 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_19 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_18 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_17 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_16 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_15 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_14 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_13 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_12 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_11 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_10 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_9 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_8 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_7 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_6 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_5 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_4 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_3 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_2 version: 1\n",
      "\n",
      "\n",
      "diabetes_mitigated_1 version: 1\n",
      "\n",
      "\n",
      "diabetes_unmitigated version: 1\n",
      "\n",
      "\n",
      "diabetes_classifier version: 1\n",
      "\n",
      "\n",
      "diabetes_model version: 10\n",
      "\t Training context : Auto ML\n",
      "\t AUC : 0.9904812577250306\n",
      "\t Accuracy : 0.9520809898762654\n",
      "\n",
      "\n",
      "diabetes_model version: 9\n",
      "\t Training context : Hyperdrive\n",
      "\t AUC : 0.9885804604667666\n",
      "\t Accuracy : 0.9457777777777778\n",
      "\n",
      "\n",
      "diabetes_model version: 8\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8755584854967908\n",
      "\t Accuracy : 0.8863333333333333\n",
      "\n",
      "\n",
      "diabetes_model version: 7\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.879600975172894\n",
      "\t Accuracy : 0.8926666666666667\n",
      "\n",
      "\n",
      "diabetes_model version: 6\n",
      "\t Training context : Pipeline\n",
      "\t AUC : 0.8837616052365906\n",
      "\t Accuracy : 0.8988888888888888\n",
      "\n",
      "\n",
      "diabetes_model version: 5\n",
      "\t Training context : File dataset\n",
      "\t AUC : 0.8568743524381947\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 4\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8483964376337131\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8483999203940495\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC : 0.8484929598487486\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "\n",
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67f4d75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>automl-sk-pipeline-v4</td><td><a href=\"https://ml.azure.com/pipelines/55ec1f8e-8c06-49b9-b8a1-a8ff704bf5fb?wsid=/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourcegroups/rg-lr-dp100/workspaces/aml_ws\" target=\"_blank\" rel=\"noopener\">55ec1f8e-8c06-49b9-b8a1-a8ff704bf5fb</a></td><td>Active</td><td><a href=\"https://southeastasia.api.azureml.ms/pipelines/v1.0/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/PipelineRuns/PipelineSubmit/55ec1f8e-8c06-49b9-b8a1-a8ff704bf5fb\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: automl-sk-pipeline-v4,\n",
       "Id: 55ec1f8e-8c06-49b9-b8a1-a8ff704bf5fb,\n",
       "Status: Active,\n",
       "Endpoint: https://southeastasia.api.azureml.ms/pipelines/v1.0/subscriptions/8f35cf98-68ff-457e-b1b3-e05921a0fd46/resourceGroups/rg-lr-dp100/providers/Microsoft.MachineLearningServices/workspaces/aml_ws/PipelineRuns/PipelineSubmit/55ec1f8e-8c06-49b9-b8a1-a8ff704bf5fb)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Publish the pipeline from the run\n",
    "\n",
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"automl-sk-pipeline-v4\", description=\"Trains sk model in pipeline\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a69f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00bc3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_model version 7\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['sk_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2b9fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n",
    "from inference_schema.schema_decorators import input_schema, output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebe24a56",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelNotFoundException",
     "evalue": "ModelNotFoundException:\n\tMessage: Model sk_model.pkl not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/aml-comp-lr/code. For more info, set logging level to DEBUG.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Model sk_model.pkl not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/aml-comp-lr/code. For more info, set logging level to DEBUG.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelNotFoundException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-94b23a65b024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m  \u001b[0;31m# Get the path to the deployed model file and load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sk_model.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36mget_model_path\u001b[0;34m(model_name, version, _workspace)\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_path_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_workspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_path_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36m_get_model_path_local\u001b[0;34m(model_name, version)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# Probing azureml-models/<name>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_model_path_local_from_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;31m# Probing azureml-models/<name> exists, probing version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36m_get_model_path_local_from_root\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    870\u001b[0m         raise ModelNotFoundException(\"Model {} not found in cache at {} or in current working directory {}. \"\n\u001b[1;32m    871\u001b[0m                                      \"For more info, set logging level to DEBUG.\".format(model_name, MODELS_DIR,\n\u001b[0;32m--> 872\u001b[0;31m                                                                                          os.getcwd()))\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelNotFoundException\u001b[0m: ModelNotFoundException:\n\tMessage: Model sk_model.pkl not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/aml-comp-lr/code. For more info, set logging level to DEBUG.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Model sk_model.pkl not found in cache at azureml-models or in current working directory /mnt/batch/tasks/shared/LS_root/mounts/clusters/aml-comp-lr/code. For more info, set logging level to DEBUG.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from azureml.core import Model\n",
    "\n",
    " # Get the path to the deployed model file and load it\n",
    "model_path = Model.get_model_path(\"sk_model\")\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "raw_data = '{\"data\":[[\"Grand Punto\", 4000, \"Compact-Regular\", \"Hatchback\",\"Fiat\", 1.4, 8, 16, 105.71, \"Y\", \"N\", 5]]}'\n",
    "\n",
    "data = json.loads(raw_data)[\"data\"]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2af08dd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b636d77a370a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrequest_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test result: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "request_headers = {}\n",
    "\n",
    "result = model.predict(data)\n",
    "print(\"Test result: \", {\"result\": result.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9578d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
